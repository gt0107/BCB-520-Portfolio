[
  {
    "objectID": "Index.html",
    "href": "Index.html",
    "title": "BCB-520-BLOG-Portfolio",
    "section": "",
    "text": "ASSIGNMENT 4\n\n\nMarks And Channel\n\n\n\n\nAssignment\n\n\nDataViz\n\n\n\n\nLets Learn about Marks and Channels\n\n\n\n\n\n\nGeraline Trossi-Torres\n\n\n\n\n\n\n  \n\n\n\n\nBCB 520 - FINAL PROJECT\n\n\nLet’s get into RainFall Data in Puerto Rico\n\n\n\n\nPortfolio\n\n\nDataViz\n\n\nAssignment\n\n\n\n\nHow much Rainfall did Puerto Rico had in the last 15 years\n\n\n\n\n\n\nApr 28, 2024\n\n\nGeraline Tross-Torres\n\n\n\n\n\n\n  \n\n\n\n\nPractice with Spatial Data\n\n\nMAPS!\n\n\n\n\nDataViz\n\n\nSpatial\n\n\nGGPlot\n\n\nAssignment\n\n\n\n\nMaps and Spatial Fields are fun!\n\n\n\n\n\n\nApr 18, 2024\n\n\nGeraline Trossi-Torres\n\n\n\n\n\n\n  \n\n\n\n\nNETWORKS IN OBSERVABLE\n\n\nInteractivity and Animation\n\n\n\n\nPortfolio\n\n\nDataViz\n\n\nNetwork\n\n\nObservable\n\n\nAssignment\n\n\n\n\nCool!\n\n\n\n\n\n\nApr 9, 2024\n\n\nBarrie Robison\n\n\n\n\n\n\n  \n\n\n\n\nPractice with Network Data\n\n\nNodes and Links and edges and vertices…\n\n\n\n\nPortfolio\n\n\nDataViz\n\n\nNetwork\n\n\niGraph\n\n\nAssignment\n\n\n\n\niGRAPH!\n\n\n\n\n\n\nApr 4, 2024\n\n\nBarrie Robison\n\n\n\n\n\n\n  \n\n\n\n\nBCB 520 - Midterm Portfolio Post\n\n\nLet’s look at funding!\n\n\n\n\nMidterm\n\n\nDataViz\n\n\nVisualization\n\n\n\n\nLet’s do some visualizations on how well University of Idaho is acquiring grants\n\n\n\n\n\n\nMar 29, 2024\n\n\nGeraline Trossi-Torres\n\n\n\n\n\n\n  \n\n\n\n\nHockey Analytics\n\n\nVisualizations for Tabular Data\n\n\n\n\nAssignment\n\n\nDataViz\n\n\nVisualization\n\n\n\n\nLets learn about hockey draft analytics\n\n\n\n\n\n\nFeb 29, 2024\n\n\nGeraline Trossi-Torres\n\n\n\n\n\n\n  \n\n\n\n\nWelcome To My Blog\n\n\n\n\n\n\n\nnews\n\n\n\n\n\n\n\n\n\n\n\nFeb 5, 2024\n\n\nGeraline Trossi-Torres\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/MapsSpatialData/index.html",
    "href": "posts/MapsSpatialData/index.html",
    "title": "Practice with Spatial Data",
    "section": "",
    "text": "In this assignment, we’ll consider some of the tools and techniques for visualizing spatial data. Spatial data comes in two broad categories, geographic and spatial fields. Let’s practice a few visualizations to get a feel for how these things work!"
  },
  {
    "objectID": "posts/MapsSpatialData/index.html#overview",
    "href": "posts/MapsSpatialData/index.html#overview",
    "title": "Practice with Spatial Data",
    "section": "",
    "text": "In this assignment, we’ll consider some of the tools and techniques for visualizing spatial data. Spatial data comes in two broad categories, geographic and spatial fields. Let’s practice a few visualizations to get a feel for how these things work!"
  },
  {
    "objectID": "posts/MapsSpatialData/index.html#geographic-maps",
    "href": "posts/MapsSpatialData/index.html#geographic-maps",
    "title": "Practice with Spatial Data",
    "section": "GEOGRAPHIC MAPS!",
    "text": "GEOGRAPHIC MAPS!\nIn class I bet Ronald that he would end up creating some kind of map based visualization before he graduated with his PHD. This is because he works on Malaria - a terrible disease with a strong spatial component to its risk levels. Let’s get some Malaria data and map it!\nThe data I obtained were from the Malaria Atlas. I downloaded a csv for 10 years of data for all the countries the had on file.\n\n\nCode\nlibrary(tidyverse)\nlibrary(readxl)\nlibrary(rnaturalearth)\nlibrary(rnaturalearthdata)\nlibrary(dplyr)\n\nMalaria &lt;- read.csv(\"National_Unit_data.csv\")\n\nIncidence&lt;- Malaria%&gt;%\n  filter(Metric == \"Infection Prevalence\")%&gt;%\n  mutate(Prevalence = Value, Year = as.factor(Year))\n\n#%&gt;%\n  #select(c(ISO3, Prevalence, Year))\n\n\nNow I’m going to use the rnaturalearth package to create contry polygons. Then I’ll add the Malaria data to that data frame.\n\n\nCode\nworld_map &lt;- ne_countries(scale = \"medium\", returnclass = \"sf\")\n\nmap_data &lt;- world_map %&gt;%\n  left_join(Incidence, by = c(\"iso_a3\" = \"ISO3\"))%&gt;%\n  filter(!is.na(Prevalence))\n\n\nNow I will make a plot!\n\n\nCode\nlibrary(gganimate)\nlibrary(transformr)\nlibrary(magick)\nlibrary(gifski)\n# \nggplot() +\n  geom_sf(data = map_data%&gt;%\n            filter(continent==\"Africa\"),\n          aes(fill = Prevalence)) +\n  scale_fill_gradient(low = \"white\", high = \"red\", na.value = \"gray\", name = \"Malaria Prevalence\") +\n  theme_minimal() +\n  theme(axis.text = element_blank(), axis.ticks = element_blank(), axis.title = element_blank()) +\n  labs(title = \"Malaria Prevalence by Country\")"
  },
  {
    "objectID": "posts/MapsSpatialData/index.html#my-version",
    "href": "posts/MapsSpatialData/index.html#my-version",
    "title": "Practice with Spatial Data",
    "section": "My VERSION",
    "text": "My VERSION\n\n\nCode\nlibrary(ggplot2)\nlibrary(sf)\nlibrary(maps)\n\n# Load U.S. map data\nusa &lt;- map_data(\"usa\")\n\n# Plot U.S. map\nggplot() +\n  geom_polygon(data = usa, aes(x = long, y = lat, group = group), fill = \"white\", color = \"black\") +\n  coord_fixed(1.3) +  # Aspect ratio adjustment\n  theme_void()  # Remove unnecessary elements\n\n\n\n\n\nCode\n# Load U.S. state boundary data\nstates &lt;- map_data(\"state\")\n\n# Plot U.S. map with state boundaries\nggplot() +\n  geom_polygon(data = usa, aes(x = long, y = lat, group = group), fill = \"white\", color = \"black\") +\n  geom_polygon(data = states, aes(x = long, y = lat, group = group), fill = NA, color = \"gray\") + # Add state boundaries\n  coord_fixed(1.3) +  # Aspect ratio adjustment\n  theme_void()  # Remove unnecessary elements\n\n\n\n\n\n\n\nCode\n# Load required packages\nlibrary(readxl)\nlibrary(ggplot2)\n\n# Load your Chlamydia cases dataset (assuming it's named 'ChlamydiaInfectionRate.xlsx')\nchlamydia_data &lt;- read_excel(\"ChlamydiaInfectionRate.xlsx\")\n\n# Merge Chlamydia cases data with state boundaries data\nstates_chlamydia &lt;- merge(states, chlamydia_data, by.x = \"region\", by.y = \"State\", all.x = TRUE)\n\n# Unique values in the 'region' column of the 'states' dataframe\nunique(states$region)\n\n\n [1] \"alabama\"              \"arizona\"              \"arkansas\"            \n [4] \"california\"           \"colorado\"             \"connecticut\"         \n [7] \"delaware\"             \"district of columbia\" \"florida\"             \n[10] \"georgia\"              \"idaho\"                \"illinois\"            \n[13] \"indiana\"              \"iowa\"                 \"kansas\"              \n[16] \"kentucky\"             \"louisiana\"            \"maine\"               \n[19] \"maryland\"             \"massachusetts\"        \"michigan\"            \n[22] \"minnesota\"            \"mississippi\"          \"missouri\"            \n[25] \"montana\"              \"nebraska\"             \"nevada\"              \n[28] \"new hampshire\"        \"new jersey\"           \"new mexico\"          \n[31] \"new york\"             \"north carolina\"       \"north dakota\"        \n[34] \"ohio\"                 \"oklahoma\"             \"oregon\"              \n[37] \"pennsylvania\"         \"rhode island\"         \"south carolina\"      \n[40] \"south dakota\"         \"tennessee\"            \"texas\"               \n[43] \"utah\"                 \"vermont\"              \"virginia\"            \n[46] \"washington\"           \"west virginia\"        \"wisconsin\"           \n[49] \"wyoming\"             \n\n\nCode\n# Unique values in the 'State' column of the 'chlamydia_data' dataframe\nunique(chlamydia_data$State)\n\n\n [1] \"Louisiana\"      \"Mississippi\"    \"Alaska\"         \"South Carolina\"\n [5] \"Georgia\"        \"Alabama\"        \"North Carolina\" \"Arkansas\"      \n [9] \"Illinois\"       \"South Dakota\"   \"Arizona\"        \"Tennessee\"     \n[13] \"New Mexico\"     \"New York\"       \"Missouri\"       \"Texas\"         \n[17] \"Nevada\"         \"Delaware\"       \"Maryland\"       \"Oklahoma\"      \n[21] \"Indiana\"        \"US TOTAL†\"      \"California\"     \"Nebraska\"      \n[25] \"Florida\"        \"Rhode Island\"   \"North Dakota\"   \"Kansas\"        \n[29] \"Virginia\"       \"Ohio\"           \"Iowa\"           \"Colorado\"      \n[33] \"Wisconsin\"      \"Michigan\"       \"Pennsylvania\"   \"Kentucky\"      \n[37] \"Massachusetts\"  \"Minnesota\"      \"Hawaii\"         \"Oregon\"        \n[41] \"Washington\"     \"Montana\"        \"New Jersey\"     \"Connecticut\"   \n[45] \"Utah\"           \"Wyoming\"        \"Idaho\"          \"West Virginia\" \n[49] \"Maine\"          \"New Hampshire\"  \"Vermont\"       \n\n\nCode\n# Trim leading and trailing spaces from the key columns\nstates$region &lt;- trimws(states$region)\nchlamydia_data$State &lt;- trimws(chlamydia_data$State)\n\n# Convert key columns to lowercase before merging\nstates$region &lt;- tolower(states$region)\nchlamydia_data$State &lt;- tolower(chlamydia_data$State)\n\n# Perform merge\nstates_chlamydia &lt;- merge(states, chlamydia_data, by.x = \"region\", by.y = \"State\", all.x = TRUE)\n\n# Plot the map with Chlamydia cases data\nggplot() +\n  geom_polygon(data = usa, aes(x = long, y = lat, group = group), fill = \"white\", color = \"black\") +\n  geom_polygon(data = states_chlamydia, aes(x = long, y = lat, group = group, fill = Cases), color = \"darkgray\") + # Add state boundaries with Chlamydia cases\n  scale_fill_gradient(low = \"lightpink\", high = \"darkred\", name = \"Chlamydia Cases\") + # Customize the color scale\n  coord_fixed(1.3) +  # Aspect ratio adjustment\n  theme_void()  # Remove unnecessary elements\n\n\n\n\n\n\n\nCode\nlibrary(rnaturalearth)\nlibrary(rnaturalearthdata)\nlibrary(dplyr)\nlibrary(rnaturalearthhires)\n\n# Get the spatial data for countries\ncountries &lt;- ne_countries(scale = \"medium\", returnclass = \"sf\")\n\n# Filter the dataset to extract Puerto Rico\npuerto_rico &lt;- subset(countries, admin == \"Puerto Rico\")\n\n# Plot Puerto Rico's geometry\nggplot() +\n  geom_sf(data = puerto_rico) +\n  theme_void()"
  },
  {
    "objectID": "posts/NetworkObservable/index.html",
    "href": "posts/NetworkObservable/index.html",
    "title": "NETWORKS IN OBSERVABLE",
    "section": "",
    "text": "The QUARTO documentation on Observable can be found here.\nThe preamble of that document summarizes things nicely:\n\nQuarto includes native support for Observable JS, a set of enhancements to vanilla JavaScript created by Mike Bostock (also the author of D3). Observable JS is distinguished by its reactive runtime, which is especially well suited for interactive data exploration and analysis.\nThe creators of Observable JS (Observable, Inc.) run a hosted service at https://observablehq.com/ where you can create and publish notebooks. Additionally, you can use Observable JS (“OJS”) in standalone documents and websites via its core libraries. Quarto uses these libraries along with a compiler that is run at render time to enable the use of OJS within Quarto documents.\nOJS works in any Quarto document (plain markdown as well as Jupyter and Knitr documents). Just include your code in an {ojs} executable code block.\n\n\n\nI’m going to start by trying to replicate this observable notebook:\n\n\nCode\ngraph1 = ({\n  nodes: [\n    {id: \"a\"},\n    {id: \"b\"},\n    {id: \"c\"}\n  ],\n  links: []\n})\n\n\ngraph2 = ({\n  nodes: [\n    {id: \"a\"},\n    {id: \"b\"},\n    {id: \"c\"}\n  ],\n  links: [\n    {source: \"a\", target: \"b\"},\n    {source: \"b\", target: \"c\"},\n    {source: \"c\", target: \"a\"}\n  ]\n})\n\n\ngraph3 = ({\n  nodes: [\n    {id: \"a\"},\n    {id: \"b\"}\n  ],\n  links: [\n    {source: \"a\", target: \"b\"}\n  ]\n})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n```{ojs}\ngraph4 = {\n  nodes: [\n    {id: \"Life Sciences\"},\n    {id: \"Physical Sciences\"},\n    {id: \"Heidi\"},\n    {id: \"Robyn\"},\n    {id: \"Konrad\"},\n    {id: \"Geraline\"},\n    {id: \"Lucas\"},\n    {id: \"Yaotian\"}\n  ],\n  links: [\n    {source: \"Life Sciences\", target: \"Physical Sciences\"},\n    {source: \"Life Sciences\", target: \"Heidi\"},\n    {source: \"Physical Sciences\", target: \"Robyn\"},\n    {source: \"Physical Sciences\", target: \"Konrad\"},\n    {source: \"Heidi\", target: \"Geraline\"},\n    {source: \"Heidi\", target: \"Lucas\"},\n    {source: \"Robyn\", target: \"Yaotian\"},\n    {source: \"Lucas\", target: \"Yaotian\"}\n  ]\n};\n\n```\n\n\n\n\n\n\n\nOJS Syntax Error (line 81, column 8)Unexpected token\n\n\n\n\n\n\n\n\n\n\nCode\nviewof graph = {\n  const form = html`&lt;form style=\"font: 12px var(--sans-serif); display: flex; height: 33px; align-items: center;\"&gt;\n  &lt;label style=\"margin-right: 1em; display: inline-flex; align-items: center;\"&gt;\n    &lt;input type=\"radio\" name=\"radio\" value=\"1\" style=\"margin-right: 0.5em;\" checked&gt; Graph 1\n  &lt;/label&gt;\n  &lt;label style=\"margin-right: 1em; display: inline-flex; align-items: center;\"&gt;\n    &lt;input type=\"radio\" name=\"radio\" value=\"2\" style=\"margin-right: 0.5em;\"&gt; Graph 2\n  &lt;/label&gt;\n  &lt;label style=\"margin-right: 1em; display: inline-flex; align-items: center;\"&gt;\n    &lt;input type=\"radio\" name=\"radio\" value=\"3\" style=\"margin-right: 0.5em;\"&gt; Graph 3\n  &lt;/label&gt;\n  &lt;label style=\"margin-right: 1em; display: inline-flex; align-items: center;\"&gt;\n    &lt;input type=\"radio\" name=\"radio\" value=\"4\" style=\"margin-right: 0.5em;\"&gt; Graph 4\n  &lt;/label&gt;\n&lt;/form&gt;`;\n  \n  const graphs = {1: graph1, 2: graph2, 3: graph3, 4: graph4};\n  const timeout = setInterval(() =&gt; {\n    form.value = graphs[form.radio.value = (+form.radio.value) % 4 + 1];\n    form.dispatchEvent(new CustomEvent(\"input\"));\n  }, 2000);\n  \n  form.onchange = () =&gt; form.dispatchEvent(new CustomEvent(\"input\")); // Safari\n  form.oninput = event =&gt; { \n    if (event.isTrusted) clearInterval(timeout), form.onchange = null;\n    form.value = graphs[form.radio.value];\n  };\n  \n  form.value = graphs[form.radio.value];\n  invalidation.then(() =&gt; clearInterval(timeout));\n  \n  return form;\n}\n\n\n\n\nchart2 = {\n  const svg = d3.create(\"svg\")\n      .attr(\"width\", width)\n      .attr(\"height\", height)\n      .attr(\"viewBox\", [-width / 2, -height / 2, width, height]);\n\n  const simulation = d3.forceSimulation()\n      .force(\"charge\", d3.forceManyBody().strength(-1000))\n      .force(\"link\", d3.forceLink().id(d =&gt; d.id).distance(200))\n      .force(\"x\", d3.forceX())\n      .force(\"y\", d3.forceY())\n      .on(\"tick\", ticked);\n\n  let link = svg.append(\"g\")\n      .attr(\"stroke\", \"#000\")\n      .attr(\"stroke-width\", 1.5)\n    .selectAll(\"line\");\n\n  let node = svg.append(\"g\")\n      .attr(\"stroke\", \"#fff\")\n      .attr(\"stroke-width\", 1.5)\n    .selectAll(\"circle\");\n\n  function ticked() {\n    node.attr(\"cx\", d =&gt; d.x)\n        .attr(\"cy\", d =&gt; d.y)\n\n    link.attr(\"x1\", d =&gt; d.source.x)\n        .attr(\"y1\", d =&gt; d.source.y)\n        .attr(\"x2\", d =&gt; d.target.x)\n        .attr(\"y2\", d =&gt; d.target.y);\n  }\n\n  // Terminate the force layout when this cell re-runs.\n  invalidation.then(() =&gt; simulation.stop());\n\n  return Object.assign(svg.node(), {\n    update({nodes, links}) {\n\n      // Make a shallow copy to protect against mutation, while\n      // recycling old nodes to preserve position and velocity.\n      const old = new Map(node.data().map(d =&gt; [d.id, d]));\n      nodes = nodes.map(d =&gt; Object.assign(old.get(d.id) || {}, d));\n      links = links.map(d =&gt; Object.assign({}, d));\n\n      simulation.nodes(nodes);\n      simulation.force(\"link\").links(links);\n      simulation.alpha(1).restart();\n\n      node = node\n        .data(nodes, d =&gt; d.id)\n        .join(enter =&gt; enter.append(\"circle\")\n          .attr(\"r\", 8)\n          .attr(\"fill\", d =&gt; color(d.id)));\n\n      link = link\n        .data(links, d =&gt; `${d.source.id}\\t${d.target.id}`)\n        .join(\"line\");\n    }\n  });\n}\n\n\nupdate = chart2.update(graph)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nChange the graph3 object so that it contains eight nodes called “Life Sciences”, “Physical Sciences”, “Heidi”, “Robyn”, “Konrad”, “Geraline”, “Lucas”, and “Yaotian”. Change the links object to reflect our shared understanding of those links.\n\n\n\nI honestly cannot believe this works! I mean… Hey! Look at this cool interactive network!\n\n\nCode\nchart = ForceGraph(miserables, {\n  nodeId: d =&gt; d.id,\n  nodeGroup: d =&gt; d.group,\n  nodeTitle: d =&gt; `${d.id}\\n${d.group}`,\n  linkStrokeWidth: l =&gt; Math.sqrt(l.value),\n  width,\n  height: 600,\n  invalidation // a promise to stop the simulation when the cell is re-run\n})\n\n\n\n\n\n\n\n\n\nThe first line of code in the chunk below defines the data object from a .json file called miserables.json. Have a look at this file within RStudio. Does the overall structure look familiar?\nCould we possibly replace the stupid data file about a stupid musical with something of our own design???\n\n\nCode\nmiserables = FileAttachment(\"miserables.json\").json()\n\n\n// Copyright 2021 Observable, Inc.\n// Released under the ISC license.\n// https://observablehq.com/@d3/force-directed-graph\nfunction ForceGraph({\n  nodes, // an iterable of node objects (typically [{id}, …])\n  links // an iterable of link objects (typically [{source, target}, …])\n}, {\n  nodeId = d =&gt; d.id, // given d in nodes, returns a unique identifier (string)\n  nodeGroup, // given d in nodes, returns an (ordinal) value for color\n  nodeGroups, // an array of ordinal values representing the node groups\n  nodeTitle, // given d in nodes, a title string\n  nodeFill = \"currentColor\", // node stroke fill (if not using a group color encoding)\n  nodeStroke = \"#fff\", // node stroke color\n  nodeStrokeWidth = 1.5, // node stroke width, in pixels\n  nodeStrokeOpacity = 1, // node stroke opacity\n  nodeRadius = 5, // node radius, in pixels\n  nodeStrength,\n  linkSource = ({source}) =&gt; source, // given d in links, returns a node identifier string\n  linkTarget = ({target}) =&gt; target, // given d in links, returns a node identifier string\n  linkStroke = \"#999\", // link stroke color\n  linkStrokeOpacity = 0.6, // link stroke opacity\n  linkStrokeWidth = 1.5, // given d in links, returns a stroke width in pixels\n  linkStrokeLinecap = \"round\", // link stroke linecap\n  linkStrength,\n  colors = d3.schemeTableau10, // an array of color strings, for the node groups\n  width = 640, // outer width, in pixels\n  height = 400, // outer height, in pixels\n  invalidation // when this promise resolves, stop the simulation\n} = {}) {\n  // Compute values.\n  const N = d3.map(nodes, nodeId).map(intern);\n  const LS = d3.map(links, linkSource).map(intern);\n  const LT = d3.map(links, linkTarget).map(intern);\n  if (nodeTitle === undefined) nodeTitle = (_, i) =&gt; N[i];\n  const T = nodeTitle == null ? null : d3.map(nodes, nodeTitle);\n  const G = nodeGroup == null ? null : d3.map(nodes, nodeGroup).map(intern);\n  const W = typeof linkStrokeWidth !== \"function\" ? null : d3.map(links, linkStrokeWidth);\n  const L = typeof linkStroke !== \"function\" ? null : d3.map(links, linkStroke);\n\n  // Replace the input nodes and links with mutable objects for the simulation.\n  nodes = d3.map(nodes, (_, i) =&gt; ({id: N[i]}));\n  links = d3.map(links, (_, i) =&gt; ({source: LS[i], target: LT[i]}));\n\n  // Compute default domains.\n  if (G && nodeGroups === undefined) nodeGroups = d3.sort(G);\n\n  // Construct the scales.\n  const color = nodeGroup == null ? null : d3.scaleOrdinal(nodeGroups, colors);\n\n  // Construct the forces.\n  const forceNode = d3.forceManyBody();\n  const forceLink = d3.forceLink(links).id(({index: i}) =&gt; N[i]);\n  if (nodeStrength !== undefined) forceNode.strength(nodeStrength);\n  if (linkStrength !== undefined) forceLink.strength(linkStrength);\n\n  const simulation = d3.forceSimulation(nodes)\n      .force(\"link\", forceLink)\n      .force(\"charge\", forceNode)\n      .force(\"center\",  d3.forceCenter())\n      .on(\"tick\", ticked);\n\n  const svg = d3.create(\"svg\")\n      .attr(\"width\", width)\n      .attr(\"height\", height)\n      .attr(\"viewBox\", [-width / 2, -height / 2, width, height])\n      .attr(\"style\", \"max-width: 100%; height: auto; height: intrinsic;\");\n\n  const link = svg.append(\"g\")\n      .attr(\"stroke\", typeof linkStroke !== \"function\" ? linkStroke : null)\n      .attr(\"stroke-opacity\", linkStrokeOpacity)\n      .attr(\"stroke-width\", typeof linkStrokeWidth !== \"function\" ? linkStrokeWidth : null)\n      .attr(\"stroke-linecap\", linkStrokeLinecap)\n    .selectAll(\"line\")\n    .data(links)\n    .join(\"line\");\n\n  const node = svg.append(\"g\")\n      .attr(\"fill\", nodeFill)\n      .attr(\"stroke\", nodeStroke)\n      .attr(\"stroke-opacity\", nodeStrokeOpacity)\n      .attr(\"stroke-width\", nodeStrokeWidth)\n    .selectAll(\"circle\")\n    .data(nodes)\n    .join(\"circle\")\n      .attr(\"r\", nodeRadius)\n      .call(drag(simulation));\n\n  if (W) link.attr(\"stroke-width\", ({index: i}) =&gt; W[i]);\n  if (L) link.attr(\"stroke\", ({index: i}) =&gt; L[i]);\n  if (G) node.attr(\"fill\", ({index: i}) =&gt; color(G[i]));\n  if (T) node.append(\"title\").text(({index: i}) =&gt; T[i]);\n  if (invalidation != null) invalidation.then(() =&gt; simulation.stop());\n\n  function intern(value) {\n    return value !== null && typeof value === \"object\" ? value.valueOf() : value;\n  }\n\n  function ticked() {\n    link\n      .attr(\"x1\", d =&gt; d.source.x)\n      .attr(\"y1\", d =&gt; d.source.y)\n      .attr(\"x2\", d =&gt; d.target.x)\n      .attr(\"y2\", d =&gt; d.target.y);\n\n    node\n      .attr(\"cx\", d =&gt; d.x)\n      .attr(\"cy\", d =&gt; d.y);\n  }\n\n  function drag(simulation) {    \n    function dragstarted(event) {\n      if (!event.active) simulation.alphaTarget(0.3).restart();\n      event.subject.fx = event.subject.x;\n      event.subject.fy = event.subject.y;\n    }\n    \n    function dragged(event) {\n      event.subject.fx = event.x;\n      event.subject.fy = event.y;\n    }\n    \n    function dragended(event) {\n      if (!event.active) simulation.alphaTarget(0);\n      event.subject.fx = null;\n      event.subject.fy = null;\n    }\n    \n    return d3.drag()\n      .on(\"start\", dragstarted)\n      .on(\"drag\", dragged)\n      .on(\"end\", dragended);\n  }\n\n  return Object.assign(svg.node(), {scales: {color}});\n}\n\n\nimport {howto} from \"@d3/example-components\"\n\nimport {Swatches} from \"@d3/color-legend\"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWhat if we replaced the datafile by making our own json file??\n\n\nCode\nlibrary(jsonlite)\n\n\nWarning: package 'jsonlite' was built under R version 4.3.3\n\n\nCode\n# create data frames for nodes and links\nnodes &lt;- data.frame(\n  id = c(\"Barrie\", \"Ronald\", \"Cody\", \"Erick\", \"Jiyin\", \"Cthulhu\"),\n  group = c(1, 1, 1 , 2, 2, 3)\n)\n\nlinks &lt;- data.frame(\n  source = c(\"Barrie\", \"Ronald\", \"Cody\", \"Barrie\", \"Erick\", \"Jiyin\", \"Ronald\"),\n  target = c(\"Cthulhu\", \"Erick\", \"Jiyin\", \"Erick\", \"Cthulhu\", \"Ronald\", \"Cody\"),\n  value = c(1, 8, 10, 6, 1, 1, 1)\n)\n\n# convert data frames to JSON objects\nnodes_json &lt;- toJSON(list(nodes = nodes), pretty = TRUE)\nlinks_json &lt;- toJSON(list(links = links), pretty = TRUE)\n\n# merge JSON objects into one\njson &lt;- paste0( nodes_json, links_json)\n\n# write JSON object to file\nwrite(json, file = \"network_graph2.json\")\n\n\nOh god…. now go back and point the stuff to the stuff…\nAnyway…. here is where I want to go:\nAMAZING"
  },
  {
    "objectID": "posts/NetworkObservable/index.html#example-1-basic-force-directed-graph---me-trying-to-get-something",
    "href": "posts/NetworkObservable/index.html#example-1-basic-force-directed-graph---me-trying-to-get-something",
    "title": "NETWORKS IN OBSERVABLE",
    "section": "",
    "text": "I’m going to start by trying to replicate this observable notebook:\n\n\nCode\ngraph1 = ({\n  nodes: [\n    {id: \"a\"},\n    {id: \"b\"},\n    {id: \"c\"}\n  ],\n  links: []\n})\n\n\ngraph2 = ({\n  nodes: [\n    {id: \"a\"},\n    {id: \"b\"},\n    {id: \"c\"}\n  ],\n  links: [\n    {source: \"a\", target: \"b\"},\n    {source: \"b\", target: \"c\"},\n    {source: \"c\", target: \"a\"}\n  ]\n})\n\n\ngraph3 = ({\n  nodes: [\n    {id: \"a\"},\n    {id: \"b\"}\n  ],\n  links: [\n    {source: \"a\", target: \"b\"}\n  ]\n})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n```{ojs}\ngraph4 = {\n  nodes: [\n    {id: \"Life Sciences\"},\n    {id: \"Physical Sciences\"},\n    {id: \"Heidi\"},\n    {id: \"Robyn\"},\n    {id: \"Konrad\"},\n    {id: \"Geraline\"},\n    {id: \"Lucas\"},\n    {id: \"Yaotian\"}\n  ],\n  links: [\n    {source: \"Life Sciences\", target: \"Physical Sciences\"},\n    {source: \"Life Sciences\", target: \"Heidi\"},\n    {source: \"Physical Sciences\", target: \"Robyn\"},\n    {source: \"Physical Sciences\", target: \"Konrad\"},\n    {source: \"Heidi\", target: \"Geraline\"},\n    {source: \"Heidi\", target: \"Lucas\"},\n    {source: \"Robyn\", target: \"Yaotian\"},\n    {source: \"Lucas\", target: \"Yaotian\"}\n  ]\n};\n\n```\n\n\n\n\n\n\n\nOJS Syntax Error (line 81, column 8)Unexpected token\n\n\n\n\n\n\n\n\n\n\nCode\nviewof graph = {\n  const form = html`&lt;form style=\"font: 12px var(--sans-serif); display: flex; height: 33px; align-items: center;\"&gt;\n  &lt;label style=\"margin-right: 1em; display: inline-flex; align-items: center;\"&gt;\n    &lt;input type=\"radio\" name=\"radio\" value=\"1\" style=\"margin-right: 0.5em;\" checked&gt; Graph 1\n  &lt;/label&gt;\n  &lt;label style=\"margin-right: 1em; display: inline-flex; align-items: center;\"&gt;\n    &lt;input type=\"radio\" name=\"radio\" value=\"2\" style=\"margin-right: 0.5em;\"&gt; Graph 2\n  &lt;/label&gt;\n  &lt;label style=\"margin-right: 1em; display: inline-flex; align-items: center;\"&gt;\n    &lt;input type=\"radio\" name=\"radio\" value=\"3\" style=\"margin-right: 0.5em;\"&gt; Graph 3\n  &lt;/label&gt;\n  &lt;label style=\"margin-right: 1em; display: inline-flex; align-items: center;\"&gt;\n    &lt;input type=\"radio\" name=\"radio\" value=\"4\" style=\"margin-right: 0.5em;\"&gt; Graph 4\n  &lt;/label&gt;\n&lt;/form&gt;`;\n  \n  const graphs = {1: graph1, 2: graph2, 3: graph3, 4: graph4};\n  const timeout = setInterval(() =&gt; {\n    form.value = graphs[form.radio.value = (+form.radio.value) % 4 + 1];\n    form.dispatchEvent(new CustomEvent(\"input\"));\n  }, 2000);\n  \n  form.onchange = () =&gt; form.dispatchEvent(new CustomEvent(\"input\")); // Safari\n  form.oninput = event =&gt; { \n    if (event.isTrusted) clearInterval(timeout), form.onchange = null;\n    form.value = graphs[form.radio.value];\n  };\n  \n  form.value = graphs[form.radio.value];\n  invalidation.then(() =&gt; clearInterval(timeout));\n  \n  return form;\n}\n\n\n\n\nchart2 = {\n  const svg = d3.create(\"svg\")\n      .attr(\"width\", width)\n      .attr(\"height\", height)\n      .attr(\"viewBox\", [-width / 2, -height / 2, width, height]);\n\n  const simulation = d3.forceSimulation()\n      .force(\"charge\", d3.forceManyBody().strength(-1000))\n      .force(\"link\", d3.forceLink().id(d =&gt; d.id).distance(200))\n      .force(\"x\", d3.forceX())\n      .force(\"y\", d3.forceY())\n      .on(\"tick\", ticked);\n\n  let link = svg.append(\"g\")\n      .attr(\"stroke\", \"#000\")\n      .attr(\"stroke-width\", 1.5)\n    .selectAll(\"line\");\n\n  let node = svg.append(\"g\")\n      .attr(\"stroke\", \"#fff\")\n      .attr(\"stroke-width\", 1.5)\n    .selectAll(\"circle\");\n\n  function ticked() {\n    node.attr(\"cx\", d =&gt; d.x)\n        .attr(\"cy\", d =&gt; d.y)\n\n    link.attr(\"x1\", d =&gt; d.source.x)\n        .attr(\"y1\", d =&gt; d.source.y)\n        .attr(\"x2\", d =&gt; d.target.x)\n        .attr(\"y2\", d =&gt; d.target.y);\n  }\n\n  // Terminate the force layout when this cell re-runs.\n  invalidation.then(() =&gt; simulation.stop());\n\n  return Object.assign(svg.node(), {\n    update({nodes, links}) {\n\n      // Make a shallow copy to protect against mutation, while\n      // recycling old nodes to preserve position and velocity.\n      const old = new Map(node.data().map(d =&gt; [d.id, d]));\n      nodes = nodes.map(d =&gt; Object.assign(old.get(d.id) || {}, d));\n      links = links.map(d =&gt; Object.assign({}, d));\n\n      simulation.nodes(nodes);\n      simulation.force(\"link\").links(links);\n      simulation.alpha(1).restart();\n\n      node = node\n        .data(nodes, d =&gt; d.id)\n        .join(enter =&gt; enter.append(\"circle\")\n          .attr(\"r\", 8)\n          .attr(\"fill\", d =&gt; color(d.id)));\n\n      link = link\n        .data(links, d =&gt; `${d.source.id}\\t${d.target.id}`)\n        .join(\"line\");\n    }\n  });\n}\n\n\nupdate = chart2.update(graph)"
  },
  {
    "objectID": "posts/NetworkObservable/index.html#task-1",
    "href": "posts/NetworkObservable/index.html#task-1",
    "title": "NETWORKS IN OBSERVABLE",
    "section": "",
    "text": "Change the graph3 object so that it contains eight nodes called “Life Sciences”, “Physical Sciences”, “Heidi”, “Robyn”, “Konrad”, “Geraline”, “Lucas”, and “Yaotian”. Change the links object to reflect our shared understanding of those links."
  },
  {
    "objectID": "posts/NetworkObservable/index.html#example-2-interactive-force-directed-graph",
    "href": "posts/NetworkObservable/index.html#example-2-interactive-force-directed-graph",
    "title": "NETWORKS IN OBSERVABLE",
    "section": "",
    "text": "I honestly cannot believe this works! I mean… Hey! Look at this cool interactive network!\n\n\nCode\nchart = ForceGraph(miserables, {\n  nodeId: d =&gt; d.id,\n  nodeGroup: d =&gt; d.group,\n  nodeTitle: d =&gt; `${d.id}\\n${d.group}`,\n  linkStrokeWidth: l =&gt; Math.sqrt(l.value),\n  width,\n  height: 600,\n  invalidation // a promise to stop the simulation when the cell is re-run\n})\n\n\n\n\n\n\n\n\n\nThe first line of code in the chunk below defines the data object from a .json file called miserables.json. Have a look at this file within RStudio. Does the overall structure look familiar?\nCould we possibly replace the stupid data file about a stupid musical with something of our own design???\n\n\nCode\nmiserables = FileAttachment(\"miserables.json\").json()\n\n\n// Copyright 2021 Observable, Inc.\n// Released under the ISC license.\n// https://observablehq.com/@d3/force-directed-graph\nfunction ForceGraph({\n  nodes, // an iterable of node objects (typically [{id}, …])\n  links // an iterable of link objects (typically [{source, target}, …])\n}, {\n  nodeId = d =&gt; d.id, // given d in nodes, returns a unique identifier (string)\n  nodeGroup, // given d in nodes, returns an (ordinal) value for color\n  nodeGroups, // an array of ordinal values representing the node groups\n  nodeTitle, // given d in nodes, a title string\n  nodeFill = \"currentColor\", // node stroke fill (if not using a group color encoding)\n  nodeStroke = \"#fff\", // node stroke color\n  nodeStrokeWidth = 1.5, // node stroke width, in pixels\n  nodeStrokeOpacity = 1, // node stroke opacity\n  nodeRadius = 5, // node radius, in pixels\n  nodeStrength,\n  linkSource = ({source}) =&gt; source, // given d in links, returns a node identifier string\n  linkTarget = ({target}) =&gt; target, // given d in links, returns a node identifier string\n  linkStroke = \"#999\", // link stroke color\n  linkStrokeOpacity = 0.6, // link stroke opacity\n  linkStrokeWidth = 1.5, // given d in links, returns a stroke width in pixels\n  linkStrokeLinecap = \"round\", // link stroke linecap\n  linkStrength,\n  colors = d3.schemeTableau10, // an array of color strings, for the node groups\n  width = 640, // outer width, in pixels\n  height = 400, // outer height, in pixels\n  invalidation // when this promise resolves, stop the simulation\n} = {}) {\n  // Compute values.\n  const N = d3.map(nodes, nodeId).map(intern);\n  const LS = d3.map(links, linkSource).map(intern);\n  const LT = d3.map(links, linkTarget).map(intern);\n  if (nodeTitle === undefined) nodeTitle = (_, i) =&gt; N[i];\n  const T = nodeTitle == null ? null : d3.map(nodes, nodeTitle);\n  const G = nodeGroup == null ? null : d3.map(nodes, nodeGroup).map(intern);\n  const W = typeof linkStrokeWidth !== \"function\" ? null : d3.map(links, linkStrokeWidth);\n  const L = typeof linkStroke !== \"function\" ? null : d3.map(links, linkStroke);\n\n  // Replace the input nodes and links with mutable objects for the simulation.\n  nodes = d3.map(nodes, (_, i) =&gt; ({id: N[i]}));\n  links = d3.map(links, (_, i) =&gt; ({source: LS[i], target: LT[i]}));\n\n  // Compute default domains.\n  if (G && nodeGroups === undefined) nodeGroups = d3.sort(G);\n\n  // Construct the scales.\n  const color = nodeGroup == null ? null : d3.scaleOrdinal(nodeGroups, colors);\n\n  // Construct the forces.\n  const forceNode = d3.forceManyBody();\n  const forceLink = d3.forceLink(links).id(({index: i}) =&gt; N[i]);\n  if (nodeStrength !== undefined) forceNode.strength(nodeStrength);\n  if (linkStrength !== undefined) forceLink.strength(linkStrength);\n\n  const simulation = d3.forceSimulation(nodes)\n      .force(\"link\", forceLink)\n      .force(\"charge\", forceNode)\n      .force(\"center\",  d3.forceCenter())\n      .on(\"tick\", ticked);\n\n  const svg = d3.create(\"svg\")\n      .attr(\"width\", width)\n      .attr(\"height\", height)\n      .attr(\"viewBox\", [-width / 2, -height / 2, width, height])\n      .attr(\"style\", \"max-width: 100%; height: auto; height: intrinsic;\");\n\n  const link = svg.append(\"g\")\n      .attr(\"stroke\", typeof linkStroke !== \"function\" ? linkStroke : null)\n      .attr(\"stroke-opacity\", linkStrokeOpacity)\n      .attr(\"stroke-width\", typeof linkStrokeWidth !== \"function\" ? linkStrokeWidth : null)\n      .attr(\"stroke-linecap\", linkStrokeLinecap)\n    .selectAll(\"line\")\n    .data(links)\n    .join(\"line\");\n\n  const node = svg.append(\"g\")\n      .attr(\"fill\", nodeFill)\n      .attr(\"stroke\", nodeStroke)\n      .attr(\"stroke-opacity\", nodeStrokeOpacity)\n      .attr(\"stroke-width\", nodeStrokeWidth)\n    .selectAll(\"circle\")\n    .data(nodes)\n    .join(\"circle\")\n      .attr(\"r\", nodeRadius)\n      .call(drag(simulation));\n\n  if (W) link.attr(\"stroke-width\", ({index: i}) =&gt; W[i]);\n  if (L) link.attr(\"stroke\", ({index: i}) =&gt; L[i]);\n  if (G) node.attr(\"fill\", ({index: i}) =&gt; color(G[i]));\n  if (T) node.append(\"title\").text(({index: i}) =&gt; T[i]);\n  if (invalidation != null) invalidation.then(() =&gt; simulation.stop());\n\n  function intern(value) {\n    return value !== null && typeof value === \"object\" ? value.valueOf() : value;\n  }\n\n  function ticked() {\n    link\n      .attr(\"x1\", d =&gt; d.source.x)\n      .attr(\"y1\", d =&gt; d.source.y)\n      .attr(\"x2\", d =&gt; d.target.x)\n      .attr(\"y2\", d =&gt; d.target.y);\n\n    node\n      .attr(\"cx\", d =&gt; d.x)\n      .attr(\"cy\", d =&gt; d.y);\n  }\n\n  function drag(simulation) {    \n    function dragstarted(event) {\n      if (!event.active) simulation.alphaTarget(0.3).restart();\n      event.subject.fx = event.subject.x;\n      event.subject.fy = event.subject.y;\n    }\n    \n    function dragged(event) {\n      event.subject.fx = event.x;\n      event.subject.fy = event.y;\n    }\n    \n    function dragended(event) {\n      if (!event.active) simulation.alphaTarget(0);\n      event.subject.fx = null;\n      event.subject.fy = null;\n    }\n    \n    return d3.drag()\n      .on(\"start\", dragstarted)\n      .on(\"drag\", dragged)\n      .on(\"end\", dragended);\n  }\n\n  return Object.assign(svg.node(), {scales: {color}});\n}\n\n\nimport {howto} from \"@d3/example-components\"\n\nimport {Swatches} from \"@d3/color-legend\""
  },
  {
    "objectID": "posts/NetworkObservable/index.html#task-2",
    "href": "posts/NetworkObservable/index.html#task-2",
    "title": "NETWORKS IN OBSERVABLE",
    "section": "",
    "text": "What if we replaced the datafile by making our own json file??\n\n\nCode\nlibrary(jsonlite)\n\n\nWarning: package 'jsonlite' was built under R version 4.3.3\n\n\nCode\n# create data frames for nodes and links\nnodes &lt;- data.frame(\n  id = c(\"Barrie\", \"Ronald\", \"Cody\", \"Erick\", \"Jiyin\", \"Cthulhu\"),\n  group = c(1, 1, 1 , 2, 2, 3)\n)\n\nlinks &lt;- data.frame(\n  source = c(\"Barrie\", \"Ronald\", \"Cody\", \"Barrie\", \"Erick\", \"Jiyin\", \"Ronald\"),\n  target = c(\"Cthulhu\", \"Erick\", \"Jiyin\", \"Erick\", \"Cthulhu\", \"Ronald\", \"Cody\"),\n  value = c(1, 8, 10, 6, 1, 1, 1)\n)\n\n# convert data frames to JSON objects\nnodes_json &lt;- toJSON(list(nodes = nodes), pretty = TRUE)\nlinks_json &lt;- toJSON(list(links = links), pretty = TRUE)\n\n# merge JSON objects into one\njson &lt;- paste0( nodes_json, links_json)\n\n# write JSON object to file\nwrite(json, file = \"network_graph2.json\")\n\n\nOh god…. now go back and point the stuff to the stuff…\nAnyway…. here is where I want to go:\nAMAZING"
  },
  {
    "objectID": "posts/MidtermPortfolioPost/Midterm_3.html",
    "href": "posts/MidtermPortfolioPost/Midterm_3.html",
    "title": "BCB 520 - Midterm Portfolio Post",
    "section": "",
    "text": "In this blog post, you will get more insight into how much federal funding is awarded at the University of Idaho (UI) by the following federal agencies: the Department of Energy (DOE), the US Department of Agriculture (NIFA), the National Institute of Health (NIH), and National Science Foundation (NSF). These agencies provide funding to different types/ areas of research (agriculture, engineering, biology, computer science, physics, social science, etc.), and we want to determine how much money is going into these types of research. We also are looking at the timeline trend of how much funding is awarded at UI compared to previous years and if there’s any positive or negative impact. We can also see the longevity of the funding, like how long that funding is available. We also did a comparison between institutions in how much funding is awarded across institutions, we compared UI with Boise State University and Idaho State University. This information will provide a general understanding of where UI stands and how it competes with other institutions in acquiring federal funding from those agencies. By the end of this blog post, you will understand the distribution of awarded federal funding across these agencies."
  },
  {
    "objectID": "posts/MidtermPortfolioPost/Midterm_3.html#preamble",
    "href": "posts/MidtermPortfolioPost/Midterm_3.html#preamble",
    "title": "BCB 520 - Midterm Portfolio Post",
    "section": "",
    "text": "In this blog post, you will get more insight into how much federal funding is awarded at the University of Idaho (UI) by the following federal agencies: the Department of Energy (DOE), the US Department of Agriculture (NIFA), the National Institute of Health (NIH), and National Science Foundation (NSF). These agencies provide funding to different types/ areas of research (agriculture, engineering, biology, computer science, physics, social science, etc.), and we want to determine how much money is going into these types of research. We also are looking at the timeline trend of how much funding is awarded at UI compared to previous years and if there’s any positive or negative impact. We can also see the longevity of the funding, like how long that funding is available. We also did a comparison between institutions in how much funding is awarded across institutions, we compared UI with Boise State University and Idaho State University. This information will provide a general understanding of where UI stands and how it competes with other institutions in acquiring federal funding from those agencies. By the end of this blog post, you will understand the distribution of awarded federal funding across these agencies."
  },
  {
    "objectID": "posts/MidtermPortfolioPost/Midterm_3.html#data",
    "href": "posts/MidtermPortfolioPost/Midterm_3.html#data",
    "title": "BCB 520 - Midterm Portfolio Post",
    "section": "DATA",
    "text": "DATA\nThe data was acquired by the database of each of these federal agencies, the data is open for the public and you can obtain information of currently active/past research projects by institution and principal investigator (PI).\n\nData Dictionary\nThis data dictionary provides an overview of the variables that was used in each individual dataset, along with their descriptions and data types. This will give us more understanding of the structure of the data that was selected and will facilitate in the analysis and the interpretation of how UI stands in means of funding from each individual federal agency.\n\n\nCode\nDataDictionary &lt;- read_xlsx(\"Data Dictionary.xlsx\")\n\nknitr::kable(head(DataDictionary ))\n\n\n\n\n\nVariable\nDescription\nData Type\n\n\n\n\nAward Number\nUnique identifier for the award\nCharacter\n\n\nInstitution\nName of the institution receiving the award\nCharacter\n\n\nPI\nPrincipal Investigator\nCharacter\n\n\nStart Date\nStart date of the award\nDate\n\n\nEnd Date\nEnd date of the award\nDate\n\n\nAmount\nAmount awarded for the project\nNumeric\n\n\n\n\n\n\n\nSummary of Data Sources\nEach of these data sets will provide information in how much money is entering UI. This provide insight, where these funds is being used, like these awarded funding are used to support the activities that are conducted to support the research project, which this is also includes the funding for faculty salaries, graduate student stipends, equipment purchases, and other research-related expenses. This will also help the UI administration to have an overall general idea how these resources are being used and how is benefiting the institution.\n\n\n\n\n\n\nNOTE\n\n\n\nSome of these data sets are long and extensive and it was shorten, for your benefit to be able to visualize how the data table looks like.\n\n\n\nDOE Awards Data (DOEawards.xlsx)\nThis dataset contains information about awards provided by the Department of Energy (DOE).\n\n\nCode\nDOEawardsUI &lt;- read_xlsx(\"DOEawards.xlsx\", .name_repair = \"minimal\")\n\nDOEawardsUI &lt;- read_xlsx(\"DOEawards.xlsx\")\n\nDOEUI_General &lt;- DOEawardsUI %&gt;% \n  dplyr::filter(Institution == 'Regents of the University of Idaho')\n\nDOEUI_New_Awards &lt;- DOEUI_General %&gt;%\n  select(Title, Institution, PI, Status, `Action Type`, `Program Office`, `Start Date`, `End Date`, `Most Recent Award Date`, `Amount Awarded to Date`)\n\nknitr::kable(head(DOEUI_New_Awards))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTitle\nInstitution\nPI\nStatus\nAction Type\nProgram Office\nStart Date\nEnd Date\nMost Recent Award Date\nAmount Awarded to Date\n\n\n\n\nNuclear Theory at the University of Idaho\nRegents of the University of Idaho\nSammarruca, Francesca\nActive\nRenewal\nOffice of Nuclear Physics\n12/01/2021\n11/30/2024\n12/29/2023\n1812000\n\n\nConverting methoxy groups on lignin-derived aromatics from a toxic hurdle to a useful resource: a systems-driven approach\nRegents of the University of Idaho\nMarx, Christopher\nActive\nNew\nOffice of Biological & Environmental Research\n09/01/2021\n08/31/2024\n08/02/2023\n1404162\n\n\nIntegrative Imaging of Plant Roots during Symbiosis with Mycorrhizal Fungi\nRegents of the University of Idaho\nVasdekis, Andreas\nActive\nNew\nOffice of Biological & Environmental Research\n08/15/2021\n08/14/2024\n06/26/2023\n1519359\n\n\nNutrient and Fine Sediment Transport Driven by Perturbations in River Bed Movement\nRegents of the University of Idaho\nYager, Elowyn\nActive\nNew\nOffice of Biological & Environmental Research\n09/01/2020\n08/31/2024\n04/12/2023\n603903\n\n\n\n\n\nCode\nlibrary(readr)\nDOEawardsUI &lt;- suppressMessages(read_xlsx(\"DOEawards.xlsx\"))\n\n\n\n\nUSDA to UI Awards Data (USDAtoUI.csv):\nThis dataset includes awards data related to the University of Idaho (UI) received from the U.S. Department of Agriculture (USDA).\n\n\nCode\nsuppressPackageStartupMessages(library(readxl))\nsuppressPackageStartupMessages(library(dplyr))\nsuppressPackageStartupMessages(library(tidyverse))\n\n\n\n\nCode\nlibrary(tidyverse)\nlibrary(readxl)\nlibrary(knitr)\n\nUSDAUI  &lt;- read.csv(\"USDAtoUI.csv\")\nknitr::kable(head(USDAUI))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAward.Date\nGrant.Number\nProposal.Number\nGrant.Title\nState.Name\nGrantee.Name\nAward.Dollars\nProgram.Name\nProgram.Area.Name\n\n\n\n\n2010-09-30\n2010-48679-01200\nN/A\nN/A\nIDAHO\nSAES - UNIVERSITY OF IDAHO\n7495\nN/A\nN/A\n\n\n2009-09-30\n2009-48679-01200\nN/A\nN/A\nIDAHO\nSAES - UNIVERSITY OF IDAHO\n6813\nN/A\nN/A\n\n\n2008-09-30\n2008-48679-01200\nN/A\nN/A\nIDAHO\nSAES - UNIVERSITY OF IDAHO\n8524\nN/A\nN/A\n\n\n2003-09-30\n2003-48604-01200\nN/A\nN/A\nIDAHO\nSAES - UNIVERSITY OF IDAHO\n1097\nN/A\nN/A\n\n\n2010-09-30\n2010-48024-01200\nN/A\nN/A\nIDAHO\nSAES - UNIVERSITY OF IDAHO\n11997\nN/A\nN/A\n\n\n2009-09-30\n2009-48024-01200\nN/A\nN/A\nIDAHO\nSAES - UNIVERSITY OF IDAHO\n14990\nN/A\nN/A\n\n\n\n\n\nCode\nlibrary(dplyr)\n\n# Assuming 'Date' is the column containing the grant date information\nstart_date &lt;- as.Date(\"2021-01-01\")\nend_date &lt;- as.Date(\"2024-03-15\")\n\nUIgrants_recent_grantsUSDA &lt;- USDAUI %&gt;% \n  filter(Award.Date &gt;= start_date & Award.Date &lt;= end_date) %&gt;%\n  arrange(desc(Award.Date))\n\nlibrary(dplyr)\n\nstart_date &lt;- as.Date(\"2024-01-01\")\nend_date &lt;- as.Date(\"2024-12-31\")\n\nUIgrants_2024_grantsUSDA &lt;- UIgrants_recent_grantsUSDA %&gt;% \n  filter(Award.Date &gt;= start_date & Award.Date &lt;= end_date) %&gt;%\n  summarise(UIgrants_2024_grantsUSDA = n())\n\n\n\n\nNSF UI Awards Data (NSFUI_2.xlsx)\nThis dataset consists of awards data from the National Science Foundation (NSF) received by the University of Idaho (UI).\n\n\nCode\nlibrary(readxl)\nlibrary(dplyr)\nlibrary(tidyverse)\nlibrary(knitr) # Ensure knitr is explicitly loaded for kable()\n\n# Reading the dataset from an Excel file\nNSFUIAwardsActive &lt;- read_xlsx(\"NSFUI_2.xlsx\")\n\n# Selecting specific columns, ensure there are no leading or trailing spaces in column names\nNSFUI_New_Awards_Specific &lt;- NSFUIAwardsActive %&gt;%\n  select(Title, NSFOrganization, StartDate, LastAmendmentDate, EndDate, AwardedAmountToDate)\n\n# Displaying the first few rows in a table format\nknitr::kable(head(NSFUI_New_Awards_Specific))\n\n\n\n\n\n\n\n\n\n\n\n\n\nTitle\nNSFOrganization\nStartDate\nLastAmendmentDate\nEndDate\nAwardedAmountToDate\n\n\n\n\nRII Track-1: Idaho Community-engaged Resilience for Energy-Water Systems (I-CREWS)\nOIA\n08/01/2023\n09/11/2023\n07/31/2028\n$2,099,031.00\n\n\nRII Track-1: Linking Genome to Phenome to Predict Adaptive Responses of Organisms to Changing Landscapes\nOIA\n10/01/2018\n09/07/2022\n03/31/2024\n$20,000,000.00\n\n\nRII Track-2 FEC: Developing a Circular Bio-Based Framework For Architecture, Engineering and Construction Through Additive Manufacturing\nOIA\n10/01/2021\n08/23/2023\n09/30/2025\n$2,999,475.00\n\n\nPhase III IUCRC at University of Idaho: Center for Advanced Forestry Systems\nEEC\n12/15/2019\n03/11/2024\n11/30/2024\n$693,814.00\n\n\nConference: NSF EPSCoR Workshop: Intelligent Manufacturing for Extreme Environments\nOIA\n09/01/2023\n08/17/2023\n08/31/2024\n$99,445.00\n\n\nCollaborative Research: As above so below: Quantifying the role of simultaneous LLSVPs and continents on Earth’s cooling history using numerical simulations of mantle convection\nEAR\n07/01/2023\n06/08/2023\n06/30/2026\n$120,952.00\n\n\n\n\n\n\n\nNIH UI Awards Data (NIHUI_2.xlsx)\nThis dataset contains information about awards received by the University of Idaho (UI) from the National Institutes of Health (NIH).\n\n\nCode\nlibrary(readxl)\nlibrary(dplyr)\nlibrary(tidyverse)\n\nNIHUIAwardsActive &lt;- read_xlsx(\"NIHUI_2.xlsx\")\n\nNIHUI_New_Awards_Specific &lt;- NIHUIAwardsActive %&gt;%\n  select('Project Title', 'Administering IC', 'Award Notice Date', `Opportunity Number`, `Project Number`, `Project Start Date`, `Project End Date`, `Budget Start Date`, `Budget End Date`, 'Total Cost', 'Total Cost (Sub Projects)', 'Funding IC(s)', 'Direct Cost IC', 'InDirect Cost IC', 'Total Cost IC')\n\nknitr::kable(head(NIHUI_New_Awards_Specific))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nProject Title\nAdministering IC\nAward Notice Date\nOpportunity Number\nProject Number\nProject Start Date\nProject End Date\nBudget Start Date\nBudget End Date\nTotal Cost\nTotal Cost (Sub Projects)\nFunding IC(s)\nDirect Cost IC\nInDirect Cost IC\nTotal Cost IC\n\n\n\n\nIdaho INBRE Administrative Core\nNIGMS\n9/18/2023\nPA-20-272\n3P20GM103408-23S4\n9/30/2001\n4/30/2024\n5/1/2023\n4/30/2024\nNA\n848625\nNA\n610878\n237747\nNA\n\n\nCenter for Modeling Complex Interactions\nNIGMS\n9/12/2023\nPA-20-272\n3P20GM104420-09S1\n3/15/2015\n6/30/2025\n7/1/2023\n6/30/2024\n266181\nNA\nNIGMS\n375566\n181166\n266181\n\n\nIdaho INBRE Program\nNIGMS\n9/18/2023\nPA-20-272\n3P20GM103408-23S4\n9/30/2001\n4/30/2024\n5/1/2023\n4/30/2024\n848625\nNA\nNIGMS\n610878\n237747\n848625\n\n\nIdentifying phage-bacteria interactions using a multispecies model\nNIGMS\n8/17/2023\nPAR-19-312\n5P20GM104420-09\n3/15/2015\n6/30/2025\n7/1/2023\n6/30/2024\nNA\n152932\nNA\n106362\n46570\nNA\n\n\nSequence-structure-function relationships in human visual photopigments\nNIGMS\n8/17/2023\nPAR-19-312\n5P20GM104420-09\n3/15/2015\n6/30/2025\n7/1/2023\n6/30/2024\nNA\n156572\nNA\n109348\n47224\nNA\n\n\nIdaho INBRE Administrative Core\nNIGMS\n5/8/2023\nPA-20-272\n3P20GM103408-23S1\n9/30/2001\n4/30/2024\n5/1/2023\n4/30/2024\nNA\n190515\nNA\n165515\n25000\nNA"
  },
  {
    "objectID": "posts/MidtermPortfolioPost/Midterm_3.html#data-visualization-and-analysis",
    "href": "posts/MidtermPortfolioPost/Midterm_3.html#data-visualization-and-analysis",
    "title": "BCB 520 - Midterm Portfolio Post",
    "section": "DATA VISUALIZATION AND ANALYSIS",
    "text": "DATA VISUALIZATION AND ANALYSIS\nThe following visualizations is going to help us visualize UI’s longevity and distribution of the university’s portfolio of current and past awards. It will helps us identify if there are awards that are nearing their expiration.Also, will be doing a comparison with UI between two peer institutions: Boise State University and Idaho State University. This will help us understand UI’s performance in securing federal funding, and how those it measures up against to the other institutions within the same region.\n\nUniversity of Idaho - Current and Future Portfolio\nI am creating visualization that will displays the active awards from each sponsor, including their start and end dates, the amount of the award, and the name of the Principal Investigator. This will provide insights of the longevity of the University of Idaho current portfolio of awards. This will also help us identify what awards are near expiration, and which one ones has a longer duration, and to identify if any of these patterns may differ across federal agencies. Ultimately, these visualizations will provide an aid to have an understanding of the sustainability of UIs funding from different federal agencies.\nIn our first visualization (Figure 1), its a general overview of the longevity of our current active awards. By, looking at this Timeline chart, we can easily point out that our NSF awards has the longest longevity (meaning we will have funding until 2028). Looking at NIH and DOE awards timeline their awards are ending in the year 2024, that is something to keep in mind and following up with the PIs that have those funding to see if they applied for new grants.\nUSDA data was not added in this timeline chart because it didn’t provide an end date of their current active awards, so for this time of grant will be analyzed and visualized differently\n\n\nCode\nlibrary(readxl)\nlibrary(dplyr)\nlibrary(ggplot2)\n\nQ1_Data &lt;- read_xlsx(\"Q1_Compilled_Data.xlsx\")\n\n# Convert StartDate and EndDate to Date objects\nQ1_Data$StartDate &lt;- as.Date(Q1_Data$StartDate, format = \"%m/%d/%Y\")\nQ1_Data$EndDate &lt;- as.Date(Q1_Data$EndDate, format = \"%m/%d/%Y\")\n\n# Filter out rows with NA values in StartDate or EndDate\nQ1_Data &lt;- Q1_Data[complete.cases(Q1_Data$StartDate, Q1_Data$EndDate), ]\n\n# Create the Gantt chart\n# Create the Gantt chart\nggplot(Q1_Data, aes(y = Sponsor, x = StartDate, xend = EndDate, yend = Sponsor)) +\n  geom_segment(size = 10, color = \"black\") +  # Use linewidth instead of size\n  scale_x_date(date_breaks = \"1 year\", date_labels = \"%Y\", limits = c(as.Date(\"2021-01-01\"), as.Date(\"2029-01-01\"))) +\n  labs(title = \"Active Awards Timeline\",\n       x = \"Timeline\",\n       y = \"Sponsor\") +\n  theme_minimal() +\n  theme(legend.position = \"bottom\")\n\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\nWarning: Removed 6 rows containing missing values (`geom_segment()`).\n\n\n\n\n\nFigure 1: Active Awards at UI. This Gantt Chart provides information of the longevity of the current awards that are at UI.\nThe previous visualization (Figure 1) was just an overview of the longevity of the current awards that are at UI. The following visualizations, we can see the active awards by sponsor and Principal Investigator (PI). By looking at these visualization we can determine the longevity of their active awards and compare/contrast between sponsors. By looking at these three visualizations (Figure 1, Figure 2, Figure 3), at a glance we can observe that we have more active awards in NSF compared to NIH and DOE, and these NSF awards has a longer end date by 2028, but still we some awards that ends in between 2024/2025 (like for the DOE and NIH awards).\nBy looking at these visualizations, we can say that for the sponsor DOE, we have only 4 current PIs that have active awards (their expiration date is in late 2024). Which comes to a concern, because why PIs are not applying for awards at DOE, it is something to look into. Like, look for information what the DOE asks to apply for their awards, and also talk to those current PIs at UI, to have their perspective and how can we expand the university’s portfolio this specific sponsor. For the NIH and NSF awards, we have an active flow of awards, but still we have to look into those awards that are to be expired, and what are the plans from those current PIs.\n\n\nCode\nlibrary(ggplot2)\nlibrary(readxl)\nlibrary(dplyr)\nlibrary(lubridate)\n\n# Read the data\nQ1_Data_PI &lt;- read_xlsx(\"Q1_Compilled_Data.xlsx\")\n\n# Filter the data for DOE sponsor\nQ1_PI_DOE &lt;- Q1_Data_PI %&gt;%\n  filter(Sponsor == \"DOE\")\n\n# Convert StartDate and EndDate to Date objects\nQ1_PI_DOE$StartDate &lt;- as.Date(Q1_PI_DOE$StartDate, format = \"%m/%d/%Y\")\nQ1_PI_DOE$EndDate &lt;- as.Date(Q1_PI_DOE$EndDate, format = \"%m/%d/%Y\")\n\n# Filter out rows with NA values in StartDate or EndDate\nQ1_PI_DOE &lt;- Q1_PI_DOE[complete.cases(Q1_PI_DOE$StartDate, Q1_PI_DOE$EndDate), ]\n\n# Create the Gantt chart\nggplot(Q1_PI_DOE, aes(y = PI, x = StartDate, xend = EndDate, yend = PI)) +\n  geom_segment(size = 5, color = \"darkgrey\") +\n  scale_x_date(date_breaks = \"1 year\", date_labels = \"%Y\") +\n  labs(title = \"Active Awards Timeline by PI\",\n       x = \"Timeline\",\n       y = \"Principal Investigator\") +\n  theme_minimal() +\n  theme(legend.position = \"bottom\",\n        plot.title = element_text(hjust = 0.5))  # Set horizontal justification to center\n\n\n\n\n\nFigure 2: Active Award by PI (DOE). This Gantt Chart provides information of the longevity of the current awards that are at UI by PI for DOE.\n\n\nCode\nlibrary(ggplot2)\nlibrary(readxl)\nlibrary(dplyr)\nlibrary(lubridate)\n\n# Read the data\nQ1_Data_PI &lt;- read_xlsx(\"Q1_Compilled_Data.xlsx\")\n\n# Filter the data for DOE sponsor\nQ1_PI_NIH &lt;- Q1_Data_PI %&gt;%\n  filter(Sponsor == \"NIH\")\n\n# Convert StartDate and EndDate to Date objects\nQ1_PI_NIH$StartDate &lt;- as.Date(Q1_PI_NIH$StartDate, format = \"%m/%d/%Y\")\nQ1_PI_NIH$EndDate &lt;- as.Date(Q1_PI_NIH$EndDate, format = \"%m/%d/%Y\")\n\n# Filter out rows with NA values in StartDate or EndDate\nQ1_PI_NIH &lt;- Q1_PI_NIH[complete.cases(Q1_PI_NIH$StartDate, Q1_PI_NIH$EndDate), ]\n\n# Create the Gantt chart\nggplot(Q1_PI_NIH, aes(y = PI, x = StartDate, xend = EndDate, yend = PI)) +\n  geom_segment(size = 5, color = \"black\") +\n  scale_x_date(date_breaks = \"1 year\", date_labels = \"%Y\") +\n  labs(title = \"Active Awards Timeline by PI\",\n       x = \"Timeline\",\n       y = \"Principal Investigator\") +\n  theme_minimal() +\n  theme(legend.position = \"bottom\",\n        plot.title = element_text(hjust = 0.5))  # Set horizontal justification to center\n\n\n\n\n\nFigure 3:Active Award by PI (NIH). This Gantt Chart provides information of the longevity of the current awards that are at UI by PI for NIH.\n\n\nCode\nlibrary(ggplot2)\nlibrary(readxl)\nlibrary(dplyr)\nlibrary(lubridate)\n\n# Read the data\nQ1_Data_PI &lt;- read_xlsx(\"Q1_Compilled_Data.xlsx\")\n\n# Filter the data for DOE sponsor\nQ1_PI_NSF &lt;- Q1_Data_PI %&gt;%\n  filter(Sponsor == \"NSF\")\n\n# Convert StartDate and EndDate to Date objects\nQ1_PI_NSF$StartDate &lt;- as.Date(Q1_PI_NSF$StartDate, format = \"%m/%d/%Y\")\nQ1_PI_NSF$EndDate &lt;- as.Date(Q1_PI_NSF$EndDate, format = \"%m/%d/%Y\")\n\n# Filter out rows with NA values in StartDate or EndDate\nQ1_PI_NSF &lt;- Q1_PI_NSF[complete.cases(Q1_PI_NSF$StartDate, Q1_PI_NSF$EndDate), ]\n\n# Create the Gantt chart with adjusted y-axis labels\nggplot(Q1_PI_NSF, aes(y = PI, x = StartDate, xend = EndDate, yend = PI)) +\n  geom_segment(size = 5, color = \"gold\") +\n  scale_x_date(date_breaks = \"1 year\", date_labels = \"%Y\") +\n  labs(title = \"Active Awards Timeline by PI\",\n       x = \"Timeline\",\n       y = \"Principal Investigator\") +\n  theme_minimal() +\n  theme(legend.position = \"bottom\",\n        plot.title = element_text(hjust = 0.5),\n        axis.text.y = element_text(size = 6))  # Reduce the size of y-axis labels\n\n\n\n\n\nFigure 4Active Award by PI (NSF). This Gantt Chart provides information of the longevity of the current awards that are at UI by PI for NSF.\nFor the following visualizations, is going to show the total of award money of each of the sponsors. On Figure 3 we have a bar chart representing each of the sponsors and in the y axis we have the total of award money in millions. By looking at this graph we can say that NSF has the highest amount of award of our current active awards, and the least amount of awarded money is from the DOE, which is to be expected because we don’t have many active award from them.\n\n\nCode\nlibrary(ggplot2)\nlibrary(scales)  # For formatting labels\n\n\n\nAttaching package: 'scales'\n\n\nThe following object is masked from 'package:purrr':\n\n    discard\n\n\nThe following object is masked from 'package:readr':\n\n    col_factor\n\n\nCode\n# Read the data\nQ1_Data_Amount &lt;- read_xlsx(\"Q1_Compilled_Data_4.xlsx\")\n\n# Convert Amount to numeric\nQ1_Data_Amount$Amount &lt;- as.numeric(Q1_Data_Amount$Amount)\n\n\nWarning: NAs introduced by coercion\n\n\nCode\n# Check if there are any non-numeric values in Amount\nnon_numeric &lt;- Q1_Data_Amount[!is.na(as.numeric(Q1_Data_Amount$Amount)), ]\n\n# Check the structure of the Amount variable\nstr(Q1_Data_Amount$Amount)\n\n\n num [1:126] 0 266181 848625 0 0 ...\n\n\nCode\n# Define colors for each sponsor\nsponsor_colors &lt;- c(\"DOE\" = \"darkgray\", \"NSF\" = \"gold\", \"NIH\" = \"black\", \"USDA\" = \"lightgray\")\n\n# Create the bar plot with colors assigned to each sponsor\nggplot(Q1_Data_Amount, aes(x = Sponsor, y = Amount, fill = Sponsor)) +\n  geom_bar(stat = \"summary\", fun = \"sum\") +\n  labs(title = \"Total Amount by Sponsor\",\n       x = \"Sponsor\",\n       y = \"Total Amount (Millions)\") +\n  scale_y_continuous(labels = scales::unit_format(unit = \"M\")) +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1),\n        plot.title = element_text(hjust = 0.5)) +  # Adjust title alignment\n  scale_fill_manual(values = sponsor_colors)  # Use manually defined colors for each sponsor\n\n\nWarning: Removed 51 rows containing non-finite values (`stat_summary()`).\n\n\n\n\n\nFigure 5: Total Amount of Award in Curent Active Award from each Sponsor\nFigure 6 is going to show the total of award money of each of the sponsors by each PI at UI. In this bar chart representing each of the sponsors, in the y axis we have the total of award money in millions, and in the x axis are the PIs that currently have funding from those sponsor. This will provide information how much funding is awarded to each PI for their research project. Knowing this type of information, you will now if that lab has funding to purchase materials, equipment, stipend for graduate/undergraduate for conducting research in their lab and also provide salary for their research technician or post-docs. The highest funding that we have is from NSF from a specific PI, and the following is NIH, for USDA the data is not presented, because in their data set doesn’t provide the list of the PIs.\n\n\nCode\n# Convert Amount to numeric\nQ1_Data$Amount &lt;- as.numeric(Q1_Data$Amount)\n\n\nWarning: NAs introduced by coercion\n\n\nCode\n# Define colors for each sponsor\nsponsor_colors &lt;- c(\"DOE\" = \"darkgray\", \"NSF\" = \"gold\", \"NIH\" = \"black\")\n\n# Create the bar plot with PI on the x-axis and filled bars by Sponsor\nggplot(Q1_Data, aes(x = PI, y = Amount, fill = Sponsor)) +\n  geom_bar(stat = \"summary\", fun = \"sum\") +\n  labs(title = \"Total Amount by PI and Sponsor\",\n       x = \"Principal Investigator\",\n       y = \"Total Amount (Millions)\") +\n  scale_y_continuous(labels = scales::unit_format(unit = \"M\")) +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1, size = 8),  # Adjust font size\n        plot.title = element_text(hjust = 0.5)) +  # Adjust title alignment\n  scale_fill_manual(values = sponsor_colors)  # Use manually defined colors for each sponsor\n\n\nWarning: Removed 51 rows containing non-finite values (`stat_summary()`).\n\n\n\n\n\nFigure 6:Total Amount of Award in Current Active Award from each Sponsor by PIs\n\n\nUniversity of Idaho - Past Portfolio (10 Years)\nWe already saw the current/future portfolio of UI, now lets see how was the performance of UI from the past 10 years. The reason that I am doing these specific visualization is to have a representation of new awards over the past 10 years. By doing this, we can identify trends that may lead to positive and/or negative developments in terms of UIs funding sponsors.By observing these trends, if we have an increasing of awards indicates a positive support from those sponsors, while if we have decrease of awards indicates a negative support from those sponsors, and we have to look more in detail why is there that decline and find solutions to improve in achieving acquiring awards from those sponsors.\nIn our first visualization (Figure 7), we can see the performance of UI for the past 10 years. This will provide an understanding of how UI performed in the past compared to our current standing. By looking at the graph we can say that the sponsor USDA has had the highest number of awards compared from the other sponsors, but looking at Figure 8 we can see that the USDA doesn’t bring the highest total amount of awarded money in that case is NSF across the past 10 years. Meaning we may have a lot of grants coming from USDA but the awarded money is not the same as a grant from NSF. Now focusing on FIGURE 8, like I mention NSF is the highest in the total amount that is being award but across these 10 years there’s has been like an up and down, especially in 2019 and 2022 has the highest funding compared to the following years.\n\n\nCode\n# Read the Excel file\nDOEawardsUI_Dates &lt;- read_xlsx(\"DOEawards.xlsx\")\n\n\nNew names:\n• `` -&gt; `...27`\n\n\nCode\nfiltered_data_UI_DOE &lt;- DOEawardsUI_Dates %&gt;%\n  filter(Institution == 'Regents of the University of Idaho')\n\n# Assuming the start date column is named \"Start_Date\"\nten_years_ago &lt;- Sys.Date() - years(10)  # \n\n# Filter the data to include only awards that\nfiltered_data_UI_10y_DOE &lt;- filtered_data_UI_DOE %&gt;%\n  filter(`Start Date` &gt;= ten_years_ago)\n\n#USDA\n\n# Read the Excel file\nUSDAawardsUI_Dates &lt;- read_xlsx(\"USDAtoUI_Edited_YR.xlsx\")\n\nfiltered_data_UI_USDA &lt;- USDAawardsUI_Dates %&gt;%\n  filter(Institution == 'University of Idaho')\n\n# Assuming the start date column is named \"Start_Date\"\nten_years_ago &lt;- Sys.Date() - years(10)  # \n\n# Filter the data to include only awards that\nfiltered_data_UI_10y_USDA &lt;- filtered_data_UI_USDA %&gt;%\n  filter(`Award Date` &gt;= ten_years_ago)\n\n#NIH\n\n# Read the Excel file\nNIHawardsUI_Dates &lt;- read_xlsx(\"UI_NIH_ALL_YR.xlsx\")\n\nfiltered_data_UI_NIH &lt;- NIHawardsUI_Dates %&gt;%\n  filter(Institution == 'UNIVERSITY OF IDAHO')\n\n# Assuming the start date column is named \"Start_Date\"\nten_years_ago &lt;- Sys.Date() - years(10)  # \n\n# Filter the data to include only awards that\n# Assuming the date format is Month/Day/Year\nfiltered_data_UI_10y_NIH &lt;- filtered_data_UI_NIH %&gt;%\n  filter(as.Date(`Project Start Date`, format = \"%m/%d/%Y\") &gt;= ten_years_ago)\n\n#NSF\n# Read the Excel file\nNSFawardsUI_Dates &lt;- read_xlsx(\"NSF_ALL_YR.xlsx\")\n\nfiltered_data_UI_NSF &lt;- NSFawardsUI_Dates %&gt;%\n  filter(Institution == 'University of Idaho')\n\n# Assuming the start date column is named \"Start_Date\"\nten_years_ago &lt;- Sys.Date() - years(10)  # \n\n# Filter the data to include only awards that\n# Assuming the date format is Month/Day/Year\nfiltered_data_UI_10y_NSF &lt;- filtered_data_UI_NSF %&gt;%\n  filter(as.Date(StartDate, format = \"%m/%d/%Y\") &gt;= ten_years_ago)\n\n# Assuming the column names for \"Start Date\" vary across datasets, replace \"Start Date\" with the actual column name for each dataset.\n\n# For DOE dataset\nfiltered_data_UI_10y_DOE &lt;- filtered_data_UI_10y_DOE %&gt;%\n  mutate(Start_Date = as.Date(`Start Date`, format = \"Start Date\"))\n\n# For USDA dataset\nfiltered_data_UI_10y_USDA &lt;- filtered_data_UI_10y_USDA %&gt;%\n  mutate(Start_Date = as.Date(`Award Date`, format = \"Award Date\"))\n\n# For NIH dataset\nfiltered_data_UI_10y_NIH &lt;- filtered_data_UI_10y_NIH %&gt;%\n  mutate(Start_Date = as.Date(`Project Start Date`, format = \"Project Start Date\"))\n\n# For NSF dataset\nfiltered_data_UI_10y_NSF &lt;- filtered_data_UI_10y_NSF %&gt;%\n  mutate(Start_Date = as.Date(StartDate, format = \"StartDate\"))\n\n# Count the number of awards by award date for each dataset\naward_counts_DOE &lt;- filtered_data_UI_10y_DOE %&gt;%\n  count(`Start Date`)\n\naward_counts_USDA &lt;- filtered_data_UI_10y_USDA %&gt;%\n  count(`Award Date`)\n\naward_counts_NIH &lt;- filtered_data_UI_10y_NIH %&gt;%\n  count(`Project Start Date`)\n\naward_counts_NSF &lt;- filtered_data_UI_10y_NSF %&gt;%\n  count(StartDate)\n\n# Add Sponsor column to each data frame\naward_counts_DOE &lt;- award_counts_DOE %&gt;% mutate(Sponsor = \"DOE\")\naward_counts_USDA &lt;- award_counts_USDA %&gt;% mutate(Sponsor = \"USDA\")\naward_counts_NIH &lt;- award_counts_NIH %&gt;% mutate(Sponsor = \"NIH\")\naward_counts_NSF &lt;- award_counts_NSF %&gt;% mutate(Sponsor = \"NSF\")\n\n# For DOE dataset\naward_counts_DOE &lt;- award_counts_DOE %&gt;%\n  rename(Start_Date = `Start Date`) %&gt;%\n  mutate(Sponsor = \"DOE\")\n\n# For USDA dataset\naward_counts_USDA &lt;- award_counts_USDA %&gt;%\n  rename(Start_Date = `Award Date`) %&gt;%\n  mutate(Sponsor = \"USDA\")\n\n# For NIH dataset\naward_counts_NIH &lt;- award_counts_NIH %&gt;%\n  rename(Start_Date = `Project Start Date`) %&gt;%\n  mutate(Sponsor = \"NIH\")\n\n# For NSF dataset\naward_counts_NSF &lt;- award_counts_NSF %&gt;%\n  rename(Start_Date = StartDate) %&gt;%\n  mutate(Sponsor = \"NSF\")\n\n# For DOE dataset\naward_counts_DOE &lt;- award_counts_DOE %&gt;%\n  mutate(Start_Date = as.Date(Start_Date, format = \"%m/%d/%Y\")) %&gt;%\n  mutate(Sponsor = \"DOE\")\n\n# For USDA dataset\naward_counts_USDA &lt;- award_counts_USDA %&gt;%\n  mutate(Start_Date = as.Date(Start_Date, format = \"%m/%d/%Y\")) %&gt;%\n  mutate(Sponsor = \"USDA\")\n\n# For NIH dataset\naward_counts_NIH &lt;- award_counts_NIH %&gt;%\n  mutate(Start_Date = as.Date(Start_Date, format = \"%m/%d/%Y\")) %&gt;%\n  mutate(Sponsor = \"NIH\")\n\n# For NSF dataset\naward_counts_NSF &lt;- award_counts_NSF %&gt;%\n  mutate(Start_Date = as.Date(Start_Date, format = \"%m/%d/%Y\")) %&gt;%\n  mutate(Sponsor = \"NSF\")\n\n\n# Combine all dataframes into a single dataframe\nall_award_counts &lt;- bind_rows(\n  award_counts_DOE,\n  award_counts_USDA,\n  award_counts_NIH,\n  award_counts_NSF\n)\n\n# Define colors for each sponsor\nsponsor_colors &lt;- c(\"DOE\" = \"darkgray\", \"NSF\" = \"gold\", \"NIH\" = \"black\", \"USDA\" = \"lightgray\")\n\n# Plot the timeline with overlapping lines, adjusted x-axis labels, individual colors, and centralized title\nggplot(all_award_counts, aes(x = Start_Date, color = Sponsor, group = Sponsor)) +\n  geom_freqpoly(binwidth = 30, size = 1) +\n  labs(title = \"Awards Timeline by Sponsor\",\n       x = \"Start Date\",\n       y = \"Count\") +\n  scale_x_date(date_breaks = \"1 year\", date_labels = \"%Y\", expand = c(0, 0)) +\n  scale_color_manual(values = sponsor_colors) +\n  theme_minimal() +\n  theme(\n    plot.title = element_text(hjust = 0.5)\n  )\n\n\n\n\n\nFigure 7: Performance of UI from the past 10 years on total amount of awards\n\n\nCode\n# Read the Excel file\nDOEawardsUI_Dates &lt;- read_xlsx(\"DOEawards.xlsx\")\n\n\nNew names:\n• `` -&gt; `...27`\n\n\nCode\nfiltered_data_UI_DOE &lt;- DOEawardsUI_Dates %&gt;%\n  filter(Institution == 'Regents of the University of Idaho')\n\n# Assuming the start date column is named \"Start_Date\"\nten_years_ago &lt;- Sys.Date() - years(10)  # \n\n# Filter the data to include only awards that\nfiltered_data_UI_10y_DOE &lt;- filtered_data_UI_DOE %&gt;%\n  filter(`Start Date` &gt;= ten_years_ago)\n\n#USDA\n\n# Read the Excel file\nUSDAawardsUI_Dates &lt;- read_xlsx(\"USDAtoUI_Edited_YR.xlsx\")\n\nfiltered_data_UI_USDA &lt;- USDAawardsUI_Dates %&gt;%\n  filter(Institution == 'University of Idaho')\n\n# Assuming the start date column is named \"Start_Date\"\nten_years_ago &lt;- Sys.Date() - years(10)  # \n\n# Filter the data to include only awards that\nfiltered_data_UI_10y_USDA &lt;- filtered_data_UI_USDA %&gt;%\n  filter(`Award Date` &gt;= ten_years_ago)\n\n#NIH\n\n# Read the Excel file\nNIHawardsUI_Dates &lt;- read_xlsx(\"UI_NIH_ALL_YR.xlsx\")\n\nfiltered_data_UI_NIH &lt;- NIHawardsUI_Dates %&gt;%\n  filter(Institution == 'UNIVERSITY OF IDAHO')\n\n# Assuming the start date column is named \"Start_Date\"\nten_years_ago &lt;- Sys.Date() - years(10)  # \n\n# Filter the data to include only awards that\n# Assuming the date format is Month/Day/Year\nfiltered_data_UI_10y_NIH &lt;- filtered_data_UI_NIH %&gt;%\n  filter(as.Date(`Project Start Date`, format = \"%m/%d/%Y\") &gt;= ten_years_ago)\n\n#NSF\n# Read the Excel file\nNSFawardsUI_Dates &lt;- read_xlsx(\"NSF_ALL_YR.xlsx\")\n\nfiltered_data_UI_NSF &lt;- NSFawardsUI_Dates %&gt;%\n  filter(Institution == 'University of Idaho')\n\n# Assuming the start date column is named \"Start_Date\"\nten_years_ago &lt;- Sys.Date() - years(10)  # \n\n# Filter the data to include only awards that\n# Assuming the date format is Month/Day/Year\nfiltered_data_UI_10y_NSF &lt;- filtered_data_UI_NSF %&gt;%\n  filter(as.Date(StartDate, format = \"%m/%d/%Y\") &gt;= ten_years_ago)\n\n# Remove dollar signs ($) and commas (,) from numeric columns\nfiltered_data_UI_10y_NSF &lt;- filtered_data_UI_10y_NSF %&gt;%\n  mutate(AwardedAmountToDate = as.numeric(gsub(\"[\\\\$,]\", \"\", AwardedAmountToDate)))\n\n\n# Sum the total amount by start date for each sponsor\namount_sum_DOE &lt;- filtered_data_UI_10y_DOE %&gt;%\n  group_by(`Start Date`) %&gt;%\n  summarize(Total_Amount = sum(`Amount Awarded to Date`))\n\namount_sum_USDA &lt;- filtered_data_UI_10y_USDA %&gt;%\n  group_by(`Award Date`) %&gt;%\n  summarize(Total_Amount = sum(`Award Dollars`))\n\namount_sum_NIH &lt;- filtered_data_UI_10y_NIH %&gt;%\n  group_by(`Project Start Date`) %&gt;%\n  summarize(Total_Amount = sum(`Total Cost`))\n\namount_sum_NSF &lt;- filtered_data_UI_10y_NSF %&gt;%\n  group_by(StartDate) %&gt;%\n  summarize(Total_Amount = sum(AwardedAmountToDate))\n\n# Add Sponsor column to each data frame\namount_sum_DOE &lt;- amount_sum_DOE %&gt;% mutate(Sponsor = \"DOE\")\namount_sum_USDA &lt;- amount_sum_USDA %&gt;% mutate(Sponsor = \"USDA\")\namount_sum_NIH &lt;- amount_sum_NIH %&gt;% mutate(Sponsor = \"NIH\")\namount_sum_NSF &lt;- amount_sum_NSF %&gt;% mutate(Sponsor = \"NSF\")\n\n# For DOE dataset\namount_sum_DOE &lt;- amount_sum_DOE %&gt;%\n  rename(Start_Date = `Start Date`) %&gt;%\n  mutate(Sponsor = \"DOE\")\n\n# For USDA dataset\namount_sum_USDA &lt;- amount_sum_USDA %&gt;%\n  rename(Start_Date = `Award Date`) %&gt;%\n  mutate(Sponsor = \"USDA\")\n\n# For NIH dataset\namount_sum_NIH &lt;- amount_sum_NIH  %&gt;%\n  rename(Start_Date = `Project Start Date`) %&gt;%\n  mutate(Sponsor = \"NIH\")\n\n# For NSF dataset\namount_sum_NSF &lt;- amount_sum_NSF %&gt;%\n  rename(Start_Date = StartDate) %&gt;%\n  mutate(Sponsor = \"NSF\")\n\n# Assuming Start_Date is in character format, convert it to datetime\namount_sum_DOE &lt;- amount_sum_DOE %&gt;%\n  mutate(Start_Date = as.Date(Start_Date, format = \"%m/%d/%Y\"))\n\namount_sum_USDA &lt;- amount_sum_USDA %&gt;%\n  mutate(Start_Date = as.Date(Start_Date, format = \"%m/%d/%Y\"))\n\namount_sum_NIH &lt;- amount_sum_NIH %&gt;%\n  mutate(Start_Date = as.Date(Start_Date, format = \"%m/%d/%Y\"))\n\namount_sum_NSF &lt;- amount_sum_NSF %&gt;%\n  mutate(Start_Date = as.Date(Start_Date, format = \"%m/%d/%Y\"))\n\n# Combine the data frames\nall_amount_sum &lt;- bind_rows(\n  amount_sum_DOE %&gt;% mutate(Sponsor = \"DOE\"),\n  amount_sum_USDA %&gt;% mutate(Sponsor = \"USDA\"),\n  amount_sum_NIH %&gt;% mutate(Sponsor = \"NIH\"),\n  amount_sum_NSF %&gt;% mutate(Sponsor = \"NSF\")\n)\n\n# Define colors for each sponsor\nsponsor_colors &lt;- c(\"DOE\" = \"darkgray\", \"NSF\" = \"gold\", \"NIH\" = \"black\", \"USDA\" = \"lightgray\")\n\nlibrary(scales)\n\n# Plot the timeline with overlapping lines, adjusted x-axis labels, individual colors, and centralized title\nggplot(all_amount_sum, aes(x = Start_Date, y = Total_Amount / 1e6, color = Sponsor, group = Sponsor)) +\n  geom_line(size = 1) +\n  labs(title = \"Awards Timeline by Sponsor - Total Amount\",\n       x = \"Start Date\",\n       y = \"Total Amount (Millions)\") +\n  scale_x_date(date_breaks = \"1 year\", date_labels = \"%Y\", expand = c(0, 0)) +\n  scale_y_continuous(labels = scales::unit_format(unit = \"M\")) +\n  scale_color_manual(values = sponsor_colors) +\n  theme_minimal() +\n  theme(\n    plot.title = element_text(hjust = 0.5)\n  )\n\n\nWarning: Removed 1 row containing missing values (`geom_line()`).\n\n\n\n\n\nFigure 8:Performance of UI from the past 10 years of total of amount money awarded\n\n\nComparison Between Peers Institutions\nWe already saw how UI is performing with these sponsors, but now lest compare with the following peer institutions: Boise State University and Idaho State University. The aim for the following visualizations is to understand how UIs performance in securing awards, conducting research, and acquiring funding measures up against similar institutions in the region or within the same academic field.\n\n\n\n\n\n\nNOTE\n\n\n\nThe following data sets are from the institutions of Boise State University and Idaho State University, the data set from University of Idaho is already been presented at the beginning of the blog post. Also, these data sets are long and extensive and it was shorten, for your benefit to be able to visualize how the data table looks like.\n\n\n\nBoise State University - Data Sources\nDepartment of Agriculture (NIFA)\n\n\nCode\nBSUUSDA  &lt;- read.csv(\"USDABSU.csv\")\nknitr::kable(head(BSUUSDA,4))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAward.Date\nGrant.Number\nProposal.Number\nGrant.Title\nState.Name\nGrantee.Name\nAward.Dollars\nProgram.Name\nProgram.Area.Name\n\n\n\n\n2003-11-14\n2004-35302-14138\n2003-01470\nHost Selection Decisions and Mass Colonization in the Douglas-Fir Beetle, Dendroctonus Pseudotsugae (Coleoptera: Scolytidae)\nIDAHO\nBOISE STATE UNIVERSITY\n70000\nOrganismal & Population Biology of Arthropods & Nematodes\nNational Research Initiative Competitive Grants Program\n\n\n2003-08-13\n2003-35101-13682\n2003-01569\nThe Effects of Wildfire on Trophic Structure and Food Web Dynamics in Stream Ecosystems\nIDAHO\nBOISE STATE UNIVERSITY\n66867\nManaged Ecosystems\nNational Research Initiative Competitive Grants Program\n\n\n2004-07-22\n2004-35102-14802\n2004-00882\nUtilizing Ground-Penetrating Radar and Solute Tracer Experiments to Determine the Extent of the Hyporheic Zone in Mountain Streams\nIDAHO\nBOISE STATE UNIVERSITY\n83489\nWater and Watersheds\nNational Research Initiative Competitive Grants Program\n\n\n2006-07-24\n2006-35101-17430\n2006-01372\nUnderstanding Linkages Between Agricultural and Natural Systems: Trophic Structure, Pesticide Exposure, and Costs and Benefits of Group Liv\nIDAHO\nBOISE STATE UNIVERSITY\n100000\nManaged Ecosystems\nNational Research Initiative Competitive Grants Program\n\n\n\n\n\nDepartment of Energy\n\n\nCode\nDOEawardsBSU &lt;- read_xlsx(\"DOEawards.xlsx\")\n\n\nNew names:\n• `` -&gt; `...27`\n\n\nCode\nDOEBSU_General &lt;- DOEawardsBSU %&gt;% \n  dplyr::filter(Institution == 'Boise State University')\n\nDOEBSU_New_Awards &lt;- DOEBSU_General %&gt;%\n  select(Title, Institution, PI, Status, `Action Type`, `Program Office`, `Start Date`, `End Date`, `Most Recent Award Date`, `Amount Awarded to Date`)\n\nknitr::kable(head(DOEBSU_New_Awards,4))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTitle\nInstitution\nPI\nStatus\nAction Type\nProgram Office\nStart Date\nEnd Date\nMost Recent Award Date\nAmount Awarded to Date\n\n\n\n\nEmerging Properties through Controlled Phase Transformations for High Energy Sodium Ion Batteries\nBoise State University\nXiong, Hui (Claire)\nActive\nNew\nOffice of Basic Energy Sciences\n08/15/2023\n08/14/2026\n09/23/2023\n599992\n\n\nUptake mechanisms of REE in sedimentary phosphorite mineral Sponsor: Department of Energy\nBoise State University\nKohn, Matthew\nActive\nNew\nOffice of Basic Energy Sciences\n09/01/2023\n08/31/2026\n09/14/2023\n888250\n\n\nDNA-Controlled Dye Aggregation ¿ A Path to Create Quantum Entanglement\nBoise State University\nKnowlton, William\nActive\nRenewal\nOffice of Basic Energy Sciences\n08/15/2023\n08/14/2025\n08/31/2023\n12500000\n\n\nNeuromorphic Systems for Power Grid Cyber-Resilience\nBoise State University\nCantley, Kurtis\nActive\nNew\nOffice of Basic Energy Sciences\n09/01/2022\n08/31/2025\n08/07/2023\n708985\n\n\n\n\n\nNational Institutes of Health (NIH)\n\n\nCode\nNIHBSUAwardsActive &lt;- read_xlsx(\"NIHBSU_2.xlsx\")\n\nNIHBSU_New_Awards_Specific &lt;- NIHBSUAwardsActive %&gt;%\n  select('Project Title', 'Administering IC', 'Award Notice Date', `Opportunity Number`, `Project Number`, `Project Start Date`, `Project End Date`, `Budget Start Date`, `Budget End Date`, 'Total Cost', 'Total Cost (Sub Projects)', 'Funding IC(s)', 'Direct Cost IC', 'InDirect Cost IC', 'Total Cost IC')\n\nknitr::kable(head(NIHBSU_New_Awards_Specific,4))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nProject Title\nAdministering IC\nAward Notice Date\nOpportunity Number\nProject Number\nProject Start Date\nProject End Date\nBudget Start Date\nBudget End Date\nTotal Cost\nTotal Cost (Sub Projects)\nFunding IC(s)\nDirect Cost IC\nInDirect Cost IC\nTotal Cost IC\n\n\n\n\nAdministrative Core\nNIGMS\n8/24/2023\nPA-20-272\n3P20GM109095-10S1\n8/1/2014\n5/31/2024\n6/1/2023\n5/31/2024\nNA\n723429\nNA\n517798\n205631\nNA\n\n\nCenter of Biomedical Research Excellence in Matrix Biology Phase II\nNIGMS\n8/24/2023\nPA-20-272\n3P20GM109095-10S1\n8/1/2014\n5/31/2024\n6/1/2023\n5/31/2024\n723429\nNA\nNIGMS\n517798\n205631\n723429\n\n\nRole of LINC-mediated Mechanosignaling in MSC Aging\nNIA\n1/29/2024\nPA-16-442\n5R01AG059923-05\n3/1/2020\n1/31/2025\n2/1/2024\n1/31/2025\n252208\nNA\nNIA\n184500\n67708\n252208\n\n\nEquipment for Spatiotemporal Dynamics of the Genome by 3D Orbital Tracking\nNIGMS\n5/23/2023\nPA-20-272\n3R15GM123446-02A1S1\n5/17/2017\n7/31/2025\n8/1/2022\n7/31/2025\n97574\nNA\nNIGMS\n97574\n0\n97574\n\n\n\n\n\nNational Science Foundation (NSF)\n\n\nCode\n# Reading the dataset from an Excel file\nNSFBSUAwardsActive &lt;- read_xlsx(\"NSFBSU_2.xlsx\")\n\n# Selecting specific columns, ensure there are no leading or trailing spaces in column names\nNSFBSU_New_Awards_Specific &lt;- NSFBSUAwardsActive %&gt;%\n  select(Title, NSFOrganization, StartDate, LastAmendmentDate, EndDate, AwardedAmountToDate)\n\n# Displaying the first few rows in a table format\nknitr::kable(head(NSFBSU_New_Awards_Specific,4))\n\n\n\n\n\n\n\n\n\n\n\n\n\nTitle\nNSFOrganization\nStartDate\nLastAmendmentDate\nEndDate\nAwardedAmountToDate\n\n\n\n\nPlanning: Track 1: Curriculum and Advancements in Recruitment, Education, and Engineering Retention (CAREER)\nEEC\n07/15/2022\n07/14/2022\n06/30/2024\n$99,808.00\n\n\nIUCRC Phase II Boise State University: Center for Atomically Thin Multifunctional Coatings (ATOMIC)\nEEC\n08/01/2021\n11/14/2023\n07/31/2026\n$582,631.00\n\n\nMRI: Acquisition of a 600 MHz NMR Console and Cryoprobe to Support Research and Education at Boise State University\nDBI\n10/01/2022\n08/10/2023\n09/30/2025\n$769,221.00\n\n\nMRI: Track 1: Acquisition of a Liquid Chromatography-High Resolution Mass Spectrometry System for Multidisciplinary Research and Training\nCHE\n09/01/2023\n08/22/2023\n08/31/2026\n$710,000.00\n\n\n\n\n\n\n\nIdaho State University - Data Sources\nDepartment of Energy\n\n\nCode\nDOEaward &lt;- read_xlsx(\"DOEawards.xlsx\")\n\n\nNew names:\n• `` -&gt; `...27`\n\n\nCode\nDOEIDAHOSATTE_General &lt;- DOEaward %&gt;% \n  dplyr::filter(Institution == 'Idaho State University')\n\nDOEDAHOSATTE_New_Awards &lt;- DOEIDAHOSATTE_General %&gt;%\n  select(Title, Institution, PI, Status, `Action Type`, `Program Office`, `Start Date`, `End Date`, `Most Recent Award Date`, `Amount Awarded to Date`)\n\nknitr::kable(head(DOEDAHOSATTE_New_Awards,4))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTitle\nInstitution\nPI\nStatus\nAction Type\nProgram Office\nStart Date\nEnd Date\nMost Recent Award Date\nAmount Awarded to Date\n\n\n\n\nPrecision Electroweak Probe of BSM Physics\nIdaho State University\nMcNulty, Dustin\nActive\nRenewal\nOffice of Nuclear Physics\n09/01/2023\n08/31/2026\n08/31/2023\n1195000\n\n\nMechanistic and Kinetic Analysis of Polymer Deconstruction and Modification by Irradiation for Polymer Upcycling\nIdaho State University\nJenkins, Courtney\nActive\nNew\nOffice of Basic Energy Sciences\n09/01/2022\n08/31/2025\n07/24/2023\n583930\n\n\n\n\n\nDepartment of Agriculture (NIFA)\n\n\nCode\nISUUSDA  &lt;- read.csv(\"USDAISU.csv\")\nknitr::kable(head(ISUUSDA,4))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAward.Date\nGrant.Number\nProposal.Number\nGrant.Title\nState.Name\nGrantee.Name\nAward.Dollars\nProgram.Name\nProgram.Area.Name\n\n\n\n\n2002-07-19\n2002-35320-12359\n2002-00673\nInstrumentation for Evaluating the Role of Photosynthetic Ecophysiology in Plant Invasions of Semiarid Communities\nIDAHO\nIDAHO STATE UNIVERSITY\n24464\nBiology of Weedy & Invasive Species in Agroecosystems\nNational Research Initiative Competitive Grants Program\n\n\n2003-07-28\n2003-35206-13612\n2003-03242\nMetabolic Consequences of Lipid Suppression on Carbohydrate Tolerance and Growth Performance in Rainbow Trout (Oncorhynchus Mykiss)\nIDAHO\nIDAHO STATE UNIVERSITY\n74759\nAnimal Growth and Nutrient Utilization\nNational Research Initiative Competitive Grants Program\n\n\n2006-08-23\n2006-35320-17463\n2006-03625\nLand Effects:Peristence Exotic Forbs in Sagebrush Steppe:Are Loss of Foundation Species/Disruption Soil Resource Partitioning Causal Links?\nIDAHO\nIDAHO STATE UNIVERSITY\n323764\nBiology of Weedy & Invasive Species in Agroecosystems\nNational Research Initiative Competitive Grants Program\n\n\n2010-01-12\n2010-85320-20506\n2009-04939\nExotic Bromus grasses in agroecosystems of the western US: REEnet synthesis of current and future invasions, impacts, and management.\nIDAHO\nIDAHO STATE UNIVERSITY\n81029\nBiology of Weedy and Invasive Species in Agroecosystems\nAgriculture and Food Research Initiative\n\n\n\n\n\nNational Institutes of Health (NIH)\n\n\nCode\nNIHISUAwardsActive &lt;- read_xlsx(\"NIHISU_2.xlsx\")\n\nNIHISU_New_Awards_Specific &lt;- NIHISUAwardsActive %&gt;%\n  select('Project Title', 'Administering IC', 'Award Notice Date', `Opportunity Number`, `Project Number`, `Project Start Date`, `Project End Date`, `Budget Start Date`, `Budget End Date`, 'Total Cost', 'Total Cost (Sub Projects)', 'Funding IC(s)', 'Direct Cost IC', 'InDirect Cost IC', 'Total Cost IC')\n\nknitr::kable(head(NIHISU_New_Awards_Specific,4))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nProject Title\nAdministering IC\nAward Notice Date\nOpportunity Number\nProject Number\nProject Start Date\nProject End Date\nBudget Start Date\nBudget End Date\nTotal Cost\nTotal Cost (Sub Projects)\nFunding IC(s)\nDirect Cost IC\nInDirect Cost IC\nTotal Cost IC\n\n\n\n\nThe Brain-Behavior Relationship: Age, Hearing, and Their Effects on Understanding Speech in Noise\nNIDCD\n1/12/2023\nPA-13-302\n7R01DC015240-06\n8/15/2016\n7/31/2024\n6/1/2022\n7/31/2024\n251216\nNA\nNIDCD\n200394\n50822\n251216\n\n\nMOLECULAR ANALYSIS OF MALARIA MITOCHONDRIAL GENE REGULATION\nNIAID\n12/18/2023\nPAR-20-259\n5DP2AI164244-03\n1/1/2022\n12/31/2026\n1/1/2024\n12/31/2024\n364371\nNA\nNIAID\n262096\n102275\n364371\n\n\nTimely Response to In-Hospital Deterioration Through Design of Actionable Augmented Intelligence\nNIGMS\n6/20/2023\nPA-19-056\n5R01GM137083-04\n7/15/2020\n6/30/2024\n7/1/2023\n6/30/2024\n397867\nNA\nNIGMS\n356308\n41559\n397867\n\n\nThe role of metal ion homeostasis in regulating bacterial capsule production\nNIAID\n8/10/2022\nPAR-18-714\n1R15AI149725-01A1\n8/10/2022\n7/31/2025\n8/10/2022\n7/31/2025\n408497\nNA\nNIGMS\n235007\n84993\n320000\n\n\n\n\n\nNational Science Foundation (NSF)\n\n\nCode\n# Reading the dataset from an Excel file\nNSFISUAwardsActive &lt;- read_xlsx(\"NSFISU_2.xlsx\")\n\n# Selecting specific columns, ensure there are no leading or trailing spaces in column names\nNSFISU_New_Awards_Specific &lt;- NSFISUAwardsActive %&gt;%\n  select(Title, NSFOrganization, StartDate, LastAmendmentDate, EndDate, AwardedAmountToDate)\n\n# Displaying the first few rows in a table format\nknitr::kable(head(NSFISU_New_Awards_Specific,4))\n\n\n\n\n\n\n\n\n\n\n\n\n\nTitle\nNSFOrganization\nStartDate\nLastAmendmentDate\nEndDate\nAwardedAmountToDate\n\n\n\n\nCDS&E: Immersive Virtual Reality for Discovering Hidden Chemical Information and Improving Multivariate Modeling and Predication\nCHE\n09/15/2023\n09/13/2023\n08/31/2026\n$449,994.00\n\n\nGP-IN: Pathways to tribal geosciences careers through cultural connections to iconic landscapes\nRISE\n01/01/2022\n08/16/2021\n12/31/2024\n$284,964.00\n\n\nSupporting Transfer Student Success Using a Multidisciplinary Approach\nDUE\n10/01/2022\n07/25/2022\n09/30/2028\n$1,499,956.00\n\n\nReynolds Creek Carbon Critical Zone Observatory\nEAR\n12/01/2013\n07/24/2023\n05/31/2024\n$3,755,249.00\n\n\n\n\n\n\n\nData Comparison of Awarded Money\nThe following visualizations will show us how much is awarded money is coming to these institutions, and will provide insights into UI’s competitiveness and standing within its peer group.\nIn our first visualization (Figure 9) we are looking at the total of awarded money of current active awards from the USDA, and UI’s excelling compared to Boise State University. There’s no data of Idaho State University,because they don’t have current active awards with them. This indicates that UI’s is on top in the game in regards of obtaining funds from the USDA. On Figure 10 we have for the sponsor DOE in contrast of what we saw in the previous graph, UI is under performing and Boise State is excelling in obtaining funds. Which is something that we need to take into consideration and look for more information, why is UI not performing well in securing funds from DOE. Figure 11. In our last visualization (Figure 11), we have the sponsor NIH, in which UI is performing well comparing to its peers. Looking at these data we can determine in the areas the UI is excelling and under performing, and we can make the necessary adjustments to keep excelling in the academic field.\nIdaho State University doesn’t have currently active USDA award that is why is not added in the following visualization\n\n\nCode\n# COMPARISON BETWEEEN USDA - AWARD MONEY\n\nUSDA_Compare_Data &lt;- read_xlsx(\"USDA_Combined_Data_Recent_Awards.xlsx\")\n\n# Define a vector of old names and a new name\nold_names &lt;- c(\"SAES - UNIVERSITY OF IDAHO\", \"FRST - UNIVERSITY OF IDAHO-FORESTRY SCHOOL\")\nnew_name &lt;- \"UNIVERSITY OF IDAHO\"\n\n# Use mutate with ifelse and %in% to change multiple old names to the new name\nUSDA_Compare_Data &lt;- mutate(USDA_Compare_Data, Grantee_Name = ifelse(Grantee_Name %in% old_names, new_name, Grantee_Name))\n\n# Calculate total award money for each institution\nUSDA_total_award_money &lt;- USDA_Compare_Data %&gt;%\n  group_by(Grantee_Name) %&gt;%\n  summarise(USDA_total_award_money = sum(Award_Dollars))\n\nmy_colors_6 &lt;- c(\"BOISE STATE UNIVERSITY\" = \"orange\", \"UNIVERSITY OF IDAHO\" = \"gold\")\n\nggplot(USDA_total_award_money, aes(x = Grantee_Name, y = USDA_total_award_money)) +\n  geom_bar(stat = \"identity\", fill = my_colors_6) +\n  ggtitle(\"Total of Award Money from USDA Grants\") +\n  xlab(\"\") +\n  ylab(\"Total Award Money\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1),\n        axis.text.y = element_text(size = 12),\n        plot.title = element_text(hjust = 0.5)) +  # Corrected position of plot title\n  scale_y_continuous(labels = scales::number_format(scale = 1e-6, suffix = \"M\"))\n\n\n\n\n\nFigure 9: Total of Award Money from USDA Grants\n\n\nCode\n# COMPARISON BETWEEEN DOE - AWARD MONEY\n\nDOE_Compare_Data &lt;- read_xlsx(\"DOEawards_Combined_Data.xlsx\")\n\n# Calculate total award money for each institution\nDOE_total_award_money &lt;- DOE_Compare_Data %&gt;%\n  group_by(Institution) %&gt;%\n  summarise(DOE_total_award_money = sum(`Amount Awarded to Date`))\n\n# Colors\nmy_colors &lt;- c(\"Boise State University\" = \"orange\", \"Idaho State University\" = \"black\", \"Regents of the University of Idaho\" = \"gold\")\n\n\nggplot(DOE_total_award_money, aes(x = Institution, y = DOE_total_award_money)) +\n  geom_bar(stat = \"identity\", position = \"dodge\", fill = my_colors)  +\n  ggtitle(\"Total of Award Money from DOE Grants\") +\n  xlab(\"\") +\n  ylab(\"Total Award Money\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1, size = 12),  # Adjust size of x-axis labels\n        axis.text.y = element_text(size = 12),  # Adjust size of y-axis labels\n        legend.text = element_text(size = 12),  # Adjust size of legend text\n        plot.title = element_text(hjust = 0.5, size = 14)) +  # Adjust size of plot title\n  scale_y_continuous(labels = scales::number_format(scale = 1e-6, suffix = \"M\"))\n\n\n\n\n\nFigure 10:Total of Award Money from DOE Grants\n\n\nCode\n# COMPARISON BETWEEEN NSF - AWARD MONEY - NO APARECE LA DATA\n\nNSF_Compare_Data &lt;- read_xlsx(\"NSF_Combined_Data.xlsx\")\n\n# Filter the data for each institution\nUI_NSF_data &lt;- NSF_Compare_Data %&gt;%\n  filter(Organization == \"Regents of the University of Idaho\")\n\nBSU_NSF_data &lt;- NSF_Compare_Data %&gt;%\n  filter(Organization == \"Boise State University\")\n\nISU_NSF_data &lt;- NSF_Compare_Data %&gt;%\n  filter(Organization == \"Idaho State University\")\n\n# Convert AwardedAmountToDate column to numeric\nNSF_Compare_Data$AwardedAmountToDate &lt;- as.numeric(gsub(\"\\\\$\", \"\", NSF_Compare_Data$AwardedAmountToDate))\n\n\nWarning: NAs introduced by coercion\n\n\nCode\n# Remove dollar signs ($) and commas (,) from numeric columns\nUI_NSF_data &lt;- UI_NSF_data %&gt;%\n  mutate(AwardedAmountToDate = as.numeric(gsub(\"[\\\\$,]\", \"\", AwardedAmountToDate)))\n\n# Calculate total award money for each institution\nNSF_total_award_money &lt;- NSF_Compare_Data %&gt;%\n  group_by(Organization) %&gt;%\n  summarise(NSF_total_award_money = sum(AwardedAmountToDate, na.rm = TRUE))\n\n# Calculate total award money for each institution\nNSF_total_award_money &lt;- NSF_Compare_Data %&gt;%\n  group_by(Organization) %&gt;%\n  summarise(NSF_total_award_money = sum(AwardedAmountToDate))\n\n# Colors\nmy_colors &lt;- c(\"Boise State University\" = \"orange\", \"Idaho State University\" = \"black\", \"Regents of the University of Idaho\" = \"gold\")\n\nggplot(NSF_total_award_money, aes(x = Organization, y = NSF_total_award_money)) +\n  geom_bar(stat = \"identity\", position = \"dodge\", fill = my_colors)  +\n  ggtitle(\"Total of Award Money from NSF Grants\") +\n  xlab(\"\") +\n  ylab(\"Total Award Money\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1, size = 12),  # Adjust size of x-axis labels\n        axis.text.y = element_text(size = 12),  # Adjust size of y-axis labels\n        legend.text = element_text(size = 12),  # Adjust size of legend text\n        plot.title = element_text(hjust = 0.5, size = 14)) +  # Adjust size of plot title\n  scale_y_continuous(labels = scales::number_format(scale = 1e-6, suffix = \"M\"))\n\n\nWarning: Removed 3 rows containing missing values (`geom_bar()`).\n\n\n\n\n\nFigure 11:Total of Award Money from NSF Grants\n\n\nCode\n# COMPARISON BETWEEEN NIH - AWARD MONEY - CALCULATED THE AVERAGE INSTEAD THE TOTAL AMMOUNT\n\nNIH_Compare_Data &lt;- read_xlsx(\"NIH_Combined_Data.xlsx\")\n\n# Calculate total award money for each institution, removing NA values in TotalCost\n\nNIH_total_award_money &lt;- NIH_Compare_Data %&gt;%\n  group_by(OrganizationName) %&gt;%\n  summarise(NIH_total_award_money = sum(TotalCost, na.rm = TRUE))\n\n# Colors\n\nmy_colors_3 &lt;- c(\"BOISE STATE UNIVERSITY\" = \"orange\", \"IDAHO STATE UNIVERSITY\" = \"black\", \"UNIVERSITY OF IDAHO\" = \"gold\")\n\nggplot(NIH_total_award_money, aes(x = OrganizationName, y = NIH_total_award_money)) +\n  geom_bar(stat = \"identity\", position = \"dodge\", fill = my_colors_3)  +\n  ggtitle(\"Total of Award Money from NIH Grants\") +\n  xlab(\"\") +\n  ylab(\"Total Award Money\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1, size = 12),  # Adjust size of x-axis labels\n        axis.text.y = element_text(size = 12),  # Adjust size of y-axis labels\n        legend.text = element_text(size = 12),  # Adjust size of legend text\n        plot.title = element_text(hjust = 0.5, size = 14)) +  # Adjust size of plot title\n  scale_y_continuous(labels = scales::number_format(scale = 1e-6, suffix = \"M\"))\n\n\n\n\n\nFigure 12:Total of Award Money from NIH Grants\n\n\nData Comparison of Grant Duration\nThe following visualizations will show us how the duration of the awarded grants of these institutions, and will provide insights into UI’s competitiveness and standing within its peer group. These visualization are for the current active awards from each sponsor.\nIn our first visualization (Figure 13), its the duration of the current active awards for the sponsor DOE. By, looking at these bar chart, we can easily point out that our DOE awards ends in 4 years compared to Boise State University that ends in 5 years. This means that during that year gap, UI have to look for renewing awards or to apply for new awards. For the NSF award (Figure 14) Idaho State University has the longest duration of their current active awards for 10 years, and University of Idaho comes second. We are coming in par with the Idaho State University, also to clarify some of these awarded grants, depending of the type of grant can go for longer than 5 years. For the NIH award (Figure 15) University of Idaho, is at the top for the the longest duration of their current active awards for the NIH, over 20 years. Like I mentioned before some of these grants can go longer than 5 years.\nUSDA data was not added for this data visualization because it didn’t provide an end date of their current active awards\n\n\nCode\n# COMPARISON BETWEEEN DOE - Grant Duration\n\nlibrary(readxl)\n\nDOE_Compare_Data &lt;- read_xlsx(\"DOEawards_Combined_Data.xlsx\")\n\nlibrary(dplyr)\n\n# Assuming 'start_date' and 'end_date' are columns containing the start and end dates of the grants,\n# and 'institution' is a column indicating the institution for each grant\n\n# Filter the data for each institution\nUI_data &lt;- DOE_Compare_Data %&gt;%\n  filter(Institution == \"Regents of the University of Idaho\")\n\nBSU_data &lt;- DOE_Compare_Data %&gt;%\n  filter(Institution == \"Boise State University\")\n\nISU_data &lt;- DOE_Compare_Data %&gt;%\n  filter(Institution == \"Idaho State University\")\n\n# Calculate the duration of grants for each institution\n# Convert \"Start Date\" and \"End Date\" columns to date objects\nUI_data &lt;- UI_data %&gt;%\n  mutate(`Start Date` = as.Date(`Start Date`, format = \"%m/%d/%Y\"),\n         `End Date` = as.Date(`End Date`, format = \"%m/%d/%Y\"))\n\n# Assuming 'grant_duration' is in days\nUI_data &lt;- UI_data %&gt;%\n  mutate(grant_duration = `End Date` - `Start Date`)\n\nUI_data &lt;- UI_data %&gt;%\n  mutate(grant_duration_years = as.numeric(grant_duration) / 365.25)\n\n# BSU\nBSU_data &lt;- BSU_data %&gt;%\n  mutate(`Start Date` = as.Date(`Start Date`, format = \"%m/%d/%Y\"),\n         `End Date` = as.Date(`End Date`, format = \"%m/%d/%Y\"))\n\n# Assuming 'grant_duration' is in days\nBSU_data &lt;- BSU_data %&gt;%\n  mutate(grant_duration = `End Date` - `Start Date`)\n\nBSU_data &lt;- BSU_data %&gt;%\n  mutate(grant_duration_years = as.numeric(grant_duration) / 365.25)\n\n# ISU\nISU_data &lt;- ISU_data %&gt;%\n  mutate(`Start Date` = as.Date(`Start Date`, format = \"%m/%d/%Y\"),\n         `End Date` = as.Date(`End Date`, format = \"%m/%d/%Y\"))\n\n# Assuming 'grant_duration' is in days\nISU_data &lt;- ISU_data %&gt;%\n  mutate(grant_duration = `End Date` - `Start Date`)\n\nISU_data &lt;- ISU_data %&gt;%\n  mutate(grant_duration_years = as.numeric(grant_duration) / 365.25)\n\n# Visualization\n\nlibrary(dplyr)\n\n# Assuming UI_data contains the grant duration information for one institution\n# and other_datasets contain the grant duration information for the other institutions\n\n# Combine datasets\ncombined_data &lt;- bind_rows(UI_data, BSU_data, ISU_data)\n\n# Colors\n\nmy_colors &lt;- c(\"Boise State University\" = \"orange\", \"Idaho State University\" = \"black\", \"Regents of the University of Idaho\" = \"gold\")\n\n# Plotting grant duration as a bar graph\n# Plotting grant duration as a bar graph\nlibrary(ggplot2)\n\nggplot(combined_data, aes(x = Institution, y = grant_duration_years)) +\n  geom_bar(stat = \"identity\", position = \"dodge\", fill = c(my_colors[combined_data$Institution])) +  \n  ggtitle(\"Grant Duration by Institution\") +\n  xlab(\"\") +\n  ylab(\"Grant Duration (Years)\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1, size = 12),  \n        axis.text.y = element_text(size = 12),  \n        plot.title = element_text(hjust = 0.5, size = 14))  \n\n\n\n\n\nFigure 13: Grant Duration by Institution (DOE). This Bar Chart provides information of the duration of the current active awards by Institution for DOE.\n\n\nCode\n# COMPARISON BETWEEEN NSF - Grant Duration\n\nlibrary(readxl)\n\nNSF_Compare_Data &lt;- read_xlsx(\"NSF_Combined_Data.xlsx\")\n\nlibrary(dplyr)\n\n# Filter the data for each institution\nUI_NSF_data &lt;- NSF_Compare_Data %&gt;%\n  filter(Organization == \"Regents of the University of Idaho\")\n\nBSU_NSF_data &lt;- NSF_Compare_Data %&gt;%\n  filter(Organization == \"Boise State University\")\n\nISU_NSF_data &lt;- NSF_Compare_Data %&gt;%\n  filter(Organization == \"Idaho State University\")\n\n# Calculate the duration of grants for each institution\n# Convert \"Start Date\" and \"End Date\" columns to date objects\n#UI\n\nUI_NSF_data &lt;- UI_NSF_data %&gt;%\n  mutate(`Start Date` = as.Date(StartDate, format = \"%m/%d/%Y\"),\n         `End Date` = as.Date(EndDate, format = \"%m/%d/%Y\"))\n\n# Assuming 'grant_duration' is in days\nUI_NSF_data &lt;- UI_NSF_data %&gt;%\n  mutate(grant_duration = `End Date` - `Start Date`)\n\nUI_NSF_data &lt;- UI_NSF_data %&gt;%\n  mutate(grant_duration_years = as.numeric(grant_duration) / 365.25)\n\n# BSU\nBSU_NSF_data  &lt;- BSU_NSF_data %&gt;%\n  mutate(`Start Date` = as.Date(StartDate, format = \"%m/%d/%Y\"),\n         `End Date` = as.Date(EndDate, format = \"%m/%d/%Y\"))\n\n# Assuming 'grant_duration' is in days\nBSU_NSF_data  &lt;- BSU_NSF_data %&gt;%\n  mutate(grant_duration = `End Date` - `Start Date`)\n\nBSU_NSF_data  &lt;- BSU_NSF_data  %&gt;%\n  mutate(grant_duration_years = as.numeric(grant_duration) / 365.25)\n\n# ISU\nISU_NSF_data&lt;- ISU_NSF_data %&gt;%\n  mutate(`Start Date` = as.Date(StartDate, format = \"%m/%d/%Y\"),\n         `End Date` = as.Date(EndDate, format = \"%m/%d/%Y\"))\n\n# Assuming 'grant_duration' is in days\nISU_NSF_data &lt;- ISU_NSF_data %&gt;%\n  mutate(grant_duration = `End Date` - `Start Date`)\n\nISU_NSF_data &lt;- ISU_NSF_data %&gt;%\n  mutate(grant_duration_years = as.numeric(grant_duration) / 365.25)\n\n# Visualization\n\nlibrary(dplyr)\n\n# Assuming UI_data contains the grant duration information for one institution\n# and other_datasets contain the grant duration information for the other institutions\n\n# Combine datasets\ncombined_data_NSF &lt;- bind_rows(UI_NSF_data, BSU_NSF_data, ISU_NSF_data)\n\n# Colors\n\nmy_colors &lt;- c(\"Boise State University\" = \"orange\", \"Idaho State University\" = \"black\", \"Regents of the University of Idaho\" = \"gold\")\n\n# Plotting grant duration as a bar graph\nlibrary(ggplot2)\n\nggplot(combined_data_NSF, aes(x = Organization, y = grant_duration_years)) +\n  geom_bar(stat = \"identity\", position = \"dodge\", fill = c(my_colors[combined_data_NSF$Organization])) +\n  ggtitle(\"Grant Duration by Organization\") +\n  xlab(\"\") +\n  ylab(\"Grant Duration (Years)\") +\n  scale_fill_manual(values = my_colors) +  # Apply custom colors\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1, size = 12),  # Adjust size of x-axis labels\n        axis.text.y = element_text(size = 12),  # Adjust size of y-axis labels\n        legend.text = element_text(size = 12),  # Adjust size of legend text\n        plot.title = element_text(hjust = 0.5, size = 14))  # Adjust size of plot title\n\n\n\n\n\nFigure 14:Grant Duration by Institution (NSF). This Bar Chart provides information of the duration of the current active awards by Institution for NSF.\n\n\nCode\n# COMPARISON BETWEEEN NIH - Grant Duration\nlibrary(readxl)\nNIH_Compare_Data &lt;- read_xlsx(\"NIH_Combined_Data.xlsx\")\n\nlibrary(dplyr)\n\n# Filter the data for each institution\nUI_NIH_data &lt;- NIH_Compare_Data %&gt;%\n  filter(OrganizationName == \"UNIVERSITY OF IDAHO\")\n\nBSU_NIH_data &lt;- NIH_Compare_Data %&gt;%\n  filter(OrganizationName == \"BOISE STATE UNIVERSITY\")\n\nISU_NIH_data &lt;- NIH_Compare_Data %&gt;%\n  filter(OrganizationName == \"IDAHO STATE UNIVERSITY\")\n\n# Calculate the duration of grants for each institution\n# Convert \"Start Date\" and \"End Date\" columns to date objects\n#UI\n\nUI_NIH_data &lt;- UI_NIH_data%&gt;%\n  mutate(`Start Date` = as.Date(ProjectStartDate, format = \"%m/%d/%Y\"),\n         `End Date` = as.Date(ProjectEndDate, format = \"%m/%d/%Y\"))\n\n# Assuming 'grant_duration' is in days\nUI_NIH_data &lt;- UI_NIH_data %&gt;%\n  mutate(grant_duration = `End Date` - `Start Date`)\n\nUI_NIH_data &lt;- UI_NIH_data %&gt;%\n  mutate(grant_duration_years = as.numeric(grant_duration) / 365.25)\n\n# BSU - no quiere funcionar no tengo la menor idea pq\nBSU_NIH_data  &lt;- BSU_NIH_data %&gt;%\n  mutate(`Start Date` = as.Date(ProjectStartDate, format = \"%m/%d/%Y\"),\n         `End Date` = as.Date(ProjectEndDate, format = \"%m/%d/%Y\"))\n\n# Assuming 'grant_duration' is in days\nBSU_NIH_data  &lt;- BSU_NIH_data %&gt;%\n  mutate(grant_duration = `End Date` - `Start Date`)\n\nBSU_NIH_data  &lt;- BSU_NIH_data  %&gt;%\n  mutate(grant_duration_years = as.numeric(grant_duration) / 365.25)\n\n# ISU\nISU_NIH_data&lt;- ISU_NIH_data %&gt;%\n  mutate(`Start Date` = as.Date(ProjectStartDate, format = \"%m/%d/%Y\"),\n         `End Date` = as.Date(ProjectEndDate, format = \"%m/%d/%Y\"))\n\n# Assuming 'grant_duration' is in days\nISU_NIH_data &lt;- ISU_NIH_data %&gt;%\n  mutate(grant_duration = `End Date` - `Start Date`)\n\nISU_NIH_data &lt;- ISU_NIH_data %&gt;%\n  mutate(grant_duration_years = as.numeric(grant_duration) / 365.25)\n\n# Visualization\n\nlibrary(dplyr)\n\n# Assuming UI_data contains the grant duration information for one institution\n# and other_datasets contain the grant duration information for the other institutions\n\n# Combine datasets\ncombined_data_NIH &lt;- bind_rows(UI_NIH_data, BSU_NIH_data, ISU_NIH_data)\n\n# Colors\n\nmy_colors_3 &lt;- c(\"BOISE STATE UNIVERSITY\" = \"orange\", \"IDAHO STATE UNIVERSITY\" = \"black\", \"UNIVERSITY OF IDAHO\" = \"gold\")\n\n# Plotting grant duration as a bar graph\nlibrary(ggplot2)\n\nggplot(combined_data_NIH, aes(x = OrganizationName, y = grant_duration_years, fill = OrganizationName)) +\n  geom_bar(stat = \"identity\", position = \"dodge\", fill = my_colors_3[combined_data_NIH$OrganizationName]) +\n  ggtitle(\"Grant Duration by Organization\") +\n  xlab(\"\") +\n  ylab(\"Grant Duration (Years)\") +\n  scale_fill_manual(values = my_colors_3) +  # Apply custom colors\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1, size = 12),  # Adjust size of x-axis labels\n        axis.text.y = element_text(size = 12),  # Adjust size of y-axis labels\n        legend.text = element_text(size = 12),  # Adjust size of legend text\n        plot.title = element_text(hjust = 0.5, size = 14))  # Adjust size of plot title\n\n\n\n\n\nFigure 15:Grant Duration by Institution (NIH). This Bar Chart provides information of the duration of the current active awards by Institution for NIH.\nBy looking at these visualizations, we can say that for the sponsor DOE, is the only one that we the grant duration is less compared with the other sponsors by institution. Which comes to a concern, like how we can expand our portfolio in regards of acquiring more awards from DOE. For NIH and NSF awards, we have an active flow of awards, and some of these awards are going to be active for the formidable future.\n\n\n\nData Comparison of Grant Status\nFor the last visualizations, I mentioned in the previous section, there’s different types of awarded grants. The following graphs will give us and understanding what type of grants (current active grants) are coming to UI compared to our peer institution.\nThe only available data for this type of analysis is from the sponsors DOE and NSF\nIn our first visualization (Figure 16), we are looking at the type of grants that these institutions have in DOE. We have two types of grants which are: new and renewal, for our current active we have 3 that are new and 1 renewal. This a type of data to keep in mind, to see how many grants are coming that are new, or if we have that are renewal. But, looking ar this Boise State University has more in new and renewal for DOE sponsor.\nIt is not surprising that UI is under performing in acquiring grants from this sponsor. We have seen that from previous visualizations\nFigure 17 we are looking at the type of grants that these institutions have in NSF. In contrast to DOE sponsor, we have more types of grants in NSF, which are the following: continuing grant, cooperative agreement, fellowship award, and standard grant. I mentioned before (Grant duration section) that some grants have a longer duration, and that’s because it depends on the type of grant it has (that also applies how much money is being awarded). In general as a whole, Boise State University has more active current awards compared to University of Idaho, so the number of types of grants are going to be different then University of Idaho. So, we are going to focus on University of Idaho, that highest type of grant that we current have is the standard grant followed by continuing grants. The one that is under performing is Fellowship award, and that is because most of these awards are awarded to graduate students. Looking at this we can see that not a lot of graduate students at UI are applying to fellowships in NSF, which is something that can be changed, giving the proper guidance.\n\n\nCode\n# COMPARISON BETWEEEN DOE - Grant Status\nlibrary(dplyr)\nlibrary(ggplot2)\n\n# Calculate total grant action count for each institution\nDOE_Grant_Action &lt;- DOE_Compare_Data %&gt;%\n  group_by(Institution, `Action Type`) %&gt;%\n  summarise(count = n(), .groups = \"drop\") %&gt;%\n  ungroup()\n\nlibrary(ggplot2)\n\n# Assuming DOE_Grant_Action is your summarized data frame with counts of Action Type by Institution\n\nggplot(DOE_Grant_Action, aes(x = Institution, y = count, fill = `Action Type`)) +\n  geom_bar(stat = \"identity\", position = \"dodge\") +\n  ggtitle(\"Number of Counts of Action Type by Institution\") +\n  xlab(\"\") +\n  ylab(\"Number of Active Grants\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1, size = 12),  # Adjust size of x-axis labels\n        axis.text.y = element_text(size = 12),  # Adjust size of y-axis labels\n        legend.text = element_text(size = 12),  # Adjust size of legend text\n        plot.title = element_text(hjust = 0.5, size = 14))\n\n\n\n\n\nFigure 16: Type of Grant for current active awards for DOE.\n\n\nCode\n# COMPARISON BETWEEEN NSF - Grant Status\nlibrary(dplyr)\nlibrary(ggplot2)\n\n# Calculate total grant action count for each institution\nNSF_Grant_Award_Instrument &lt;- NSF_Compare_Data %&gt;%\n  group_by(Organization, AwardInstrument) %&gt;%\n  summarise(count = n(), .groups = \"drop\") %&gt;%\n  ungroup()\n\n# Check unique levels of AwardInstrument\nunique_levels &lt;- unique(NSF_Grant_Award_Instrument$AwardInstrument)\n\n# Adjust my_colors_4 to match the number of unique levels\nmy_colors_4 &lt;- c(\"navyblue\", \"darkgreen\", \"darkorange\", \"darkred\")  # or any other color palette you prefer\n\n# Plot with adjusted colors\nggplot(NSF_Grant_Award_Instrument, aes(x = Organization, y = count, fill = AwardInstrument)) +\n  geom_bar(stat = \"identity\", position = \"dodge\") +\n  ggtitle(\"Number of Counts of Action Type by Institution\") +\n  xlab(\"\") +\n  ylab(\"Number of Active Grants\") +\n  scale_fill_manual(values = my_colors_4) +  # Add this line to set custom colors\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1, size = 12),  \n        axis.text.y = element_text(size = 12),  \n        legend.text = element_text(size = 12),  \n        plot.title = element_text(hjust = 0.5, size = 14))\n\n\n\n\n\nFigure 17: Type of Grant for current active awards for NSF.\nBy looking at these visualizations, we can have an understanding of the types of grants that we have at UI for our current awards. I think to expand UIs portfolio is to provide information and workshops for graduate students to have the opportunity to apply for fellowship awards, which will help them to further continue on their research projects."
  },
  {
    "objectID": "posts/MidtermPortfolioPost/Midterm_3.html#conlusionssummary",
    "href": "posts/MidtermPortfolioPost/Midterm_3.html#conlusionssummary",
    "title": "BCB 520 - Midterm Portfolio Post",
    "section": "CONLUSIONS/SUMMARY",
    "text": "CONLUSIONS/SUMMARY\nLooking back at all the previous visualizations, we got a better understanding in how much federal funding is awarded at the University of Idaho (UI) by the following federal agencies: the Department of Energy (DOE), the US Department of Agriculture (NIFA), the National Institute of Health (NIH), and National Science Foundation (NSF). UI excelled in some of them in securing funding in USDA, NIH and NSF grants, the only one that we need to looked into is DOE. We have only 4 currently PIs that have funding through them. It is important for the administration to gain more information, how UI can obtain more funding from DOE. The other thing we have to keep in mind is the current projects that are about to expire in 2024, and if there’s plan for renewal or writing for a new grant. Overall, University of Idaho is a academic institution that have grants coming to the university and is increasing in research projects that are on par with other institutions.\n##IMPROVED VISUALIZATIONS\n\nQuestion #1: NSF Active Awards by PI\n\n\nCode\nlibrary(ggplot2)\nlibrary(readxl)\nlibrary(dplyr)\nlibrary(lubridate)\n\n# Read the data\nQ1_Data_PI &lt;- read_xlsx(\"Q1_Compilled_Data.xlsx\")\n\n# Filter the data for DOE sponsor\nQ1_PI_NSF &lt;- Q1_Data_PI %&gt;%\n  filter(Sponsor == \"NSF\")\n\n# Convert StartDate and EndDate to Date objects\nQ1_PI_NSF$StartDate &lt;- as.Date(Q1_PI_NSF$StartDate, format = \"%m/%d/%Y\")\nQ1_PI_NSF$EndDate &lt;- as.Date(Q1_PI_NSF$EndDate, format = \"%m/%d/%Y\")\n\n# Filter out rows with NA values in StartDate or EndDate\nQ1_PI_NSF &lt;- Q1_PI_NSF[complete.cases(Q1_PI_NSF$StartDate, Q1_PI_NSF$EndDate), ]\n\n# Determine the minimum and maximum dates for the x-axis\nmin_date &lt;- min(Q1_PI_NSF$StartDate)\nmax_date &lt;- max(Q1_PI_NSF$EndDate)\n\n# Extend the x-axis by a certain margin (e.g., 1 year)\nextended_min_date &lt;- min_date - lubridate::years(1)\nextended_max_date &lt;- max_date + lubridate::years(1)\n\n# Create the Gantt chart with adjusted y-axis labels and amounts\nggplot(Q1_PI_NSF, aes(y = PI, x = StartDate, xend = EndDate)) +\n  geom_segment(aes(xend = EndDate, y = PI, yend = PI), size = 5, color = \"gold\") +  # Segment colored by PI\n  geom_text(aes(x = EndDate, label = Amount), vjust = -0.5, hjust = -0.1, size = 2.5) +  # Add text labels for amounts at the end of bars with reduced size\n  scale_x_date(date_breaks = \"1 year\", date_labels = \"%Y\", limits = c(extended_min_date, extended_max_date)) +\n  labs(title = \"Active Awards Timeline by PI\",\n       x = \"Timeline\",\n       y = \"Principal Investigator\") +\n  theme_minimal() +\n  theme(legend.position = \"none\",  # Remove the legend\n        plot.title = element_text(hjust = 0.5),\n        axis.text.y = element_text(size = 6))  # Reduce the size of y-axis label\n\n\n\n\n\n\n\nAmount of Current Active Awards in UI\n\n\nCode\nlibrary(ggplot2)\nlibrary(scales)  # For formatting labels\n\n# Read the data\nQ1_Data_Amount_2 &lt;- read_xlsx(\"Q1_Compilled_Data_4.xlsx\")\n\n# Make a copy of the Amount column\nQ1_Data_Amount_2$Original_Amount &lt;- Q1_Data_Amount_2$Amount\n\n# Remove dollar signs from the Amount column\nQ1_Data_Amount_2$Amount &lt;- gsub(\"\\\\$\", \",\", Q1_Data_Amount_2$Amount)\n\n# Convert the Amount column to numeric\nQ1_Data_Amount_2$Amount &lt;- as.numeric(Q1_Data_Amount_2$Amount)\n\n\nWarning: NAs introduced by coercion\n\n\nCode\n# Check for NA values in the Amount column\nany(is.na(Q1_Data_Amount_2$Amount))\n\n\n[1] TRUE\n\n\nCode\n# Check the structure of the Amount variable\nstr(Q1_Data_Amount_2$Amount)\n\n\n num [1:126] 0 266181 848625 0 0 ...\n\n\nCode\n# Define colors for each sponsor\nsponsor_colors &lt;- c(\"DOE\" = \"darkgray\", \"NSF\" = \"gold\", \"NIH\" = \"black\", \"USDA\" = \"lightgray\")\n\n# Create the bar plot with colors assigned to each sponsor\nggplot(Q1_Data_Amount, aes(x = Sponsor, y = Amount, fill = Sponsor)) +\n  geom_bar(stat = \"summary\", fun = \"sum\") +\n  labs(title = \"Total Amount by Sponsor\",\n       x = \"Sponsor\",\n       y = \"Total Amount (Millions)\") +\n  scale_y_continuous(labels = scales::unit_format(unit = \"M\")) +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1),\n        plot.title = element_text(hjust = 0.5)) +  # Adjust title alignment\n  scale_fill_manual(values = sponsor_colors)  # Use manually defined colors for each sponsor\n\n\nWarning: Removed 51 rows containing non-finite values (`stat_summary()`)."
  },
  {
    "objectID": "posts/MarksChannels/Asig4_2.html",
    "href": "posts/MarksChannels/Asig4_2.html",
    "title": "ASSIGNMENT 4",
    "section": "",
    "text": "The data set contains a list of more that 100,000 copies of video games, from the time period of 1983 - 2012. It is a public data set that it can be obtain by the following website Kaggle - Video Game Sales\nThe data contains the rank of overall sales, game title, platform of the video game release, year of game release, genre of the game, publisher of game, and sales in the millions for US, Europe, Japan, rest of world wide and total global sales.\n\n\nWe have a Flat Table, the items are the rows, wherein each row is the different types of games that has been released from 1983 - 2012. Each item (games) is described by attributes, which are put in columns. Those attributes represent: index, rank, game title, platform, year, genre, publisher, US, Europe, Japan, Rest of the Word, Global (total of sales), and reviews. For each column of the different countries represent the total sales from each one in terms of millions in sales.\n\n\nCode\nlibrary(readxl)\nmy_df &lt;- read_excel(\"VIdeo_Game_sales.xlsx\")\n\nknitr::kable(head(my_df,10))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRank\nName\nPlatform\nYear\nGenre\nPublisher\nNA_Sales\nEU_Sales\nJP_Sales\nOther_Sales\nGlobal_Sales\n\n\n\n\n1\nWii Sports\nWii\n2006\nSports\nNintendo\n41.49\n29.02\n3.77\n8.46\n82.74\n\n\n2\nSuper Mario Bros.\nNES\n1985\nPlatform\nNintendo\n29.08\n3.58\n6.81\n0.77\n40.24\n\n\n3\nMario Kart Wii\nWii\n2008\nRacing\nNintendo\n15.85\n12.88\n3.79\n3.31\n35.82\n\n\n4\nWii Sports Resort\nWii\n2009\nSports\nNintendo\n15.75\n11.01\n3.28\n2.96\n33.00\n\n\n5\nPokemon Red/Pokemon Blue\nGB\n1996\nRole-Playing\nNintendo\n11.27\n8.89\n10.22\n1.00\n31.37\n\n\n6\nTetris\nGB\n1989\nPuzzle\nNintendo\n23.20\n2.26\n4.22\n0.58\n30.26\n\n\n7\nNew Super Mario Bros.\nDS\n2006\nPlatform\nNintendo\n11.38\n9.23\n6.50\n2.90\n30.01\n\n\n8\nWii Play\nWii\n2006\nMisc\nNintendo\n14.03\n9.20\n2.93\n2.85\n29.02\n\n\n9\nNew Super Mario Bros. Wii\nWii\n2009\nPlatform\nNintendo\n14.59\n7.06\n4.70\n2.26\n28.62\n\n\n10\nDuck Hunt\nNES\n1984\nShooter\nNintendo\n26.93\n0.63\n0.28\n0.47\n28.31\n\n\n\n\n\nCode\nlibrary(tidyverse)\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.4.4     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.0\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\n\n\n\n\nCategorical: game title, platform, year, genre, publisher\nOrdinal: Index, ranking\nQuantitative: US (sales in millions), Europe (sales in millions), Japan (sales in millions), rest of the word (sales in millions), global (sales in millions), reviews in the sales"
  },
  {
    "objectID": "posts/MarksChannels/Asig4_2.html#video-games-sales-1980---2020",
    "href": "posts/MarksChannels/Asig4_2.html#video-games-sales-1980---2020",
    "title": "ASSIGNMENT 4",
    "section": "",
    "text": "The data set contains a list of more that 100,000 copies of video games, from the time period of 1983 - 2012. It is a public data set that it can be obtain by the following website Kaggle - Video Game Sales\nThe data contains the rank of overall sales, game title, platform of the video game release, year of game release, genre of the game, publisher of game, and sales in the millions for US, Europe, Japan, rest of world wide and total global sales.\n\n\nWe have a Flat Table, the items are the rows, wherein each row is the different types of games that has been released from 1983 - 2012. Each item (games) is described by attributes, which are put in columns. Those attributes represent: index, rank, game title, platform, year, genre, publisher, US, Europe, Japan, Rest of the Word, Global (total of sales), and reviews. For each column of the different countries represent the total sales from each one in terms of millions in sales.\n\n\nCode\nlibrary(readxl)\nmy_df &lt;- read_excel(\"VIdeo_Game_sales.xlsx\")\n\nknitr::kable(head(my_df,10))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRank\nName\nPlatform\nYear\nGenre\nPublisher\nNA_Sales\nEU_Sales\nJP_Sales\nOther_Sales\nGlobal_Sales\n\n\n\n\n1\nWii Sports\nWii\n2006\nSports\nNintendo\n41.49\n29.02\n3.77\n8.46\n82.74\n\n\n2\nSuper Mario Bros.\nNES\n1985\nPlatform\nNintendo\n29.08\n3.58\n6.81\n0.77\n40.24\n\n\n3\nMario Kart Wii\nWii\n2008\nRacing\nNintendo\n15.85\n12.88\n3.79\n3.31\n35.82\n\n\n4\nWii Sports Resort\nWii\n2009\nSports\nNintendo\n15.75\n11.01\n3.28\n2.96\n33.00\n\n\n5\nPokemon Red/Pokemon Blue\nGB\n1996\nRole-Playing\nNintendo\n11.27\n8.89\n10.22\n1.00\n31.37\n\n\n6\nTetris\nGB\n1989\nPuzzle\nNintendo\n23.20\n2.26\n4.22\n0.58\n30.26\n\n\n7\nNew Super Mario Bros.\nDS\n2006\nPlatform\nNintendo\n11.38\n9.23\n6.50\n2.90\n30.01\n\n\n8\nWii Play\nWii\n2006\nMisc\nNintendo\n14.03\n9.20\n2.93\n2.85\n29.02\n\n\n9\nNew Super Mario Bros. Wii\nWii\n2009\nPlatform\nNintendo\n14.59\n7.06\n4.70\n2.26\n28.62\n\n\n10\nDuck Hunt\nNES\n1984\nShooter\nNintendo\n26.93\n0.63\n0.28\n0.47\n28.31\n\n\n\n\n\nCode\nlibrary(tidyverse)\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.4.4     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.0\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\n\n\n\n\nCategorical: game title, platform, year, genre, publisher\nOrdinal: Index, ranking\nQuantitative: US (sales in millions), Europe (sales in millions), Japan (sales in millions), rest of the word (sales in millions), global (sales in millions), reviews in the sales"
  },
  {
    "objectID": "posts/MarksChannels/Asig4_2.html#expressiveness-and-effectiveness",
    "href": "posts/MarksChannels/Asig4_2.html#expressiveness-and-effectiveness",
    "title": "ASSIGNMENT 4",
    "section": "Expressiveness and Effectiveness",
    "text": "Expressiveness and Effectiveness\n\n\nCode\nlibrary(tidyr)\nlibrary(ggplot2)\n\nlong_df &lt;- pivot_longer(my_df, cols = c(NA_Sales, JP_Sales, EU_Sales), \n                        names_to = \"Sales_Type\", values_to = \"Sales\")\n\nggplot(long_df, aes(x=Genre, y=Sales, color=Sales_Type)) +\n  geom_boxplot(alpha=0.5) +\n  geom_jitter(width=0.2, height=0, size=1.5) +\n  theme_minimal(base_size = 14) +\n  ggtitle(\"Comparative Video Game Sales by Genre across Regions\") +\n  xlab(\"Video Game Genre\") + ylab(\"Sales (Millions)\") +\n  theme(axis.text.x = element_text(angle = 45, vjust = 0.5),\n        legend.title = element_blank(),\n        plot.title = element_text(face = \"bold\", size = 16),\n        axis.title = element_text(size = 14))\n\n\n\n\n\nFigure 1: It’s a Jitter plot that represents the individual data points for video game sales (in millions) by their Genre from different Regions; these regions are NA (North America), EU (Europe), and JP (Japan). For marks I used Points to present my observations, and my channels are spatial position, shape and color.\n\n\nCode\nlong_df &lt;- pivot_longer(my_df, cols = c(NA_Sales, JP_Sales, EU_Sales, Other_Sales, Global_Sales), \n                        names_to = \"Sales_Type\", values_to = \"Sales\")\n\nggplot(long_df, aes(x=Genre, y=Sales, color=Sales_Type, shape=Sales_Type)) +\n  geom_boxplot(alpha=0.5) +\n  geom_jitter(width=0.2, height=0, size=2.5) +\n  theme_minimal(base_size = 14) +\n  ggtitle(\"Comparative Video Game Sales by Genre across Regions\") +\n  xlab(\"Video Game Genre\") + ylab(\"Sales (Millions)\") +\n  theme(axis.text.x = element_text(angle = 45, vjust = 0.5),\n        legend.title = element_blank(),\n        plot.title = element_text(face = \"bold\", size = 16),\n        axis.title = element_text(size = 14)) +\n  scale_color_brewer(palette = \"Set3\") +\n  guides(shape = guide_legend(override.aes = list(size = 6)))\n\n\n\n\n\nFigure 2: For this second Jitter plot, I added more regions to compare the video game sales (in millions), so now we have the regions NA (North America), EU (Europe), JP (Japan), Other (other countries), and Global. The marks is still the same as the previous plot, but my channels I distorded. I changed the shape for each of the individual regions and its color. These makes it more distorted to understand the data."
  },
  {
    "objectID": "posts/MarksChannels/Asig4_2.html#discriminability",
    "href": "posts/MarksChannels/Asig4_2.html#discriminability",
    "title": "ASSIGNMENT 4",
    "section": "Discriminability",
    "text": "Discriminability\n\n\nCode\ntitle_platform&lt;-my_df%&gt;%\n  select(Platform,Name)%&gt;%\n  group_by(Platform, Name)%&gt;%\n  summarise(count=n_distinct(Name))%&gt;%\n  group_by(Platform) %&gt;%\n  summarise(TotalCount = sum(count))\n\n\n`summarise()` has grouped output by 'Platform'. You can override using the\n`.groups` argument.\n\n\nCode\nsuppressMessages({title_platform&lt;-my_df%&gt;%\n  select(Platform,Name)%&gt;%\n  group_by(Platform,Name)%&gt;%\n  summarise(count=n_distinct(Name))%&gt;%\n  group_by(Platform) %&gt;%\n  summarise(TotalCount = sum(count))})\n\nlibrary(ggplot2)\n\ntitle_platform$Platform &lt;- reorder(title_platform$Platform, title_platform$TotalCount)\n\nlibrary(ggplot2)\n\nlibrary(ggplot2)\n\nggplot(data = title_platform, aes(x = Platform, y = TotalCount, fill = Platform)) +\n  geom_col(color = \"black\", width = 0.7) +\n  ggtitle(\"Comparative Distribution of Game Titles Across Platforms\") +\n  xlab(\"Platform\") + ylab(\"Game Titles\") +\n  scale_fill_viridis_d() +\n  theme_minimal() +\n  theme(\n    plot.title = element_text(face = \"bold\", size = 16),\n    axis.title = element_text(size = 14),\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    legend.position = \"none\"\n  )\n\n\n\n\n\nFigure 3: It’s a Bar plot that represents the distribution of game title counts across from different platforms. For marks, I used “lines” to present my observations, and my channels are spatial position and color. The game title counts are ordered from lowest to highest according to their platform. It helps us to perceive how many games there are for each platform. Looking at the color range it’s from dark blue to bright yellow, meaning that with a brighter color, we have more game titles for that specific platform.\n\n\nCode\nggplot(my_df, aes(x = Platform, fill = Platform)) +\n  geom_bar(color = \"black\", width = 0.7) +\n  ggtitle(\"Platform Distribution\") +\n  xlab(\"Platform\") +\n  ylab(\"Game Titles\") +\n  theme_minimal() +\n  theme(plot.title = element_text(hjust = 0.5),\n        axis.text.x = element_text(angle = 45, hjust = 1))\n\n\n\n\n\nFigure 4: This second Bar plot is the same representation for the distribution of game title counts across from different platforms. I used the same marks and channels from the previous figure. The difference from the previous figure is that there’s no order between game title counts regarding to platform. The color scheme has no meaning that helps as a guide to perceive the highest and lowest count, which just makes it difficult to perceive at first glance."
  },
  {
    "objectID": "posts/MarksChannels/Asig4_2.html#seperability",
    "href": "posts/MarksChannels/Asig4_2.html#seperability",
    "title": "ASSIGNMENT 4",
    "section": "Seperability",
    "text": "Seperability\n\n\nCode\ntitle_year_games &lt;- my_df %&gt;%\n  select(Year, Genre) %&gt;%\n  count(Year, Genre)\n\n\nlibrary(ggplot2)\nlibrary(viridis)  # Load the viridis package for its color palettes\n\n\nLoading required package: viridisLite\n\n\nCode\n# Enhanced ggplot with the viridis color palette\nggplot(title_year_games, aes(x = Year, y = n, fill = Genre)) +\n  geom_bar(stat = \"identity\", position = \"stack\", color = \"grey80\", size = 0.1) +  # Adding subtle borders\n  scale_fill_viridis_d() +  # Use the viridis discrete color palette\n  theme_minimal(base_size = 12) +  # Adjusting base font size for overall consistency\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1, size = 10, color = \"grey20\"),  # Enhancing x-axis labels\n    axis.text.y = element_text(size = 10, color = \"grey20\"),  # Enhancing y-axis labels\n    axis.title.x = element_text(size = 12, face = \"bold\", margin = margin(t = 10)),  # Styling x-axis title\n    axis.title.y = element_text(size = 12, face = \"bold\", margin = margin(r = 10)),  # Styling y-axis title\n    plot.title = element_text(size = 16, face = \"bold\", hjust = 0.5),  # Centering and emphasizing the plot title\n    legend.position = \"right\",  # Adjusting legend position for better layout\n    legend.title = element_text(size = 12),  # Styling the legend title for clarity\n    legend.text = element_text(size = 10)  # Adjusting legend text size for readability\n  ) +\n  ggtitle(\"Number of Games per Genre per Year\") +\n  xlab(\"Year\") +\n  ylab(\"Number of Games\") +\n  scale_x_discrete(breaks = function(x) x[seq(1, length(x), by = 2)])\n\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n\n\n\nFigure 5: The stacked Bar Chart represents the number of games per genre per year. For marks, I used “lines” to present my observations, and my channels are spatial position and color. Looking at the color range it’s from dark blue to bright yellow, meaning that with a darker blue color, we have more number games per genre on per year.\n\n\nCode\ntitle_year_games &lt;- my_df %&gt;%\n  select(Year, Genre) %&gt;%\n  count(Year, Genre)\n\nlibrary(ggplot2)\n\n# Example using title_year_games data frame\nggplot(title_year_games, aes(x = Year, y = n, fill = Genre)) +\n  geom_bar(stat = \"identity\", position = \"stack\") +\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1, size = 10), # Rotate and adjust size of x-axis labels\n    axis.title.x = element_text(size = 12),\n    axis.title.y = element_text(size = 12)\n  ) +\n  ggtitle(\"Number of Games per Genre per Year\") +\n  xlab(\"Year\") +\n  ylab(\"Number of Games\")\n\n\n\n\n\nFigure 6: The stacked Bar Chart represents the number of games per genre per year. For marks, I used “lines” to present my observations, and my channels are spatial position and color. Looking at this chart it’s difficult to distinguish the number of games per genre for some of the years."
  },
  {
    "objectID": "posts/MarksChannels/Asig4_2.html#popout",
    "href": "posts/MarksChannels/Asig4_2.html#popout",
    "title": "ASSIGNMENT 4",
    "section": "Popout",
    "text": "Popout\n\n\nCode\ntitle_genre&lt;-my_df%&gt;%\n  select(Genre,Name)%&gt;%\n  group_by(Genre, Name)%&gt;%\n  summarise(count=n_distinct(Name))%&gt;%\n  group_by(Genre) %&gt;%\n  summarise(TotalCount = sum(count))\n\n\n`summarise()` has grouped output by 'Genre'. You can override using the\n`.groups` argument.\n\n\nCode\nlibrary(ggplot2)\nlibrary(viridis)\n\ntitle_genre$Genre &lt;- reorder(title_genre$Genre, title_genre$TotalCount)\n\nggplot(data = title_genre, aes(x = Genre, y = TotalCount, fill = Genre)) +\n  geom_col(color = \"black\", width = 0.7) +\n  scale_fill_viridis_d(option = \"plasma\", begin = 0.1, end = 0.9) +  # Applying a vibrant color palette with good contrast\n  ggtitle(\"Genre Distribution\") +\n  xlab(\"Genre\") +\n  ylab(\"Game Titles\") +\n  theme_minimal(base_size = 12) +  # Using a minimal theme with a base font size for better readability\n  theme(\n    plot.title = element_text(hjust = 0.5, size = 18, face = \"bold\", color = \"grey20\"),  # Centered and bold title with adjusted color\n    axis.title = element_text(size = 14, face = \"bold\", color = \"grey20\"),  # Bold and slightly larger axis titles for clarity\n    axis.text.x = element_text(angle = 45, hjust = 1, size = 12, color = \"grey20\", vjust = 1),  # Adjusted x-axis labels for better legibility\n    axis.text.y = element_text(size = 12, color = \"grey20\"),  # Y-axis labels with adjusted size and color\n    legend.position = \"none\"  # Removing the legend since the fill color is directly linked to the x-axis labels\n  )\n\n\n\n\n\nFigure 7: The Bar Chart represents the number of game titles per genre. For marks, I used “lines” to present my observations, and my channels are spatial position and color. Looking at the color range it’s from dark purple to bright yellow, meaning that a dark blue color, is the least number of game titles per genre and bright yellow is for the highest number of game titles for that genre w. It is also in order from least number to highest number of game titles per genre.\n\n\nCode\ntitle_genre&lt;-my_df%&gt;%\n  select(Genre,Name)%&gt;%\n  group_by(Genre, Name)%&gt;%\n  summarise(count=n_distinct(Name))%&gt;%\n  group_by(Genre) %&gt;%\n  summarise(TotalCount = sum(count))\n\n\n`summarise()` has grouped output by 'Genre'. You can override using the\n`.groups` argument.\n\n\nCode\nggplot(data = title_genre, aes(x = Genre, y = TotalCount, fill = Genre)) +\n  geom_col(color = \"black\", width = 0.7) +\n  ggtitle(\"Genre Distribution\") +\n  xlab(\"Genre\") +\n  ylab(\"Game Titles\") +\n  theme_minimal(base_size = 12)\n\n\n\n\n\nFigure 8:This Bar Chart represents the number of game titles per genre. For marks, I used “lines” to present my observations, and my channels are spatial position and color. The color scheme and the order of the game titles per genre don’t help to perceive the lowest game titles, for example, the ones that have the same quantity of game titles in different genres, you have to search for them to be able to identify them. The color scheme doesn’t give that pop out to easily identify which game title has the lowest quantity per genre."
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "Hey welcome to Quarto Blog!! Lets get into the Gaming World"
  },
  {
    "objectID": "posts/VisualizationTabularDataPart2/Asig5_2.html",
    "href": "posts/VisualizationTabularDataPart2/Asig5_2.html",
    "title": "Hockey Analytics",
    "section": "",
    "text": "In this assignment, we are going to practice creating visualizations for tabular data. Unlike previous assignments, however, this time we will all be using the same data sets. I’m doing this because I want everyone to engage in the same logic process and have the same design objectives in mind."
  },
  {
    "objectID": "posts/VisualizationTabularDataPart2/Asig5_2.html#overview",
    "href": "posts/VisualizationTabularDataPart2/Asig5_2.html#overview",
    "title": "Hockey Analytics",
    "section": "",
    "text": "In this assignment, we are going to practice creating visualizations for tabular data. Unlike previous assignments, however, this time we will all be using the same data sets. I’m doing this because I want everyone to engage in the same logic process and have the same design objectives in mind."
  },
  {
    "objectID": "posts/VisualizationTabularDataPart2/Asig5_2.html#learning-objectives",
    "href": "posts/VisualizationTabularDataPart2/Asig5_2.html#learning-objectives",
    "title": "Hockey Analytics",
    "section": "LEARNING OBJECTIVES",
    "text": "LEARNING OBJECTIVES\n\nDemonstrate that you can manipulate tabular data to facilitate different visualization tasks. The minimum skills are FILTERING, SELECTING, and SUMMARIZING, all while GROUPING these operations as dictated by your data.\nDemonstrate that you can use tabular data to explore, analyze, and choose the most appropriate visualization idioms given a specific motivating question.\nDemonstrate that you can Find, Access, and Integrate additional data in order to fully address the motivating question.\n\nThe scenario below will allow you to complete the assignment. It deals with data that are of the appropriate complexity and extent (number of observations and variables) to challenge you. If you want to use different data (yours or from another source) I am happy to work with you to make that happen!"
  },
  {
    "objectID": "posts/VisualizationTabularDataPart2/Asig5_2.html#scenario",
    "href": "posts/VisualizationTabularDataPart2/Asig5_2.html#scenario",
    "title": "Hockey Analytics",
    "section": "SCENARIO",
    "text": "SCENARIO\nImagine you are a high priced data science consultant. One of your good friends, Cassandra Canuck, is an Assistant General Manager for the Vancouver Canucks, a team in the National Hockey League with a long, long…. long history of futility.\nThis season feels different.\nThe Canucks are currently among the league leaders and appear to be on their way to their first playoff appearance in many years. A few weeks ago, the Vancouver Canucks decided to trade an underperforming player with a high upside and their first round draft pick to the Calgary Flames for Elias Lindholm, a very solid forward that might prove to be the missing piece of their Stanley Cup puzzle. Exciting!\nExcept that now the Canucks are struggling. They’ve lost 4 straight games and have seemingly lost their identity as a team. The fans are questioning whether the trade was worth it. Woe is me!\nFor the purposes of this exercise, let’s set the 2024 NHL draft order using the Tankathon Simulator. The NHL uses a lottery system in which the teams lowest in the standings have the highest odds of getting the first overall pick. This year the Canucks are at the top of the league, and positioned to have the 31st overall pick. According to the simulator, Calgary will pick at number 2 (which is very valuable!), and the Canuck’s pick at 31.\nHere is a screenshot:\n\n\nHere is the question:\nWas the trade worth it? This trade has a high likelihood of becoming what we call a rental. Elias Lindholm is on an expiring contract, meaning Vancouver is guaranteed to hold his contract only through the end of the season. They might be able to extend him, but that depends on the salary cap.\nMeanwhile, Calgary can draft a player at position 31, who may or may not turn out to be of equal or greater value than Lindholm.\nWas the trade worth it? Did Vancouver or Calgary “win” the trade?\nCan we make some visualizations that help us answer this question?\nHere is an article on modeling draft pick value!\nOriginal analysis!\nEric Tulsky’s original paper*"
  },
  {
    "objectID": "posts/VisualizationTabularDataPart2/Asig5_2.html#directions",
    "href": "posts/VisualizationTabularDataPart2/Asig5_2.html#directions",
    "title": "Hockey Analytics",
    "section": "DIRECTIONS",
    "text": "DIRECTIONS\nCreate a new post in your portfolio for this assignment. Call it something cool, like NHL draft analysis, or Hockey Analytics, or John Wick….\nCopy the data files from the repository, and maybe also the .qmd file.\nUse the .qmd file as the backbone of your assignment, changing the code and the markdown text as you go."
  },
  {
    "objectID": "posts/VisualizationTabularDataPart2/Asig5_2.html#the-data",
    "href": "posts/VisualizationTabularDataPart2/Asig5_2.html#the-data",
    "title": "Hockey Analytics",
    "section": "THE DATA",
    "text": "THE DATA\nHow can we evaluate whether trading a first round pick for a rental player is a good idea? One approach is to look at the historical performance of players from various draft positions.\nI’ve created a data set that will allow us to explore player performance as a function of draft position. If you are curious as to how I obtained and re-arranged these data, you can check out that tutorial here. For this assignment, though, I want to focus on the visualizations.\n\n\nCode\nNHLDraft&lt;-read.csv(\"NHLDraft.csv\")\nNHLDictionary&lt;-read_excel(\"NHLDictionary.xlsx\")\n\nknitr::kable(NHLDictionary)\n\n\n\n\n\n\n\n\n\n\nAttribute\nType\nDescription\n\n\n\n\ndraftyear\nOrdinal\nCalendar year in which the player was drafted into the NHL.\n\n\nname\nItem\nFull name of the player.\n\n\nround\nOrdinal\nRound in which the player was drafted (1 to 7).\n\n\noverall\nOrdinal\nOverall draft position of the player (1 to 224)\n\n\npickinRound\nOrdinal\nPosition in which the player was drafted in their round (1 to 32).\n\n\nheight\nQuantitative\nPlayer height in inches.\n\n\nweight\nQuantitative\nPlayer weight in pounds.\n\n\nposition\nCategorical\nPlayer position (Forward, Defense, Goaltender)\n\n\nplayerId\nItem\nUnique ID (key) assigned to each player.\n\n\npostdraft\nOrdinal\nNumber of seasons since being drafted (0 to 20).\n\n\nNHLgames\nQuantitative\nNumber of games played in the NHL in that particular season (regular season is 82 games, playoffs are up to 28 more).\n\n\n\n\n\nIn this case, we have a dataframe with all the drafted players from 2000-2018, their position, their draft year and position, and then rows for each season since being drafted (postdraft). The key variable here is NHLgames, which tells us how many games they played in the NHL each season since being drafted. Whether drafted players even make the NHL, and how many games they play, might be a good proxy to understand the value of a draft pick we just traded away.\n\n\n\n\n\n\nHINT\n\n\n\nIn the GitHub repository there is a file called NHLdraftstats.csv. What’s in there? Can we use that information?"
  },
  {
    "objectID": "posts/VisualizationTabularDataPart2/Asig5_2.html#analytics-regarding-if-the-trade-was-worth-it",
    "href": "posts/VisualizationTabularDataPart2/Asig5_2.html#analytics-regarding-if-the-trade-was-worth-it",
    "title": "Hockey Analytics",
    "section": "ANALYTICS REGARDING IF THE TRADE WAS WORTH IT",
    "text": "ANALYTICS REGARDING IF THE TRADE WAS WORTH IT\n\n2013 Draft Picks\n\n\nCode\nNHLdraftstats &lt;- read.csv(\"NHLdraftstats.csv\")\n\nlibrary(dplyr)\n\nplayers_stats_2013_2 &lt;- NHLdraftstats %&gt;%\n  filter(draftyear == 2013) %&gt;%\n  filter(name != \"Elias Lindholm\")\n\nggplot(players_stats_2013_2, aes(x=postdraft, y=NHLgames, color=as.factor(round))) +\n  geom_smooth(se=FALSE) +\n  theme_minimal() +\n  ggtitle(\"Overall Players in 2013 by Draft Round\") +\n  xlab(\"Post Draft Position\") +  \n  ylab(\"NHL Games Played\") + \n  theme(plot.title = element_text(hjust = 0.5)) +\n  scale_color_brewer(palette=\"Set1\", name=\"Draft Round\")\n\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\n\n\n\nFigure 1: Representation of the overall players that were drafted in 2013. By looking at this line graph we can determine that the players drafted in Round 1 played the most NHL games compared from the other draft rounds. This indicates that players selected in the first round draft, are valuable players that can bring a lot winnings to the team. The NHL player Elias Lindholm was drafted in this year 2013 in the first round pick.\n\n\nElias Lindholm Performance\nSince, we looked at the overall pick of players that were drafted in 2013, I wanted to look were Elias Lindholm performance lies post draft.\n\n\nCode\nlibrary(dplyr)\nlibrary(ggplot2)\n\nNHLdraftstats &lt;- read.csv(\"NHLdraftstats.csv\")\n\n\nElias_stats &lt;- NHLdraftstats %&gt;%\n  filter(name == \"Elias Lindholm\")\n\nggplot(Elias_stats, aes(x=postdraft, y=NHLgames)) +\n  geom_smooth() +  \n  theme_minimal() +\n  ggtitle(\"Elias Lindholm Performance\") +\n  xlab(\"Post Draft Position\") +  \n  ylab(\"NHL Games Played\") + \n  theme(plot.title = element_text(hjust = 0.5))\n\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\n\n\n\nFigure 2: This line graph represent Elias Lindholm post draft, and we can see that at the beginning of being drafted has played a lot of NHL games, meaning that he is an outstanding player.\n\n\n2013 Draft Pick by Positions\nElias Lindholm is in the forward position, I wanted to see how many players got drafted from the same position in contrast to the other positions.\n\n\nCode\nplayers_stats_2013 &lt;- NHLdraftstats %&gt;%\n  filter(draftyear == 2013)\n\nlibrary(dplyr)\n\n\nagg_data &lt;- players_stats_2013 %&gt;%\n  group_by(round, position) %&gt;%\n  summarise(AvgNHLGames = mean(NHLgames, na.rm = TRUE), .groups = 'drop')\n\n\nggplot(agg_data, aes(x = factor(round), y = AvgNHLGames, fill = factor(round))) +\n  geom_col() +\n  facet_wrap(~position, scales = \"free_y\") +\n  theme_minimal() +\n  ggtitle(\"Average NHL Games Played by Draft Round and Position (2013)\") +\n  xlab(\"Draft Round\") +\n  ylab(\"Average NHL Games Played\") +\n  scale_fill_brewer(palette = \"Set1\", name = \"Draft Round\") +\n  theme(plot.title = element_text(hjust = 0.5),\n        axis.text.x = element_text(angle = 45, hjust = 1, size = 12))\n\n\n\n\n\nFigure3: The following bar graphs are divided by position, by round and the average of NHL played games from the players that were drafted in 2013. By looking at this graphs we can say that the positions for forward and defense are highly drafted in the first round and are the ones that played the most in NHL games. The Goal Tender there’s no overall pick in this 2013 draft pick. Meaning that these two positions for defense and forward are the most highly looked for selecting players.\n\n\nElias Lindholm vs Drafted Players 2013 Performance\nWe now that Elias Lindholm has a good performance after being drafted. I wanted to compare with the other players that were also drafted on 2013. This will help me have a perspective why Calgary did the trade with Vancouver for him.\n\n\nCode\nplayers_stats_2013 &lt;- NHLdraftstats %&gt;%\n  filter(draftyear == 2013)\n\nlibrary(dplyr)\nlibrary(ggplot2)\n\n# Calculate the average NHL games played by players other than Elias Lindholm\naverage_games &lt;- players_stats_2013 %&gt;%\n  filter(name != \"Elias Lindholm\") %&gt;%\n  summarise(average_NHL_games = mean(NHLgames, na.rm = TRUE))\n\n# Calculate Elias Lindholm's average NHL games\nelias_avg_games &lt;- players_stats_2013 %&gt;%\n  filter(name == \"Elias Lindholm\") %&gt;%\n  summarise(NHLgames = mean(NHLgames, na.rm = TRUE)) %&gt;%\n  mutate(name = \"Elias Lindholm\", category = \"Individual\")\n\n# Create a data frame for the draft average\naverage_df &lt;- data.frame(\n  name = \"2013 Draft Average\",\n  NHLgames = average_games$average_NHL_games,\n  category = \"Average\"\n)\n\n# Ensure both data frames have the same structure and combine them\ncomparison_data &lt;- rbind(elias_avg_games, average_df)\n\n# Create the bar graph comparing Elias Lindholm's NHL games played to the 2013 draft average\nggplot(comparison_data, aes(x = name, y = NHLgames, fill = category)) +\n  geom_col() +\n  theme_minimal() +\n  ggtitle(\"Elias Lindholm vs. 2013 Draft Average NHL Games Played\") +\n  xlab(\"Category\") +\n  ylab(\"NHL Games Played\") +\n  scale_fill_manual(values = c(\"Average\" = \"red\", \"Individual\" = \"blue\")) +\n  theme(plot.title = element_text(hjust = 0.5), axis.text.x = element_blank())\n\n\n\n\n\nFigure 4: In this bar graph is comparison between the performance of Elias Lindholm vs the drafted players of 2013. I took the average of the NHL games played of the drafted players (is the one label as average and the blue bar) and also the average for Elias’s performance (is the one label as individual and the red bar). By looking at this graph we can say that Elias’s performance is alot higher than the overall average of the players that were drafted at the same year as Elias.\n\n\nElias Lindholm vs Forward Players (Drafted in 2013)\nWe now that Elias Lindholm has a good performance after being drafted compared to other players that were drafted on the same year. Now, I wanted to compare the performance with players that have the same position as Elias. This also, will give more insight the decision of the trade.\n\n\nCode\nforwards_2013 &lt;- players_stats_2013 %&gt;%\n  filter(draftyear == 2013, position == \"Forward\") %&gt;%\n  select(name, position, NHLgames) \n\nlibrary(dplyr)\n\n# Mark Elias Lindholm and other players\nplayers_stats_2013 &lt;- players_stats_2013 %&gt;%\n  mutate(Category = ifelse(name == \"Elias Lindholm\", \"Elias Lindholm\", \"Other Players\"))\n\n# Calculate average NHL games for Elias and other players\navg_games_comparison &lt;- players_stats_2013 %&gt;%\n  group_by(Category) %&gt;%\n  summarise(AverageNHLGames = mean(NHLgames, na.rm = TRUE))\n\n# Plot\nggplot(avg_games_comparison, aes(x = Category, y = AverageNHLGames, fill = Category)) +\n  geom_col() +\n  theme_minimal() +\n  ggtitle(\"Average NHL Games: Elias Lindholm vs Other Forwards (2013 Draft)\") +\n  xlab(\"\") +\n  ylab(\"Average NHL Games Played\") +\n  scale_fill_manual(values = c(\"Elias Lindholm\" = \"blue\", \"Other Players\" = \"red\"))\n\n\n\n\n\nFigure 4: In this bar graph is comparison between the performance of Elias Lindholm vs the players on the same position as forward. I took the average of the NHL games played of the drafted players (is the one label as Other Players) and also the average for Elias’s performance (Blue bar). By looking at this graph we can say that Elias’s performance is alot higher than the overall average of the players that were drafted at the same year as Elias in the postion as forward.\n\n\nElias Lindholm vs. Forwards (Drafted in 2018)\nWe now that Elias Lindholm has a good performance, now I wanted to compare its performance with forward players that were drafted in 2018. It is clear that Elias has more experience and has alot of exposure in playing alot of NHL games. I just wanted to see and compare their performances between the two variables. Like having an experience player is better than acquiring new players.\n\n\nCode\nlibrary(dplyr)\n\nplayers_stats_2018 &lt;- NHLdraftstats %&gt;%\n  filter(draftyear == 2018, position == \"Forward\") %&gt;%\n  select(name, position, NHLgames) \n\nlibrary(dplyr)\nlibrary(ggplot2)\n\n# Assuming Elias Lindholm is also a forward and you want his stats\nelias_metric &lt;- NHLdraftstats %&gt;%\n  filter(name == \"Elias Lindholm\", position == \"Forward\") %&gt;%\n  summarise(AverageNHLGames = mean(NHLgames, na.rm = TRUE))\n\n# Calculate the average NHL games for forwards drafted in 2018\navg_2018_metric &lt;- players_stats_2018 %&gt;%\n  filter(position == \"Forward\") %&gt;%\n  summarise(AverageNHLGames = mean(NHLgames, na.rm = TRUE))\n\n# Combine the data for comparison\ncomparison_data &lt;- rbind(\n  data.frame(Name = \"Elias Lindholm\", Metric = elias_metric$AverageNHLGames),\n  data.frame(Name = \"2018 Forwards\", Metric = avg_2018_metric$AverageNHLGames)\n)\n\n# Plot the comparison\nggplot(comparison_data, aes(x = Name, y = Metric, fill = Name)) +\n  geom_col() +\n  theme_minimal() +\n  ggtitle(\"Comparison: Elias Lindholm vs. 2018 Forwards\") +\n  ylab(\"Average NHL Games Played\") +\n  xlab(\"\") +\n  scale_fill_manual(values = c(\"Elias Lindholm\" = \"blue\", \"2018 Forwards\" = \"red\"))\n\n\n\n\n\nFigure 5: In this bar graph is comparison between the performance of Elias Lindholm vs forward players drafted in 2018. I took the average of the NHL games played of the 2018 Forwards (Red Bar) and also the average for Elias’s performance (Blue bar). By looking at this graph we can say that Elias’s performance is alot higher than the overall average of the Forward players that were drafted in 2018. But, this is also due that Elias has alot more experience than the players drafted in 2018."
  },
  {
    "objectID": "posts/VisualizationTabularDataPart2/Asig5_2.html#conclusion",
    "href": "posts/VisualizationTabularDataPart2/Asig5_2.html#conclusion",
    "title": "Hockey Analytics",
    "section": "CONCLUSION",
    "text": "CONCLUSION\nBased on my visualizations, I think the Vancouver Canucks got a good trade with Elias Lindholm. He’s a solid forward based on the comparison data of other players in the same position in the same draft year; Elias Lindholm is a player in another league. Maybe, the reason that the Canucks made the trade with the Calgary Flames; is that they needed a player that could bring them the win of the Stanley Cup. The Canucks are thinking about their current gaming plan; and not too much about the future. Maybe the Calgary Flames wanted new players to improve their gaming strategies, and have a solid team for the future NHL games."
  },
  {
    "objectID": "posts/NetworkData/index.html",
    "href": "posts/NetworkData/index.html",
    "title": "Practice with Network Data",
    "section": "",
    "text": "In this assignment, we’ll consider some of the tools and techniques for visualizing network data. Network data is characterized by two unique items that are not found in tabular or spatial data - Nodes and Links. In addition, there is a sub-type of network data that we will consider - Hierarchical or Tree data. Let’s practice a few visualizations to get a feel for how these things work!"
  },
  {
    "objectID": "posts/NetworkData/index.html#igraph",
    "href": "posts/NetworkData/index.html#igraph",
    "title": "Practice with Network Data",
    "section": "IGRAPH",
    "text": "IGRAPH\nLet’s start with igraph, which is an open source toolset for network analysis. The great thing about igraph is that you can use these tools in R, Python, Mathematica, and C++. It is very flexible and very powerful.\n\nigraph in R\nFirst up, we’ll install R/igraph and load the library (note that I’ve commented out the package installation because I’ve already installed igraph on my machine):\n\n\nCode\n# install.packages(\"igraph\")\nlibrary(igraph)\n\n\nWarning: package 'igraph' was built under R version 4.3.3\n\n\n\nAttaching package: 'igraph'\n\n\nThe following objects are masked from 'package:stats':\n\n    decompose, spectrum\n\n\nThe following object is masked from 'package:base':\n\n    union\n\n\nNow I’m going to walk you through a modified version of the igraph tutorial, which you can find here"
  },
  {
    "objectID": "posts/NetworkData/index.html#creating-a-graph",
    "href": "posts/NetworkData/index.html#creating-a-graph",
    "title": "Practice with Network Data",
    "section": "Creating a graph",
    "text": "Creating a graph\nigraph offers many ways to create a graph. The simplest one is the function make_empty_graph:\n\n\nCode\ng &lt;- make_empty_graph()\n\n\nThe most common way to create a graph is make_graph, which constructs a network based on specified edges. For example, to make a graph with 10 nodes (numbered 1 to 10) and two edges connecting nodes 1-2 and 1-5:\n\n\nCode\ng &lt;- make_graph(edges = c(1,2, 1,5), n=10, directed = FALSE)\n\n\nWe can print the graph to get a summary of its nodes and edges:\n\n\nCode\ng\n\n\nIGRAPH dede6f4 U--- 10 2 -- \n+ edges from dede6f4:\n[1] 1--2 1--5\n\n\nThis means: Undirected Named graph with 10 vertices and 2 edges, with the exact edges listed out. If the graph has a [name] attribute, it is printed as well.\n\n\n\n\n\n\nNote\n\n\n\nsummary does not list the edges, which is convenient for large graphs with millions of edges:\n\n\n\n\nCode\nsummary(g)\n\n\nIGRAPH dede6f4 U--- 10 2 -- \n\n\nThe same function make_graph can create some notable graphs by just specifying their name. For example you can create the graph that represents the social network of Zachary’s karate club, that shows the friendship between 34 members of a karate club at a US university in the 1970s:\n\n\nCode\ng &lt;- make_graph('Zachary')\n\n\nTo visualize a graph you can use plot:\n\n\nCode\nplot(g)"
  },
  {
    "objectID": "posts/NetworkData/index.html#vertex-and-edge-ids",
    "href": "posts/NetworkData/index.html#vertex-and-edge-ids",
    "title": "Practice with Network Data",
    "section": "Vertex and edge IDs",
    "text": "Vertex and edge IDs\nVertices and edges have numerical vertex IDs in igraph. Vertex IDs are always consecutive and they start with 1. For a graph with n vertices the vertex IDs are always between 1 and n. If some operation changes the number of vertices in the graphs, e.g. a subgraph is created via induced_subgraph, then the vertices are renumbered to satisfy this criterion.\nThe same is true for the edges as well: edge IDs are always between 1 and m, the total number of edges in the graph.\nIn addition to IDs, vertices and edges can be assigned a name and other attributes. That makes it easier to track them whenever the graph is altered."
  },
  {
    "objectID": "posts/NetworkData/index.html#addingdeleting-vertices-and-edges",
    "href": "posts/NetworkData/index.html#addingdeleting-vertices-and-edges",
    "title": "Practice with Network Data",
    "section": "Adding/deleting vertices and edges",
    "text": "Adding/deleting vertices and edges\nLet’s continue working with the Karate club graph. To add one or more vertices to an existing graph, use add_vertices:\n\n\nCode\ng &lt;- add_vertices(g, 3)\n\n\nSimilarly, to add edges you can use add_edges:\n\n\nCode\ng &lt;- add_edges(g, edges = c(1,35, 1,36, 34,37))\n\n\nEdges are added by specifying the source and target vertex IDs for each edge. This call added three edges, one connecting vertices 1 and 35, one connecting vertices 1 and 36, and one connecting vertices 34 and 37.\nIn addition to the add_vertices and add_edges functions, the plus operator can be used to add vertices or edges to graph. The actual operation that is performed depends on the type of the right hand side argument:\n\n\nCode\ng &lt;- g + edges(c(1,35, 1,36, 34,37))\n\n\nYou can add a single vertex/edge at a time using add_vertex and add_edge.\nLet us add some more vertices and edges to our graph. In igraph we can use the magrittr package, which provides a mechanism for chaining commands with the operator %\\&gt;%:\n\n\nCode\ng &lt;- g %&gt;% add_edges(edges=c(1,34)) %&gt;% add_vertices(3) %&gt;%\n     add_edges(edges=c(38,39, 39,40, 40,38, 40,37))\ng\n\n\nIGRAPH df2300f U--- 40 86 -- Zachary\n+ attr: name (g/c)\n+ edges from df2300f:\n [1]  1-- 2  1-- 3  1-- 4  1-- 5  1-- 6  1-- 7  1-- 8  1-- 9  1--11  1--12\n[11]  1--13  1--14  1--18  1--20  1--22  1--32  2-- 3  2-- 4  2-- 8  2--14\n[21]  2--18  2--20  2--22  2--31  3-- 4  3-- 8  3--28  3--29  3--33  3--10\n[31]  3-- 9  3--14  4-- 8  4--13  4--14  5-- 7  5--11  6-- 7  6--11  6--17\n[41]  7--17  9--31  9--33  9--34 10--34 14--34 15--33 15--34 16--33 16--34\n[51] 19--33 19--34 20--34 21--33 21--34 23--33 23--34 24--26 24--28 24--33\n[61] 24--34 24--30 25--26 25--28 25--32 26--32 27--30 27--34 28--34 29--32\n[71] 29--34 30--33 30--34 31--33 31--34 32--33 32--34 33--34  1--35  1--36\n+ ... omitted several edges\n\n\nCode\nplot(g)\n\n\n\n\n\nWe now have an undirected graph with 40 vertices and 86 edges. Vertex and edge IDs are always contiguous, so if you delete a vertex all subsequent vertices will be renumbered. When a vertex is renumbered, edges are not renumbered, but their source and target vertices will be. Use delete_vertices and delete_edges to perform these operations. For instance, to delete the edge connecting vertices 1-34, get its ID and then delete it:\n\n\nCode\nget.edge.ids(g, c(1,34))\n\n\n[1] 82\n\n\n\n\nCode\ng &lt;- delete_edges(g, 82)\n\n\nAs an example, to create a broken ring:\n\n\nCode\ng &lt;- make_ring(10) %&gt;% delete_edges(\"10|1\")\nplot(g)\n\n\n\n\n\nThe example above shows that you can also refer to edges with strings containing the IDs of the source and target vertices, connected by a pipe symbol |. \"10|1\" in the above example means the edge that connects vertex 10 to vertex 1. Of course you can also use the edge IDs directly, or retrieve them with the get.edge.ids function:\n\n\nCode\ng &lt;- make_ring(5)\ng &lt;- delete_edges(g, get.edge.ids(g, c(1,5, 4,5)))\nplot(g)"
  },
  {
    "objectID": "posts/NetworkData/index.html#constructing-graphs",
    "href": "posts/NetworkData/index.html#constructing-graphs",
    "title": "Practice with Network Data",
    "section": "Constructing graphs",
    "text": "Constructing graphs\nIn addition to make_empty_graph, make_graph, and make_graph_from_literal, igraph includes many other function to construct a graph. Some are deterministic, i.e. they produce the same graph each single time, e.g. make_tree:\n\n\nCode\ngraph1 &lt;- make_tree(127, 2, mode = \"undirected\")\nsummary(graph1)\n\n\nIGRAPH df79452 U--- 127 126 -- Tree\n+ attr: name (g/c), children (g/n), mode (g/c)\n\n\nCode\nplot(graph1)\n\n\n\n\n\nThis generates a regular tree graph with 127 vertices, each vertex having two children. No matter how many times you call make_tree, the generated graph will always be the same if you use the same parameters:\n\n\nCode\ngraph2 &lt;- make_tree(127, 2, mode = \"undirected\")\n\n\n\n\nCode\nidentical_graphs(graph1,graph2)\n\n\n[1] TRUE\n\n\nOther functions generate graphs stochastically, i.e. they produce a different graph each time. For instance sample_grg:\n\n\nCode\ngraph1 &lt;- sample_grg(100, 0.2)\nsummary(graph1)\n\n\nIGRAPH dfb47e0 U--- 100 558 -- Geometric random graph\n+ attr: name (g/c), radius (g/n), torus (g/l)\n\n\nCode\nplot(graph1)\n\n\n\n\n\nThis generates a geometric random graph: n points are chosen randomly and uniformly inside the unit square and pairs of points closer to each other than a predefined distance d are connected by an edge. If you generate GRGs with the same parameters, they will be different:\n\n\nCode\ngraph2 &lt;- sample_grg(100, 0.2)\nidentical_graphs(graph1, graph2)\n\n\n[1] FALSE\n\n\nCode\nplot(graph2)\n\n\n\n\n\nA slightly looser way to check if the graphs are equivalent is via isomorphic. Two graphs are said to be isomorphic if they have the same number of components (vertices and edges) and maintain a one-to-one correspondence between vertices and edges, i.e., they are connected in the same way.\n\n\nCode\nisomorphic(graph1, graph2)\n\n\n[1] FALSE\n\n\nChecking for isomorphism can take a while for large graphs (in this case, the answer can quickly be given by checking the degree sequence of the two graphs). identical_graph is a stricter criterion than isomorphic: the two graphs must have the same list of vertices and edges, in exactly the same order, with same directedness, and the two graphs must also have identical graph, vertex and edge attributes."
  },
  {
    "objectID": "posts/NetworkData/index.html#setting-and-retrieving-attributes",
    "href": "posts/NetworkData/index.html#setting-and-retrieving-attributes",
    "title": "Practice with Network Data",
    "section": "Setting and retrieving attributes",
    "text": "Setting and retrieving attributes\nIn addition to IDs, vertex and edges can have attributes such as a name, coordinates for plotting, metadata, and weights. The graph itself can have such attributes too (e.g. a name, which will show in summary). In a sense, every graph, vertex and edge can be used as an R namespace to store and retrieve these attributes.\nTo demonstrate the use of attributes, let us create a simple social network:\n\n\nCode\ng &lt;- make_graph(~ Alice-Bob:Claire:Frank, Claire-Alice:Dennis:Frank:Esther,\n                George-Dennis:Frank, Dennis-Esther)\n\n\nEach vertex represents a person, so we want to store ages, genders and types of connection between two people (is_formal refers to whether a connection between one person or another is formal or informal, i.e. colleagues or friends). The \\$ operator is a shortcut to get and set graph attributes. It is shorter and just as readable as graph_attr and set_graph_attr.\n\n\nCode\nV(g)$age &lt;- c(25, 31, 18, 23, 47, 22, 50) \nV(g)$gender &lt;- c(\"f\", \"m\", \"f\", \"m\", \"m\", \"f\", \"m\")\nE(g)$is_formal &lt;- c(FALSE, FALSE, TRUE, TRUE, TRUE, FALSE, TRUE, FALSE, FALSE)\nsummary(g)\n\n\nIGRAPH e01e7b9 UN-- 7 9 -- \n+ attr: name (v/c), age (v/n), gender (v/c), is_formal (e/l)\n\n\nV and E are the standard way to obtain a sequence of all vertices and edges, respectively. This assigns an attribute to all vertices/edges at once. Another way to generate our social network is with the use of set_vertex_attr and set_edge_attr and the operator %\\&gt;%:\n\n\nCode\ng &lt;- make_graph(~ Alice-Bob:Claire:Frank, Claire-Alice:Dennis:Frank:Esther,\n                George-Dennis:Frank, Dennis-Esther) %&gt;%\n  set_vertex_attr(\"age\", value = c(25, 31, 18, 23, 47, 22, 50)) %&gt;%\n  set_vertex_attr(\"gender\", value = c(\"f\", \"m\", \"f\", \"m\", \"m\", \"f\", \"m\")) %&gt;%\n  set_edge_attr(\"is_formal\", value = c(FALSE, FALSE, TRUE, TRUE, TRUE, FALSE, TRUE, FALSE, FALSE))\nsummary(g)\n\n\nTo assign or modify an attribute for a single vertex/edge:\n\n\nCode\nE(g)$is_formal\n\n\n[1] FALSE FALSE  TRUE  TRUE  TRUE FALSE  TRUE FALSE FALSE\n\n\nCode\nE(g)$is_formal[1] &lt;- TRUE\nE(g)$is_formal\n\n\n[1]  TRUE FALSE  TRUE  TRUE  TRUE FALSE  TRUE FALSE FALSE\n\n\nAttribute values can be set to any R object, but note that storing the graph in some file formats might result in the loss of complex attribute values. Vertices, edges and the graph itself can all be used to set attributes, e.g. to add a date to the graph:\n\n\nCode\ng$date &lt;- c(\"2022-02-11\")\ngraph_attr(g, \"date\")\n\n\n[1] \"2022-02-11\"\n\n\nTo retrieve attributes, you can also use graph_attr, vertex_attr, and edge_attr. To find the ID of a vertex you can use the function match:\n\n\nCode\nmatch(c(\"George\"), V(g)$name)\n\n\n[1] 7\n\n\nTo assign attributes to a subset of vertices or edges, you can use:\n\n\nCode\nV(g)$name[1:3] &lt;- c(\"Alejandra\", \"Bruno\", \"Carmina\")\nV(g)\n\n\n+ 7/7 vertices, named, from e01e7b9:\n[1] Alejandra Bruno     Carmina   Frank     Dennis    Esther    George   \n\n\nTo delete attributes:\n\n\nCode\ng &lt;- delete_vertex_attr(g, \"gender\")\nV(g)$gender\n\n\nNULL\n\n\nIf you want to save a graph in R with all the attributes use the R’s standard function dput function and retrieve it later with dget. You can also just save the R workspace and restore it later."
  },
  {
    "objectID": "posts/NetworkData/index.html#structural-properties-of-graphs",
    "href": "posts/NetworkData/index.html#structural-properties-of-graphs",
    "title": "Practice with Network Data",
    "section": "Structural properties of graphs",
    "text": "Structural properties of graphs\nigraph provides a large set of functions to calculate various structural properties of graphs. It is beyond the scope of this tutorial to document all of them, hence this section will only introduce a few of them for illustrative purposes. We will work on the small social network constructed in the previous section.\nPerhaps the simplest property one can think of is the degree. The degree of a vertex equals the number of edges adjacent to it. In case of directed networks, we can also define in-degree (the number of edges pointing towards the vertex) and out-degree (the number of edges originating from the vertex). igraph is able to calculate all of them using a simple syntax:\n\n\nCode\ndegree(g)\n\n\nAlejandra     Bruno   Carmina     Frank    Dennis    Esther    George \n        3         1         4         3         3         2         2 \n\n\nIf the graph was directed, we would have been able to calculate the in- and out-degrees separately using degree(mode=\"in\") and degree(mode=\"out\"). You can also pass a single vertex ID or a list of vertex IDs to degree if you want to calculate the degrees for only a subset of vertices:\n\n\nCode\ndegree(g, 7)\n\n\nGeorge \n     2 \n\n\n\n\nCode\ndegree(g, v=c(3,4,5))\n\n\nCarmina   Frank  Dennis \n      4       3       3 \n\n\nMost functions that accept vertex IDs also accept vertex names (i.e. the values of the name vertex attribute) as long as the names are unique:\n\n\nCode\ndegree(g, v=c(\"Carmina\", \"Frank\", \"Dennis\"))\n\n\nCarmina   Frank  Dennis \n      4       3       3 \n\n\nIt also works for single vertices:\n\n\nCode\ndegree(g, \"Bruno\")\n\n\nBruno \n    1 \n\n\nA similar syntax is used for most of the structural properties igraph can calculate. For vertex properties, the functions accept a vertex ID, a vertex name, or a list of vertex IDs or names (and if they are omitted, the default is the set of all vertices). For edge properties, the functions accept a single edge ID or a list of edge IDs.\n\nNOTE: For some measures, it does not make sense to calculate them only for a few vertices or edges instead of the whole graph, as it would take the same time anyway. In this case, the functions won’t accept vertex or edge IDs, but you can still restrict the resulting list later using standard operations. One such example is eigenvector centrality (evcent()).\n\nBesides degree, igraph includes built-in routines to calculate many other centrality properties, including vertex and edge betweenness (edge_betweenness) or Google’s PageRank (page_rank) just to name a few. Here we just illustrate edge betweenness:\n\n\nCode\nedge_betweenness(g)\n\n\n[1] 6 6 4 3 4 4 4 2 3\n\n\nNow we can also figure out which connections have the highest betweenness centrality:\n\n\nCode\nebs &lt;- edge_betweenness(g)\nas_edgelist(g)[ebs == max(ebs), ]\n\n\n     [,1]        [,2]     \n[1,] \"Alejandra\" \"Bruno\"  \n[2,] \"Alejandra\" \"Carmina\""
  },
  {
    "objectID": "posts/NetworkData/index.html#querying-vertices-and-edges-based-on-attributes",
    "href": "posts/NetworkData/index.html#querying-vertices-and-edges-based-on-attributes",
    "title": "Practice with Network Data",
    "section": "Querying vertices and edges based on attributes",
    "text": "Querying vertices and edges based on attributes\n\nSelecting vertices\nImagine that in a given social network, you want to find out who has the largest degree. You can do that with the tools presented so far and the which.max function:\n\n\nCode\nwhich.max(degree(g))\n\n\nCarmina \n      3 \n\n\nAnother example would be to select only vertices that have only odd IDs but not even ones, using the V function:\n\n\nCode\ngraph &lt;- graph.full(n=10)\nonly_odd_vertices &lt;- which(V(graph)%%2==1)\nlength(only_odd_vertices)\n\n\n[1] 5\n\n\nOf course, it is possible to select vertices or edges by positional indices:\n\n\nCode\nseq &lt;- V(graph)[2, 3, 7]\nseq\n\n\n+ 3/10 vertices, from e079061:\n[1] 2 3 7\n\n\n\n\nCode\nseq &lt;- seq[1, 3]    # filtering an existing vertex set\nseq\n\n\n+ 2/10 vertices, from e079061:\n[1] 2 7\n\n\nSelecting a vertex that does not exist results in an error:\n\n\nCode\nseq &lt;- V(graph)[2, 3, 7, \"foo\", 3.5]\n## Error in simple_vs_index(x, ii, na_ok) : Unknown vertex selected\n\n\nAttribute names can also be used as-is within the indexing brackets of V() and E(). This can be combined with R’s ability to use boolean vectors for indexing to obtain very concise and readable expressions to retrieve a subset of the vertex or edge set of a graph. For instance, the following command gives you the names of the individuals younger than 30 years in our social network:\n\n\nCode\nV(g)[age &lt; 30]$name\n\n\n[1] \"Alejandra\" \"Carmina\"   \"Frank\"     \"Esther\"   \n\n\nOf course, &lt; is not the only boolean operator that can be used for this. Other possibilities include the following:\n\n\n\n\n\n\n\nOperator\nMeaning\n\n\n\n\n==\nThe attribute/property value must be equal to\n\n\n!=\nThe attribute/property value must not be equal to\n\n\n&lt;\nThe attribute/property value must be less than\n\n\n&lt;=\nThe attribute/property value must be less than or equal to\n\n\n&gt;\nThe attribute/property value must be greater than\n\n\n&gt;=\nThe attribute/property value must be greater than or equal to\n\n\n%in%\nThe attribute/property value must be included in\n\n\n\nYou can also create a “not in” operator from %in% using the Negate function:\n\n\nCode\n`%notin%` &lt;- Negate(`%in%`)\n\n\nIf an attribute has the same name as an igraph function, you should be careful as the syntax can become a little confusing. For instance, if there is an attribute named degree that represents the grades of an exam for each person, that should not be confused with the igraph function that computes the degrees of vertices in a network sense:\n\n\nCode\nV(g)$degree &lt;- c(\"A\", \"B\", \"B+\", \"A+\", \"C\", \"A\", \"B\")\nV(g)$degree[degree(g) == 3]\n\n\n[1] \"A\"  \"A+\" \"C\" \n\n\n\n\nCode\nV(g)$name[degree(g) == 3]\n\n\n[1] \"Alejandra\" \"Frank\"     \"Dennis\"   \n\n\n\n\nSelecting edges\nEdges can be selected based on attributes just like vertices. As mentioned above, the standard way to get edges is E. Moreover, there are a few special structural properties for selecting edges.\nUsing .from allows you to filter the edge sequence based on the source vertices of the edges. E.g., to select all the edges originating from Carmina (who has vertex index 3):\n\n\nCode\nE(g)[.from(3)]\n\n\n+ 4/9 edges from e01e7b9 (vertex names):\n[1] Alejandra--Carmina Carmina  --Frank   Carmina  --Dennis  Carmina  --Esther \n\n\nOf course it also works with vertex names:\n\n\nCode\nE(g)[.from(\"Carmina\")]\n\n\n+ 4/9 edges from e01e7b9 (vertex names):\n[1] Alejandra--Carmina Carmina  --Frank   Carmina  --Dennis  Carmina  --Esther \n\n\nUsing .to filters edge sequences based on the target vertices. This is different from .from if the graph is directed, while it gives the same answer for undirected graphs. Using .inc selects only those edges that are incident on a single vertex or at least one of the vertices, irrespectively of the edge directions.\nThe %--% operator can be used to select edges between specific groups of vertices, ignoring edge directions in directed graphs. For instance, the following expression selects all the edges between Carmina (vertex index 3), Dennis (vertex index 5) and Esther (vertex index 6):\n\n\nCode\nE(g) [ 3:5 %--% 5:6 ]\n\n\n+ 3/9 edges from e01e7b9 (vertex names):\n[1] Carmina--Dennis Carmina--Esther Dennis --Esther\n\n\nTo make the %--% operator work with names, you can build string vectors containing the names and then use these vectors as operands. For instance, to select all the edges that connect men to women, we can do the following after re-adding the gender attribute that we deleted earlier:\n\n\nCode\nV(g)$gender &lt;- c(\"f\", \"m\", \"f\", \"m\", \"m\", \"f\", \"m\")\n\n\n\n\nCode\nmen &lt;- V(g)[gender == \"m\"]$name\nmen\n\n\n[1] \"Bruno\"  \"Frank\"  \"Dennis\" \"George\"\n\n\n\n\nCode\nwomen &lt;- V(g)[gender == \"f\"]$name\nwomen\n\n\n[1] \"Alejandra\" \"Carmina\"   \"Esther\"   \n\n\n\n\nCode\nE(g)[men %--% women]\n\n\n+ 5/9 edges from e01e7b9 (vertex names):\n[1] Alejandra--Bruno  Alejandra--Frank  Carmina  --Frank  Carmina  --Dennis\n[5] Dennis   --Esther"
  },
  {
    "objectID": "posts/NetworkData/index.html#treating-a-graph-as-an-adjacency-matrix",
    "href": "posts/NetworkData/index.html#treating-a-graph-as-an-adjacency-matrix",
    "title": "Practice with Network Data",
    "section": "Treating a graph as an adjacency matrix",
    "text": "Treating a graph as an adjacency matrix\nThe adjacency matrix is another way to represent a graph. In an adjacency matrix, rows and columns are labeled by graph vertices, and the elements of the matrix indicate the number of edges between vertices i and j. The adjacency matrix for the example graph is:\n\n\nCode\nget.adjacency(g)\n\n\nWarning: `get.adjacency()` was deprecated in igraph 2.0.0.\nℹ Please use `as_adjacency_matrix()` instead.\n\n\n7 x 7 sparse Matrix of class \"dgCMatrix\"\n          Alejandra Bruno Carmina Frank Dennis Esther George\nAlejandra         .     1       1     1      .      .      .\nBruno             1     .       .     .      .      .      .\nCarmina           1     .       .     1      1      1      .\nFrank             1     .       1     .      .      .      1\nDennis            .     .       1     .      .      1      1\nEsther            .     .       1     .      1      .      .\nGeorge            .     .       .     1      1      .      .\n\n\nFor example, Carmina (1, 0, 0, 1, 1, 1, 0) is directly connected to Alejandra (who has vertex index 1), Frank (index 4), Dennis (index 5) and Esther (index 6), but not to Bruno (index 2) or to George (index 7)."
  },
  {
    "objectID": "posts/NetworkData/index.html#layouts-and-plotting",
    "href": "posts/NetworkData/index.html#layouts-and-plotting",
    "title": "Practice with Network Data",
    "section": "Layouts and plotting",
    "text": "Layouts and plotting\nA graph is an abstract mathematical object without a specific representation in 2D, 3D or any other geometric space. This means that whenever we want to visualise a graph, we have to find a mapping from vertices to coordinates in two- or three-dimensional space first, preferably in a way that is useful and/or pleasing for the eye. A separate branch of graph theory, namely graph drawing, tries to solve this problem via several graph layout algorithms. igraph implements quite a few layout algorithms and is also able to draw them onto the screen or to any output format that R itself supports.\n\nLayout algorithms\nThe layout functions in igraph always start with layout. The following table summarises them:\n\n\n\n\n\n\n\nMethod name\nAlgorithm description\n\n\n\n\nlayout_randomly\nPlaces the vertices completely randomly\n\n\nlayout_in_circle\nDeterministic layout that places the vertices on a circle\n\n\nlayout_on_sphere\nDeterministic layout that places the vertices evenly on the surface of a sphere\n\n\nlayout_with_drl\nThe Drl (Distributed Recursive Layout) algorithm for large graphs\n\n\nlayout_with_fr\nFruchterman-Reingold force-directed algorithm\n\n\nlayout_with_kk\nKamada-Kawai force-directed algorithm\n\n\nlayout_with_lgl\nThe LGL (Large Graph Layout) algorithm for large graphs\n\n\nlayout_as_tree\nReingold-Tilford tree layout, useful for (almost) tree-like graphs\n\n\nlayout_nicely\nLayout algorithm that automatically picks one of the other algorithms based on certain properties of the graph\n\n\n\nLayout algorithms can be called directly with a graph as its first argument. They will return a matrix with two columns and as many rows as the number of vertices in the graph; each row will correspond to the position of a single vertex, ordered by vertex IDs. Some algorithms have a 3D variant; in this case they return three columns instead of 2.\n\n\nCode\nlayout &lt;- layout_with_kk(g)\n\n\nSome layout algorithms take additional arguments; e.g., when laying out a graph as a tree, it might make sense to specify which vertex is to be placed at the root of the layout:\n\n\nCode\nlayout &lt;- layout_as_tree(g, root = 2)\n\n\n\n\nDrawing a graph using a layout\nWe can plot our imaginary social network with the Kamada-Kawai layout algorithm as follows:\n\n\nCode\nlayout &lt;- layout_with_kk(g)\n\n\n\n\nCode\nplot(g, layout = layout, main = \"Social network with the Kamada-Kawai layout algorithm\")\n\n\n\n\n\nThis should open a new window showing a visual representation of the network. Remember that the exact placement of nodes may be different on your machine since the layout is not deterministic.\nThe layout argument also accepts functions; in this case, the function will be called with the graph as its first argument. This makes it possible to just pass the name of a layout function directly, without creating a layout variable:\n\n\nCode\nplot(g, layout = layout_with_fr,\n     main = \"Social network with the Fruchterman-Reingold layout algorithm\")\n\n\n\n\n\nTo improve the visuals, a trivial addition would be to color the vertices according to the gender. We should also try to place the labels slightly outside the vertices to improve readability:\n\n\nCode\nV(g)$color &lt;- ifelse(V(g)$gender == \"m\", \"yellow\", \"red\")\nplot(g, layout = layout, vertex.label.dist = 3.5,\n     main = \"Social network - with genders as colors\")\n\n\n\n\n\nYou can also treat the gender attribute as a factor and provide the colors with an argument to plot(), which takes precedence over the color vertex attribute. Colors will be assigned automatically to levels of a factor:\n\n\nCode\nplot(g, layout=layout, vertex.label.dist=3.5, vertex.color=as.factor(V(g)$gender))\n\n\n\n\n\nAs seen above with the vertex.color argument, you can specify visual properties as arguments to plot instead of using vertex or edge attributes. The following plot shows the formal ties with thick lines while informal ones with thin lines:\n\n\nCode\nplot(g, layout=layout, vertex.label.dist=3.5, vertex.size=20,\n     vertex.color=ifelse(V(g)$gender == \"m\", \"yellow\", \"red\"),\n     edge.width=ifelse(E(g)$is_formal, 5, 1))\n\n\n\n\n\nThis latter approach is preferred if you want to keep the properties of the visual representation of your graph separate from the graph itself.\nIn summary, there are special vertex and edge properties that correspond to the visual representation of the graph. These attributes override the default settings of igraph (i.e color, weight, name, shape,layout,etc.). The following two tables summarise the most frequently used visual attributes for vertices and edges, respectively:\n\n\nVertex attributes controlling graph plots\n\n\n\n\n\n\n\n\nAttribute name\nKeyword argument\nPurpose\n\n\n\n\ncolor\nvertex.color\nColor of the vertex\n\n\nlabel\nvertex.label\nLabel of the vertex. They will be converted to character. Specify NA to omit vertex labels. The default vertex labels are the vertex ids.\n\n\nlabel.cex\nvertex.label.cex\nFont size of the vertex label, interpreted as a multiplicative factor, similarly to R’s text function\n\n\nlabel.color\nvertex.label.color\nColor of the vertex label\n\n\nlabel.degree\nvertex.label.degree\nIt defines the position of the vertex labels, relative to the center of the vertices. It is interpreted as an angle in radian, zero means ‘to the right’, and ‘pi’ means to the left, up is -pi/2 and down is pi/2. The default value is -pi/4\n\n\nlabel.dist\nvertex.label.dist\nDistance of the vertex label from the vertex itself, relative to the vertex size\n\n\nlabel.family\nvertex.label.family\nFont family of the vertex, similarly to R’s text function\n\n\nlabel.font\nvertex.label.font\nFont within the font family of the vertex, similarly to R’s text function\n\n\nshape\nvertex.shape\nThe shape of the vertex, currently “circle”, “square”, “csquare”, “rectangle”, “crectangle”, “vrectangle”, “pie” (see vertex.shape.pie), ‘sphere’, and “none” are supported, and only by the plot.igraph command.\n\n\nsize\nvertex.size\nThe size of the vertex, a numeric scalar or vector, in the latter case each vertex sizes may differ\n\n\n\n\n\nEdge attributes controlling graph plots\n\n\n\n\n\n\n\n\nAttribute name\nKeyword argument\nPurpose\n\n\n\n\ncolor\nedge.color\nColor of the edge\n\n\ncurved\nedge.curved\nA numeric value specifies the curvature of the edge; zero curvature means straight edges, negative values means the edge bends clockwise, positive values the opposite. TRUE means curvature 0.5, FALSE means curvature zero\n\n\narrow.size\nedge.arrow.size\nCurrently this is a constant, so it is the same for every edge. If a vector is submitted then only the first element is used, ie. if this is taken from an edge attribute then only the attribute of the first edge is used for all arrows.\n\n\narrow.width\nedge.arrow.width\nThe width of the arrows. Currently this is a constant, so it is the same for every edge\n\n\nwidth\nedge.width\nWidth of the edge in pixels\n\n\nlabel\nedge.label\nIf specified, it adds a label to the edge.\n\n\nlabel.cex\nedge.label.cex\nFont size of the edge label, interpreted as a multiplicative factor, similarly to R’s text function\n\n\nlabel.color\nedge.label.color\nColor of the edge label\n\n\nlabel.family\nedge.label.family\nFont family of the edge, similarly to R’s text function\n\n\nlabel.font\nedge.label.font\nFont within the font family of the edge, similarly to R’s text function\n\n\n\n\n\nGeneric arguments of plot()\nThese settings can be specified as arguments to the plot function to control the overall appearance of the plot.\n\n\n\n\n\n\n\nKeyword argument\nPurpose\n\n\n\n\nlayout\nThe layout to be used. It can be an instance of Layout, a list of tuples containing X-Y coordinates, or the name of a layout algorithm. The default is auto, which selects a layout algorithm automatically based on the size and connectedness of the graph.\n\n\nmargin\nThe amount of empty space below, over, at the left and right of the plot, it is a numeric vector of length four."
  },
  {
    "objectID": "posts/NetworkData/index.html#assignment",
    "href": "posts/NetworkData/index.html#assignment",
    "title": "Practice with Network Data",
    "section": "ASSIGNMENT",
    "text": "ASSIGNMENT\nImprove the network above by:\n\nColoring the edges according to Advisor / BCB520 attribute.\nColoring the nodes according to Department.\nAdujsting the labels to improve readability.\nFind the best layout you can for this garbage. What a nightmare."
  },
  {
    "objectID": "posts/NetworkData/index.html#improved-network",
    "href": "posts/NetworkData/index.html#improved-network",
    "title": "Practice with Network Data",
    "section": "IMPROVED NETWORK",
    "text": "IMPROVED NETWORK\n\n\nCode\nlibrary(dplyr)\n\nBCB&lt;-people%&gt;%\n  filter(BCB520 == \"TRUE\")%&gt;%\n  select(name, BCB520)\n\nedgelist&lt;- combn(BCB$name, 2)\nedgelist_df &lt;- as.data.frame(t(edgelist))\ncolnames(edgelist_df) &lt;- c(\"from\", \"to\")\nedgelist_df$BCB520&lt;-\"TRUE\"\nedgelist_df$Advisor&lt;-\"FALSE\"\n\nrelations$BCB520 &lt;- \"FALSE\"\n\nrelations3&lt;-rbind(relations, edgelist_df)\n\ng &lt;- graph_from_data_frame(relations3, directed=FALSE, vertices=people)\n\n\nplot(g,  layout = layout_with_fr)\n\n\n\n\n\n\n\nCode\nlibrary(igraph)\nlibrary(igraph)\n\n# Assuming you already have 'people' and 'relations' data frames\n\n# Color Palette\npalette &lt;- c(\"blue\", \"red\")\n\n# Create the graph\ng &lt;- graph_from_data_frame(relations3, directed = FALSE, vertices = people)\n\n# Define edge colors based on attributes\nedge_colors &lt;- ifelse(E(g)$BCB520 == \"TRUE\", palette[1], ifelse(E(g)$Advisor == \"TRUE\", palette[2], \"black\"))\n\n# Plot the graph with customized edge colors\nplot(\n  g,\n  layout = layout_nicely,\n  edge.color = edge_colors,\n  vertex.label.color = \"black\",\n  vertex.size = 10,\n  vertex.label.cex = 0.8,\n  edge.arrow.size = 0.5\n)\n\n\n\n\n\n\n\nCode\nlibrary(igraph)\n\n# Assuming you already have 'people' and 'relations' data frames\n\n# Color Palette\npalette &lt;- c(\"blue\", \"red\")\n\n# Create the graph\ng &lt;- graph_from_data_frame(relations3, directed = FALSE, vertices = people)\n\n# Get unique departments\ndepartments &lt;- unique(people$department)\n\n# Define colors for each department\ndepartment_colors &lt;- rainbow(length(departments))\n\n# Map department colors to vertices\nV(g)$color &lt;- department_colors[match(people$department, departments)]\n\n# Define edge colors based on attributes\nedge_colors &lt;- ifelse(E(g)$BCB520 == \"TRUE\", palette[1], ifelse(E(g)$Advisor == \"TRUE\", palette[2], \"black\"))\n\n# Plot the graph with customized edge colors\nplot(\n  g,\n  layout = layout_nicely,\n  edge.color = edge_colors,\n  vertex.label.color = \"black\",\n  vertex.size = 10,\n  vertex.label.cex = 0.8,\n  edge.arrow.size = 0.5\n)\n\n\n\n\n\n\n\nCode\n# Assuming you already have 'people' and 'relations' data frames\n\n# Color Palette\npalette &lt;- c(\"blue\", \"red\")\n\n# Create the graph\ng &lt;- graph_from_data_frame(relations3, directed = FALSE, vertices = people)\n\n# Get unique departments\ndepartments &lt;- unique(people$department)\n\n# Define colors for each department\ndepartment_colors &lt;- rainbow(length(departments))\n\n# Map department colors to vertices\nV(g)$color &lt;- department_colors[match(people$department, departments)]\n\n# Define edge colors based on attributes\nedge_colors &lt;- ifelse(E(g)$BCB520 == \"TRUE\", palette[1], ifelse(E(g)$Advisor == \"TRUE\", palette[2], \"black\"))\n\n# Plot the graph with customized edge colors\nplot(\n  g,\n  layout = layout_nicely,\n  edge.color = edge_colors,\n  vertex.label.color = \"black\",\n  vertex.size = 10,\n  vertex.label.cex = 0.8,\n  edge.arrow.size = 0.5,\n  vertex.label.dist = 0.5,  # Adjust label distance from vertices\n  vertex.label.family = \"sans\",  # Font family for labels\n  vertex.label.font = 2  # Font style for labels (bold)\n)\n\n\n\n\n\n\n\nCode\n# Assuming you already have 'people' and 'relations' data frames\n\n# Color Palette\npalette &lt;- c(\"blue\", \"red\")\n\n# Create the graph\ng &lt;- graph_from_data_frame(relations3, directed = FALSE, vertices = people)\n\n# Get unique departments\ndepartments &lt;- unique(people$department)\n\n# Define colors for each department\ndepartment_colors &lt;- rainbow(length(departments))\n\n# Map department colors to vertices\nV(g)$color &lt;- department_colors[match(people$department, departments)]\n\n# Define edge colors based on attributes\nedge_colors &lt;- ifelse(E(g)$BCB520 == \"TRUE\", palette[1], ifelse(E(g)$Advisor == \"TRUE\", palette[2], \"black\"))\n\n# Plot the graph with customized edge colors and improved labels\nplot(\n  g,\n  layout = layout_in_circle(g),\n  edge.color = edge_colors,\n  vertex.label.color = \"black\",\n  vertex.size = 10,\n  vertex.label.cex = 0.8,\n  edge.arrow.size = 0.5,\n  vertex.label.dist = 0.5,\n  vertex.label.family = \"sans\",\n  vertex.label.font = 2,\n  vertex.label.degree = 0,\n  vertex.label.cex = 0.8,\n  vertex.label.color = \"black\"\n)"
  },
  {
    "objectID": "posts/FinalProject/Final_Project.html",
    "href": "posts/FinalProject/Final_Project.html",
    "title": "BCB 520 - FINAL PROJECT",
    "section": "",
    "text": "This assignment provides you the opportunity to synthesize all of the concepts we’ve covered in the course to date. The basic framework is that you will create a COMPLETE data visualization BLOG post that is suitable as a showcase component of your Data Science Portfolio. The point is to SHOW people your skills."
  },
  {
    "objectID": "posts/FinalProject/Final_Project.html#overview",
    "href": "posts/FinalProject/Final_Project.html#overview",
    "title": "BCB 520 - FINAL PROJECT",
    "section": "",
    "text": "This assignment provides you the opportunity to synthesize all of the concepts we’ve covered in the course to date. The basic framework is that you will create a COMPLETE data visualization BLOG post that is suitable as a showcase component of your Data Science Portfolio. The point is to SHOW people your skills."
  },
  {
    "objectID": "posts/FinalProject/Final_Project.html#structure",
    "href": "posts/FinalProject/Final_Project.html#structure",
    "title": "BCB 520 - FINAL PROJECT",
    "section": "STRUCTURE",
    "text": "STRUCTURE\nThe basic formatting guidelines for this assignment are:\n\nInclude code fold or code tools options (or both) that allow users to view and copy your code while maintaining overall readability of your post.\nSuppress all output and warnings that might distract from your visualizations and writing.\nProperly title your assignment. The main title should be “BCB 520 - Final Project”, and the subtitle should be a descriptive title related to your question or topic.\nInclude author, date, categories, and a description in your YAML header.\nWrite clear, complete sentences for a target audience with some scientific background but little training in your specific discipline.\nInclude references if appropriate and use hyperlinks to external sources of data, inspiration, or examples.\nUse the header hierarchy and create a sensible document outline with white space. Format for readability! Use bold and italic fonts to emphasize things! Use color by customizing your .css file!\n\nIn addition to the above formatting guidelines, your portfolio post must contain the following sections:\n\nPreamble\nWrite a brief paragraph describing the primary question or purpose of the post. Ideally, the concept should be challenging enough that it requires at least two visualizations that use different idioms (ie. don’t just make two scatterplots with different variables). The concept should also be challenging enough that it captures the interest of the reader (i.e. a plot of height and weight that shows they are correlated is trivial and not appropriate). The best approach is to explore a topic or question in which YOU are very interested.\n\n\nData\n\n\nCode\nlibrary(ggplot2)\n\n\nWarning: package 'ggplot2' was built under R version 4.3.3\n\n\nCode\nlibrary(sf)\n\n\nWarning: package 'sf' was built under R version 4.3.3\n\n\nLinking to GEOS 3.11.2, GDAL 3.8.2, PROJ 9.3.1; sf_use_s2() is TRUE\n\n\nCode\nlibrary(tigris)\n\n\nWarning: package 'tigris' was built under R version 4.3.3\n\n\nTo enable caching of data, set `options(tigris_use_cache = TRUE)`\nin your R script or .Rprofile.\n\n\nCode\nlibrary(dplyr)\n\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\n\nCode\nlibrary(rnaturalearth)\n\n\nWarning: package 'rnaturalearth' was built under R version 4.3.3\n\n\nCode\nlibrary(rnaturalearthdata)\n\n\nWarning: package 'rnaturalearthdata' was built under R version 4.3.3\n\n\n\nAttaching package: 'rnaturalearthdata'\n\n\nThe following object is masked from 'package:rnaturalearth':\n\n    countries110\n\n\nCode\nlibrary(dplyr)\nlibrary(rnaturalearthhires)\nlibrary(plotly)\n\n\nWarning: package 'plotly' was built under R version 4.3.3\n\n\n\nAttaching package: 'plotly'\n\n\nThe following object is masked from 'package:ggplot2':\n\n    last_plot\n\n\nThe following object is masked from 'package:stats':\n\n    filter\n\n\nThe following object is masked from 'package:graphics':\n\n    layout\n\n\nCode\nlibrary(readxl)\nlibrary(dplyr)\n\n\nWrite a summary of the data sources you will use. Include a Data Dictionary table that fully describes each individual data file used. You may use your own research data or publicly available data from any source you like (with attribution). There aren’t any minimum or maximum data set size requirements, other than you need something big enough to be interesting and not so big that we don’t have a supercomputer capable of creating your visualization.\nNEW REQUIREMENT: Your assignment must feature one of the two new data types we have considered since the midterm: NETWORK DATA or SPATIAL DATA.\n\n\nVisualizations\nCreate your visualizations and include text that explains any steps or design choices. Be sure to include clearly labeled axes and a concise but complete figure caption for each visualization. Make deliberate choices for color palettes, point marks, line types, etc. Demonstrate that you understand the concepts we have covered!\n\n\nCode\n# Get the spatial data for countries\ncountries &lt;- ne_countries(scale = \"medium\", returnclass = \"sf\")\n\n# Filter the dataset to extract Puerto Rico\npuerto_rico &lt;- subset(countries, admin == \"Puerto Rico\")\n\n# Plot Puerto Rico's geometry\nggplot() +\n  geom_sf(data = puerto_rico) +\n  theme_void()\n\n\n\n\n\n\n\nCode\nlibrary(tidyverse)\n\n\nWarning: package 'lubridate' was built under R version 4.3.3\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ lubridate 1.9.3     ✔ tibble    3.2.1\n✔ purrr     1.0.2     ✔ tidyr     1.3.0\n✔ readr     2.1.5     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ plotly::filter() masks dplyr::filter(), stats::filter()\n✖ dplyr::lag()     masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\nCode\nlibrary(readxl)\nlibrary(viridis)\n\n\nLoading required package: viridisLite\n\n\nCode\nlibrary (plotly)\n\n# Read the data\nrainfallprwide &lt;- read_excel('geraline_data_mm.xlsx')\n\nstations &lt;- rainfallprwide %&gt;%\n  select(STATION, LATITUDE, LONGITUDE, NAME)%&gt;%\n  unique()\n\ng &lt;- list(\n  scope = 'north america',\n  center = list(lat = 18.2208, lon = -66.5901),  # Centered on Puerto Rico\n  projection = list(type = 'mercator'),\n  showland = TRUE,\n  landcolor = \"rgb(220, 220, 220)\",  # Light gray\n  subunitcolor = \"rgb(200, 200, 200)\",  # Light gray\n  countrycolor = \"rgb(200, 200, 200)\",  # Light gray\n  countrywidth = 0.5,\n  subunitwidth = 0.5\n)\n\n plot_geo(stations, lat = ~LATITUDE, lon = ~LONGITUDE) %&gt;%\n  add_markers(\n    text = ~NAME,\n    symbol = I(\"circle\"),\n    size = I(10),\n    hoverinfo = \"text\"\n  ) %&gt;%\n  layout(\n    title = 'Rainfall in Puerto Rico Stations',\n    geo = g\n  )\n\n\n\n\n\n\n\n\nCode\nlibrary(plotly)\nlibrary(ggplot2)\nlibrary(maps)\n\n\nWarning: package 'maps' was built under R version 4.3.3\n\n\n\nAttaching package: 'maps'\n\n\nThe following object is masked from 'package:viridis':\n\n    unemp\n\n\nThe following object is masked from 'package:purrr':\n\n    map\n\n\nCode\n# Get the map data for Puerto Rico\nmap_data &lt;- map_data(\"world\", region = \"Puerto Rico\")\n\n# Create the base map with ggplot2\nbase_map &lt;- ggplot() +\n  geom_polygon(data = map_data, aes(x = long, y = lat, group = group), fill = \"lightgray\", color = \"black\") +\n  coord_map() +\n  ggtitle(\"Map of Puerto Rico\")\n\n# Convert the base map to a Plotly object\nplotly_map &lt;- ggplotly(base_map)\n\n# Assuming 'stations' is your data frame and it has columns 'LATITUDE', 'LONGITUDE', and 'NAME'\n# Add station markers to the Plotly map\n plotly_map %&gt;%\n  add_markers(\n    data = stations,\n    x = ~LONGITUDE,\n    y = ~LATITUDE,\n    text = ~NAME,\n    marker = list(\n      symbol = \"circle\",  # Change the symbol to square\n      color = \"navy\",     # Change the color to blue\n      size = 10           # Change the size to 10\n    ),\n    hoverinfo = \"text\"\n  ) \n\n\n\n\n\n\n\n\nCode\nlibrary(tidyverse)\nlibrary(readxl)\n\n#2009\n# Read the data\nrainfallprwide &lt;- read_excel('geraline_data_mm.xlsx')\n\n# Create the stations data frame and filter for month 1\nstations_rain &lt;- rainfallprwide %&gt;%\n  filter(MONTH == 1) %&gt;%\n  select(STATION, LATITUDE, LONGITUDE, NAME, MONTH, \"2009\") %&gt;%\n  unique()\n\n# Extract years from column names\nyears &lt;- as.character(2009:2023)\n\n# Convert the numeric columns to numeric type\nrainfallprwide[,-(1:5)] &lt;- lapply(rainfallprwide[,-(1:5)], as.numeric)\n\n\nWarning in lapply(rainfallprwide[, -(1:5)], as.numeric): NAs introduced by\ncoercion\n\n\nCode\n# Calculate total rainfall for each station for each year individually\nstation_year_total_rainfall &lt;- rainfallprwide %&gt;%\n  group_by(STATION, LATITUDE, LONGITUDE, NAME) %&gt;%\n  summarise(across(all_of(years), ~sum(.x, na.rm = TRUE), .names = \"Total_Rainfall_{.col}\"))\n\n\n`summarise()` has grouped output by 'STATION', 'LATITUDE', 'LONGITUDE'. You can\noverride using the `.groups` argument.\n\n\nCode\n# Convert the base map to a Plotly object\nplotly_map &lt;- ggplotly(base_map)\n\n# Assuming 'stations_rain' is your data frame and it has columns 'LATITUDE', 'LONGITUDE', 'NAME', and '2009'\n# Add station markers to the Plotly map with size based on rainfall in 2009\n plotly_map %&gt;%\n  add_markers(\n    data = station_year_total_rainfall,\n    x = ~LONGITUDE,\n    y = ~LATITUDE,\n    text = ~NAME,\n    marker = list(\n      symbol = \"circle\",       # Change the symbol to square\n      color = ~Total_Rainfall_2009 / 100,          # Change the color to blue\n      size = ~Total_Rainfall_2009 / 100,\n      colorscale = \"Blues\",\n      reversescale = TRUE              # Size based on rainfall in 2009\n    ),\n    hoverinfo = \"text\"\n  ) \n\n\n\n\n\n\n\n\nCode\n#2012\n# Read the data\nrainfallprwide &lt;- read_excel('geraline_data_mm.xlsx')\n\n# Create the stations data frame and filter for month 1\nstations_rain &lt;- rainfallprwide %&gt;%\n  filter(MONTH == 1) %&gt;%\n  select(STATION, LATITUDE, LONGITUDE, NAME, MONTH, \"2012\") %&gt;%\n  unique()\n\n# Extract years from column names\nyears &lt;- as.character(2009:2023)\n\n# Convert the numeric columns to numeric type\nrainfallprwide[,-(1:5)] &lt;- lapply(rainfallprwide[,-(1:5)], as.numeric)\n\n\nWarning in lapply(rainfallprwide[, -(1:5)], as.numeric): NAs introduced by\ncoercion\n\n\nCode\n# Calculate total rainfall for each station for each year individually\nstation_year_total_rainfall &lt;- rainfallprwide %&gt;%\n  group_by(STATION, LATITUDE, LONGITUDE, NAME) %&gt;%\n  summarise(across(all_of(years), ~sum(.x, na.rm = TRUE), .names = \"Total_Rainfall_{.col}\"))\n\n\n`summarise()` has grouped output by 'STATION', 'LATITUDE', 'LONGITUDE'. You can\noverride using the `.groups` argument.\n\n\nCode\n# Convert the base map to a Plotly object\nplotly_map &lt;- ggplotly(base_map)\n\n# Assuming 'stations_rain' is your data frame and it has columns 'LATITUDE', 'LONGITUDE', 'NAME', and '2009'\n# Add station markers to the Plotly map with size based on rainfall in 2009\n plotly_map %&gt;%\n  add_markers(\n    data = station_year_total_rainfall,\n    x = ~LONGITUDE,\n    y = ~LATITUDE,\n    text = ~NAME,\n    marker = list(\n      symbol = \"circle\",       # Change the symbol to square\n      color = ~Total_Rainfall_2012 / 100,          # Change the color to blue\n      size = ~Total_Rainfall_2012 / 100,\n      colorscale = \"Blues\",\n      reversescale = TRUE              # Size based on rainfall in 2009\n    ),\n    hoverinfo = \"text\"\n  )\n\n\n\n\n\n\n\n\nCode\n#2017\n# Read the data\nrainfallprwide &lt;- read_excel('geraline_data_mm.xlsx')\n\n# Create the stations data frame and filter for month 1\nstations_rain &lt;- rainfallprwide %&gt;%\n  filter(MONTH == 1) %&gt;%\n  select(STATION, LATITUDE, LONGITUDE, NAME, MONTH, \"2009\") %&gt;%\n  unique()\n\n# Extract years from column names\nyears &lt;- as.character(2009:2023)\n\n# Convert the numeric columns to numeric type\nrainfallprwide[,-(1:5)] &lt;- lapply(rainfallprwide[,-(1:5)], as.numeric)\n\n\nWarning in lapply(rainfallprwide[, -(1:5)], as.numeric): NAs introduced by\ncoercion\n\n\nCode\n# Calculate total rainfall for each station for each year individually\nstation_year_total_rainfall &lt;- rainfallprwide %&gt;%\n  group_by(STATION, LATITUDE, LONGITUDE, NAME) %&gt;%\n  summarise(across(all_of(years), ~sum(.x, na.rm = TRUE), .names = \"Total_Rainfall_{.col}\"))\n\n\n`summarise()` has grouped output by 'STATION', 'LATITUDE', 'LONGITUDE'. You can\noverride using the `.groups` argument.\n\n\nCode\n# Convert the base map to a Plotly object\nplotly_map &lt;- ggplotly(base_map)\n\n# Assuming 'stations_rain' is your data frame and it has columns 'LATITUDE', 'LONGITUDE', 'NAME', and '2009'\n# Add station markers to the Plotly map with size based on rainfall in 2009\n plotly_map %&gt;%\n  add_markers(\n    data = station_year_total_rainfall,\n    x = ~LONGITUDE,\n    y = ~LATITUDE,\n    text = ~NAME,\n    marker = list(\n      symbol = \"circle\",       # Change the symbol to square\n      color = ~Total_Rainfall_2017 / 100,          # Change the color to blue\n      size = ~Total_Rainfall_2017 / 100,\n      colorscale = \"Blues\",\n      reversescale = TRUE              # Size based on rainfall in 2009\n    ),\n    hoverinfo = \"text\"\n  )\n\n\n\n\n\n\n\n\nCode\n#2019\n# Read the data\nrainfallprwide &lt;- read_excel('geraline_data_mm.xlsx')\n\n# Create the stations data frame and filter for month 1\nstations_rain &lt;- rainfallprwide %&gt;%\n  filter(MONTH == 1) %&gt;%\n  select(STATION, LATITUDE, LONGITUDE, NAME, MONTH, \"2009\") %&gt;%\n  unique()\n\n# Extract years from column names\nyears &lt;- as.character(2009:2023)\n\n# Convert the numeric columns to numeric type\nrainfallprwide[,-(1:5)] &lt;- lapply(rainfallprwide[,-(1:5)], as.numeric)\n\n\nWarning in lapply(rainfallprwide[, -(1:5)], as.numeric): NAs introduced by\ncoercion\n\n\nCode\n# Calculate total rainfall for each station for each year individually\nstation_year_total_rainfall &lt;- rainfallprwide %&gt;%\n  group_by(STATION, LATITUDE, LONGITUDE, NAME) %&gt;%\n  summarise(across(all_of(years), ~sum(.x, na.rm = TRUE), .names = \"Total_Rainfall_{.col}\"))\n\n\n`summarise()` has grouped output by 'STATION', 'LATITUDE', 'LONGITUDE'. You can\noverride using the `.groups` argument.\n\n\nCode\n# Convert the base map to a Plotly object\nplotly_map &lt;- ggplotly(base_map)\n\n# Assuming 'stations_rain' is your data frame and it has columns 'LATITUDE', 'LONGITUDE', 'NAME', and '2009'\n# Add station markers to the Plotly map with size based on rainfall in 2009\n plotly_map %&gt;%\n  add_markers(\n    data = station_year_total_rainfall,\n    x = ~LONGITUDE,\n    y = ~LATITUDE,\n    text = ~NAME,\n    marker = list(\n      symbol = \"circle\",       # Change the symbol to square\n      color = ~Total_Rainfall_2019 / 100,          # Change the color to blue\n      size = ~Total_Rainfall_2019 / 100,\n      colorscale = \"Blues\",\n      reversescale = TRUE              # Size based on rainfall in 2009\n    ),\n    hoverinfo = \"text\"\n  )\n\n\n\n\n\n\n\n\nCode\n#2022\n# Read the data\nrainfallprwide &lt;- read_excel('geraline_data_mm.xlsx')\n\n# Create the stations data frame and filter for month 1\nstations_rain &lt;- rainfallprwide %&gt;%\n  filter(MONTH == 1) %&gt;%\n  select(STATION, LATITUDE, LONGITUDE, NAME, MONTH, \"2009\") %&gt;%\n  unique()\n\n# Extract years from column names\nyears &lt;- as.character(2009:2023)\n\n# Convert the numeric columns to numeric type\nrainfallprwide[,-(1:5)] &lt;- lapply(rainfallprwide[,-(1:5)], as.numeric)\n\n\nWarning in lapply(rainfallprwide[, -(1:5)], as.numeric): NAs introduced by\ncoercion\n\n\nCode\n# Calculate total rainfall for each station for each year individually\nstation_year_total_rainfall &lt;- rainfallprwide %&gt;%\n  group_by(STATION, LATITUDE, LONGITUDE, NAME) %&gt;%\n  summarise(across(all_of(years), ~sum(.x, na.rm = TRUE), .names = \"Total_Rainfall_{.col}\"))\n\n\n`summarise()` has grouped output by 'STATION', 'LATITUDE', 'LONGITUDE'. You can\noverride using the `.groups` argument.\n\n\nCode\n# Convert the base map to a Plotly object\nplotly_map &lt;- ggplotly(base_map)\n\n# Assuming 'stations_rain' is your data frame and it has columns 'LATITUDE', 'LONGITUDE', 'NAME', and '2009'\n# Add station markers to the Plotly map with size based on rainfall in 2009\n plotly_map %&gt;%\n  add_markers(\n    data = station_year_total_rainfall,\n    x = ~LONGITUDE,\n    y = ~LATITUDE,\n    text = ~NAME,\n    marker = list(\n      symbol = \"circle\",       # Change the symbol to square\n      color = ~Total_Rainfall_2022 / 100,          # Change the color to blue\n      size = ~Total_Rainfall_2022 / 100,\n      colorscale = \"Blues\",\n      reversescale = TRUE              # Size based on rainfall in 2009\n    ),\n    hoverinfo = \"text\"\n  )\n\n\n\n\n\n\n\n\nCode\nlibrary(dplyr)\n\n# Read the data\nrainfallprwide &lt;- read_excel('geraline_data_mm.xlsx')\n\n# Extract years from column names\nyears &lt;- as.character(2009:2023)\n\n# Convert the numeric columns to numeric type\nrainfallprwide[,-(1:5)] &lt;- lapply(rainfallprwide[,-(1:5)], as.numeric)\n\n\nWarning in lapply(rainfallprwide[, -(1:5)], as.numeric): NAs introduced by\ncoercion\n\n\nCode\n# Calculate total rainfall for each station for each year individually\nstation_year_total_rainfall &lt;- rainfallprwide %&gt;%\n  group_by(STATION, LATITUDE, LONGITUDE, NAME) %&gt;%\n  summarise(across(all_of(years), ~sum(.x, na.rm = TRUE), .names = \"Total_Rainfall_{.col}\"))\n\n\n`summarise()` has grouped output by 'STATION', 'LATITUDE', 'LONGITUDE'. You can\noverride using the `.groups` argument.\n\n\n\n\nCode\nlibrary(plotly)\n\n# Create an empty list to store the plots\nplot_list &lt;- list()\n\n# Loop over each year\nfor (year in 2009:2023) {\n  # Create a map for the current year\n  plot &lt;- ggplotly(base_map) %&gt;%\n    add_markers(\n      data = station_year_total_rainfall,\n      x = ~LONGITUDE,\n      y = ~LATITUDE,\n      text = ~NAME,\n      marker = list(\n        symbol = \"circle\",\n        color = station_year_total_rainfall[[paste0(\"Total_Rainfall_\", year)]] / 100,\n        size = station_year_total_rainfall[[paste0(\"Total_Rainfall_\", year)]] / 100,\n        colorscale = \"Blues\",\n        reversescale = TRUE\n      ),\n      hoverinfo = \"text\"\n    )\n  \n  # Add the plot to the list\n  plot_list[[year - 2008]] &lt;- plot\n}\n\n# Arrange the plots in a grid\nsubplot(plot_list, nrows = 5)\n\n\n\n\n\n\n\n\nConclusions or Summary\nAnswer your research question. Draw a conclusion or inference related to your topic. Summarize your results. What new questions have emerged as a result of your visualizations? What interesting next steps have emerged?"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "My name is Geraline Trossi-Torres, I’m a PhD student in Microbiology, Molecular Biology and Biochemistry at the University of Idaho. When not doing research I enjoy playing on my XBOX S or reading a good fantasy and Sci-fi books."
  },
  {
    "objectID": "about.html#education",
    "href": "about.html#education",
    "title": "About",
    "section": "Education",
    "text": "Education\nBoise State University | Boise, ID\nMS in Biomolecular Sciences | Fall 2020 - Fall 2022\nPontifical Catholic University of Puerto Rico| Ponce, PR\nMS in Biotechnology | Fall 2016 - Spring 2018\nUniversity of Puerto Rico - Ponce | Ponce, PR\nB.S in Biotechnology | Fall 2011 - Spring 2016"
  },
  {
    "objectID": "about.html#experience",
    "href": "about.html#experience",
    "title": "About",
    "section": "Experience",
    "text": "Experience\nBoise State University | Research Technician | January 2023 - June 2023\nBoise State University | Research Assistant | August 2022 - December 2022\nUPR-PRISE Program (NIH-NIGMS RISE) | Program Coordinator | August 2019 - June 2020\nUPR-PRISE Program (NIH-NIGMS RISE) | Research Coordinator | July 2018 - July 2019"
  }
]